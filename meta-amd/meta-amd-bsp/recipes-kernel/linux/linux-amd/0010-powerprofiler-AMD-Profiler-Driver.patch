From 0de73acd2d113cc0736711c36863aadd080402a0 Mon Sep 17 00:00:00 2001
From: amlakshm <AmmuThivya.LakshmiS@amd.com>
Date: Wed, 9 Oct 2024 10:34:00 +0000
Subject: [PATCH] powerprofiler:  AMD Profiler Driver

This is a not a GPL driver. The driver is need to enable uProf

Signed-off-by: Sudheesh Mavila <sudheesh.mavila@amd.com>
---
 drivers/Kconfig                               |    2 +
 drivers/Makefile                              |    2 +-
 drivers/powerprofiler/AMDPPcert.sh            |  120 +
 drivers/powerprofiler/AMDPowerProfilerVersion |    1 +
 drivers/powerprofiler/Kconfig                 |   19 +
 drivers/powerprofiler/Makefile                |  160 +
 drivers/powerprofiler/Makefile.bak            |  160 +
 drivers/powerprofiler/dkms.conf               |    6 +
 drivers/powerprofiler/inc/MsrList.h           |   67 +
 drivers/powerprofiler/inc/MsrListZen4.h       |   55 +
 .../powerprofiler/inc/PmcCommonDataTypes.h    |  203 ++
 drivers/powerprofiler/inc/PmcDataBuffer.h     |   29 +
 drivers/powerprofiler/inc/PmcDataBufferOps.h  |   23 +
 drivers/powerprofiler/inc/PmcInterface.h      |  187 ++
 drivers/powerprofiler/inc/PmcOsTypes.h        |   47 +
 drivers/powerprofiler/inc/PmcProcessConfig.h  |   85 +
 drivers/powerprofiler/inc/PmcTimerConfig.h    |   46 +
 drivers/powerprofiler/inc/PmcTypes.h          |  112 +
 drivers/powerprofiler/inc/PmcUtils.h          |   28 +
 drivers/powerprofiler/inc/PwrAccessPmcData.h  |   30 +
 drivers/powerprofiler/inc/PwrCommonConfig.h   |   21 +
 .../powerprofiler/inc/PwrCommonDataTypes.h    |  895 ++++++
 .../inc/PwrCounterAccessInterface.h           |   46 +
 drivers/powerprofiler/inc/PwrDriverInternal.h |   62 +
 drivers/powerprofiler/inc/PwrDriverIoctls.h   |  145 +
 drivers/powerprofiler/inc/PwrDriverTypedefs.h |  118 +
 drivers/powerprofiler/inc/PwrDriverUtils.h    |  205 ++
 drivers/powerprofiler/inc/PwrOsPrimitives.h   |  163 +
 drivers/powerprofiler/inc/PwrProfAsm.h        |  408 +++
 drivers/powerprofiler/inc/PwrProfCpuid.h      |   68 +
 .../powerprofiler/inc/PwrProfDebugHelper.h    |   18 +
 drivers/powerprofiler/inc/PwrProfInternal.h   |   49 +
 .../powerprofiler/inc/PwrProfSharedMemOps.h   |   20 +
 drivers/powerprofiler/inc/PwrProfTimer.h      |   51 +
 .../powerprofiler/inc/PwrProfTimerHelper.h    |   40 +
 .../powerprofiler/inc/PwrSharedBufferConfig.h |  100 +
 drivers/powerprofiler/inc/PwrVersion.h        |   37 +
 drivers/powerprofiler/src/PmcDataBufferOps.c  |  343 ++
 drivers/powerprofiler/src/PmcProcessConfig.c  | 2811 +++++++++++++++++
 drivers/powerprofiler/src/PmcTimerConfig.c    |  342 ++
 drivers/powerprofiler/src/PmcUtils.c          |   97 +
 drivers/powerprofiler/src/PwrAccessPmcData.c  |  176 ++
 drivers/powerprofiler/src/PwrCommonConfig.c   |   70 +
 drivers/powerprofiler/src/PwrCommonHelper.c   |  622 ++++
 .../src/PwrCounterAccessInterface.c           |  520 +++
 drivers/powerprofiler/src/PwrDriverUtils.c    |  935 ++++++
 drivers/powerprofiler/src/PwrOsPrimitives.c   |  597 ++++
 .../powerprofiler/src/PwrProfDebugHelper.c    |   67 +
 drivers/powerprofiler/src/PwrProfEntry.c      | 1216 +++++++
 drivers/powerprofiler/src/PwrProfModule.c     |  311 ++
 .../powerprofiler/src/PwrProfSharedMemOps.c   |  263 ++
 drivers/powerprofiler/src/PwrProfTimer.c      |  801 +++++
 .../powerprofiler/src/PwrProfTimerHelper.c    |  226 ++
 drivers/powerprofiler/src/PwrSampleCollect.c  |  613 ++++
 54 files changed, 13837 insertions(+), 1 deletion(-)
 create mode 100644 drivers/powerprofiler/AMDPPcert.sh
 create mode 100644 drivers/powerprofiler/AMDPowerProfilerVersion
 create mode 100644 drivers/powerprofiler/Kconfig
 create mode 100644 drivers/powerprofiler/Makefile
 create mode 100644 drivers/powerprofiler/Makefile.bak
 create mode 100644 drivers/powerprofiler/dkms.conf
 create mode 100644 drivers/powerprofiler/inc/MsrList.h
 create mode 100644 drivers/powerprofiler/inc/MsrListZen4.h
 create mode 100644 drivers/powerprofiler/inc/PmcCommonDataTypes.h
 create mode 100644 drivers/powerprofiler/inc/PmcDataBuffer.h
 create mode 100644 drivers/powerprofiler/inc/PmcDataBufferOps.h
 create mode 100644 drivers/powerprofiler/inc/PmcInterface.h
 create mode 100644 drivers/powerprofiler/inc/PmcOsTypes.h
 create mode 100644 drivers/powerprofiler/inc/PmcProcessConfig.h
 create mode 100644 drivers/powerprofiler/inc/PmcTimerConfig.h
 create mode 100644 drivers/powerprofiler/inc/PmcTypes.h
 create mode 100644 drivers/powerprofiler/inc/PmcUtils.h
 create mode 100644 drivers/powerprofiler/inc/PwrAccessPmcData.h
 create mode 100644 drivers/powerprofiler/inc/PwrCommonConfig.h
 create mode 100644 drivers/powerprofiler/inc/PwrCommonDataTypes.h
 create mode 100644 drivers/powerprofiler/inc/PwrCounterAccessInterface.h
 create mode 100644 drivers/powerprofiler/inc/PwrDriverInternal.h
 create mode 100644 drivers/powerprofiler/inc/PwrDriverIoctls.h
 create mode 100644 drivers/powerprofiler/inc/PwrDriverTypedefs.h
 create mode 100644 drivers/powerprofiler/inc/PwrDriverUtils.h
 create mode 100644 drivers/powerprofiler/inc/PwrOsPrimitives.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfAsm.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfCpuid.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfDebugHelper.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfInternal.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfSharedMemOps.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfTimer.h
 create mode 100644 drivers/powerprofiler/inc/PwrProfTimerHelper.h
 create mode 100644 drivers/powerprofiler/inc/PwrSharedBufferConfig.h
 create mode 100644 drivers/powerprofiler/inc/PwrVersion.h
 create mode 100644 drivers/powerprofiler/src/PmcDataBufferOps.c
 create mode 100644 drivers/powerprofiler/src/PmcProcessConfig.c
 create mode 100644 drivers/powerprofiler/src/PmcTimerConfig.c
 create mode 100644 drivers/powerprofiler/src/PmcUtils.c
 create mode 100644 drivers/powerprofiler/src/PwrAccessPmcData.c
 create mode 100644 drivers/powerprofiler/src/PwrCommonConfig.c
 create mode 100644 drivers/powerprofiler/src/PwrCommonHelper.c
 create mode 100644 drivers/powerprofiler/src/PwrCounterAccessInterface.c
 create mode 100644 drivers/powerprofiler/src/PwrDriverUtils.c
 create mode 100644 drivers/powerprofiler/src/PwrOsPrimitives.c
 create mode 100644 drivers/powerprofiler/src/PwrProfDebugHelper.c
 create mode 100644 drivers/powerprofiler/src/PwrProfEntry.c
 create mode 100644 drivers/powerprofiler/src/PwrProfModule.c
 create mode 100644 drivers/powerprofiler/src/PwrProfSharedMemOps.c
 create mode 100644 drivers/powerprofiler/src/PwrProfTimer.c
 create mode 100644 drivers/powerprofiler/src/PwrProfTimerHelper.c
 create mode 100644 drivers/powerprofiler/src/PwrSampleCollect.c

diff --git a/drivers/Kconfig b/drivers/Kconfig
index efb66e25fa2d..863a3cff3e1d 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -187,6 +187,8 @@ source "drivers/ntb/Kconfig"
 
 source "drivers/pwm/Kconfig"
 
+source "drivers/powerprofiler/Kconfig"
+
 source "drivers/irqchip/Kconfig"
 
 source "drivers/ipack/Kconfig"
diff --git a/drivers/Makefile b/drivers/Makefile
index 1bec7819a837..af22abb39afe 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -21,7 +21,7 @@ obj-$(CONFIG_GENERIC_PHY)	+= phy/
 obj-$(CONFIG_PINCTRL)		+= pinctrl/
 obj-$(CONFIG_GPIOLIB)		+= gpio/
 obj-y				+= pwm/
-
+obj-$(CONFIG_AMD_POWER_PROFILER)				+= powerprofiler/
 obj-y				+= pci/
 
 obj-$(CONFIG_PARISC)		+= parisc/
diff --git a/drivers/powerprofiler/AMDPPcert.sh b/drivers/powerprofiler/AMDPPcert.sh
new file mode 100644
index 000000000000..1a1d72bbe271
--- /dev/null
+++ b/drivers/powerprofiler/AMDPPcert.sh
@@ -0,0 +1,120 @@
+#!/bin/bash
+#=====================================================================
+# Copyright (c) 2024 Advanced Micro Devices, Inc. All rights reserved.
+#
+# Create secure boot signing/signed ko
+#
+#=====================================================================
+
+TO=$1
+MN=$2
+if [ $TO -eq 0 ];  then
+	if which mokutil >/dev/null 2>&1; then
+		state=$(mokutil --sb-state)
+
+		message="*************************************************
+Warning: Secure Boot is currently enabled.
+-- Select \"no\" and disable Secure Boot from the BIOS menu to proceed.
+-- Select \"yes\" to enroll in Secure Boot by creating a password.
+   Be sure to complete the entire Secure Boot enrollment process.
+   An abrupt abort may require a complex restoration process to re-enroll.
+   Refer to the user guide for more information."
+
+		if [ "$state" == "SecureBoot enabled" ]; then
+			while true; do
+				printf "$message\n";
+				read -p "   Continue enrolling with Secure Boot? (yes/no) " yn
+				case $yn in
+					yes | y | YES | Y )
+						echo "Installing software..."
+						exit 0;
+						;;
+					no | n | NO | N )
+						echo "Installation cancelled."
+						exit 1;
+						;;
+					* )
+						echo "Invalid input. Please type 'yes' or 'no'."
+						;;
+				esac
+			done
+		else
+			exit 3;
+		fi
+	else
+		exit 3;
+	fi
+fi
+
+ST=/usr/src/linux-headers-`uname -r`/scripts/sign-file
+CERT=/var/lib/amd_pp_cert/certs
+
+mokutil --sb-state 2>&1 | grep "EFI variables are not"
+if [ $? -eq 0 ]; then
+	echo "# EFI variables are not supported on this system"
+	exit;
+fi
+
+if [ -f /etc/redhat-release ]; then
+ST=/usr/src/kernels/`uname -r`/scripts/sign-file
+fi
+
+if [ `id -u` -ne 0 ]; then
+    exit
+    echo "#"
+    echo "# ERROR:"
+    echo "#"
+    echo "# Signing certificates must be created as root."
+    echo "# Please rerun last command as root."
+    echo "#"
+fi
+
+if [ ! -d "$CERT" ]; then
+    mkdir -pm 0700 $CERT
+fi
+
+if [ ! -f $CERT/x509.genkey ]; then
+    echo "[ req ]" > $CERT/x509.genkey
+    echo "default_bits = 4096" >> $CERT/x509.genkey
+    echo "distinguished_name = req_distinguished_name" >> $CERT/x509.genkey
+    echo "prompt = no" >> $CERT/x509.genkey
+    echo "string_mask = utf8only" >> $CERT/x509.genkey
+    echo "x509_extensions = myexts" >> $CERT/x509.genkey
+    echo "" >> $CERT/x509.genkey
+    echo "[ req_distinguished_name ]" >> $CERT/x509.genkey
+    echo "O = Local Machine Owner" >> $CERT/x509.genkey
+    echo "CN = Build time autogenerated module signing key for AMDPP module" >> $CERT/x509.genkey
+    echo "emailAddress = root@localhost" >> $CERT/x509.genkey
+    echo "" >> $CERT/x509.genkey
+    echo "[ myexts ]" >> $CERT/x509.genkey
+    echo "basicConstraints=critical,CA:FALSE" >> $CERT/x509.genkey
+    echo "keyUsage=digitalSignature" >> $CERT/x509.genkey
+    echo "subjectKeyIdentifier=hash" >> $CERT/x509.genkey
+    echo "authorityKeyIdentifier=keyid" >> $CERT/x509.genkey
+fi
+
+if [ ! -f $CERT/module_signing_key.der ]; then
+    message1="****************************************************
+# Tip: When prompted for \"Password\",
+# create a new password for installing the signed certificate.
+# This password may be required when system reboots in order
+# to enroll the signing certificate in the BIOS key table.
+# DO NOT use your login password or root password!"
+    printf "$message1\n"
+    openssl req -new -x509 -batch -config $CERT/x509.genkey \
+	-outform DEV -keyout $CERT/module_signing_key.priv \
+	-out $CERT/module_signing_key.der -days 3650 -nodes -sha256
+
+    if [ $? -ne 0 ]; then
+	echo "Key Generation Failed"
+	/usr/bin/rm $CERT/module_signing_key.der
+    else
+	mokutil --import $CERT/module_signing_key.der
+        if [ $? -ne 0 ]; then
+                echo "Import key Failed"
+		/usr/bin/rm $CERT/module_signing_key.der
+        fi
+    fi
+fi
+
+$ST sha256 $CERT/module_signing_key.priv $CERT/module_signing_key.der $MN
diff --git a/drivers/powerprofiler/AMDPowerProfilerVersion b/drivers/powerprofiler/AMDPowerProfilerVersion
new file mode 100644
index 000000000000..9a62de225f08
--- /dev/null
+++ b/drivers/powerprofiler/AMDPowerProfilerVersion
@@ -0,0 +1 @@
+10.5
diff --git a/drivers/powerprofiler/Kconfig b/drivers/powerprofiler/Kconfig
new file mode 100644
index 000000000000..36447d05f36f
--- /dev/null
+++ b/drivers/powerprofiler/Kconfig
@@ -0,0 +1,19 @@
+# SPDX-License-Identifier: GPL-2.0-only
+#
+# TI's shared transport line discipline and the protocol
+# drivers (BT, FM and GPS)
+#
+
+menuconfig AMD_POWER_PROFILER
+  bool "AMD Power Profiler driver"
+  help
+    AMD Power Profiler tool
+     
+	  If you want this code to be compiled in, say Y here.
+
+if AMD_POWER_PROFILER
+# Client driver configurations go here.
+config POWER_PROFILER_CORE
+	tristate "AMD Power Profiler core Driver"
+  default m
+endif
diff --git a/drivers/powerprofiler/Makefile b/drivers/powerprofiler/Makefile
new file mode 100644
index 000000000000..812aa6f5455a
--- /dev/null
+++ b/drivers/powerprofiler/Makefile
@@ -0,0 +1,160 @@
+# Copyright (c) 2015 Advanced Micro Devices, Inc.  All Rights Reserved
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in
+# all copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+# THE SOFTWARE.
+ 
+# Module Name
+MODULE_NAME=AMDPowerProfiler
+# Module version
+MODULE_VERSION=$(shell cat AMDPowerProfilerVersion)
+
+# Module after compilation
+MODULE_NAME_KO=$(MODULE_NAME).ko
+
+# check is module inserted
+MODPROBE_OUTPUT=$(shell lsmod | grep $(MODULE_NAME))
+
+# check pcore dkms status
+PCORE_DKMS_STATUS=$(shell dkms status | grep $(MODULE_NAME) | grep $(MODULE_VERSION))
+
+# Compilation flags
+EXTRA_CFLAGS=-I$(PWD)/inc -mpopcnt -DKERNEL_MODULE
+# Compilation flags with debug enabled
+#EXTRA_CFLAGS=-I$(PWD)/inc -I$(PWD)/../inc -DKERNEL_MODULE -g -DDEBUG -mpopcnt
+
+subdir-ccflags-y += -I$(srctree)/$(src)/inc/
+# DKMS path
+PCORE_DKMS_PATH=/usr/src/$(MODULE_NAME)-$(MODULE_VERSION)
+
+# Kernel Version
+ifeq ($(KERNEL_VERSION),)
+KERNEL_VERSION=$(shell uname -r)
+endif
+
+# GCC 9 release extends the -Wmissing-attributes warnings(enabled by -Wall) 
+# due to which the module aliases pointing to _init and _exit is failing
+# “-Wno-missing-attributes” is added for GCC version >= 9.0 and kernel version <= 5.00
+G_VERSION=9
+K_VERSION=5
+KERNEL_MAJOR_VERSION=$(shell uname -r | cut -f1 -d.)
+GCCVERSION = $(shell gcc -dumpversion | cut -f1 -d.)
+ifeq ($(G_VERSION),$(firstword $(sort $(GCCVERSION) $(G_VERSION))))
+	ifeq ($(K_VERSION),$(lastword $(sort $(KERNEL_MAJOR_VERSION) $(K_VERSION))))
+		EXTRA_CFLAGS +=-Wno-missing-attributes
+	endif
+endif
+
+# Module needs to be compiled
+obj-m += $(MODULE_NAME).o
+
+# Fill object file names
+${MODULE_NAME}-objs :=  src/PmcDataBufferOps.o src/PmcProcessConfig.o src/PmcTimerConfig.o src/PmcUtils.o src/PwrAccessPmcData.o src/PwrCommonConfig.o src/PwrCommonHelper.o src/PwrCounterAccessInterface.o src/PwrDriverUtils.o src/PwrOsPrimitives.o src/PwrProfDebugHelper.o src/PwrProfEntry.o src/PwrProfModule.o src/PwrProfSharedMemOps.o src/PwrProfTimer.o src/PwrProfTimerHelper.o src/PwrSampleCollect.o
+
+# make
+all:
+	@chmod a+x ./AMDPPcert.sh
+	@./AMDPPcert.sh 0 1; echo $$? > $(PWD)/sign_status;
+	@SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 1 ]; then \
+			exit 1; \
+		fi
+	@make -C /lib/modules/$(KERNEL_VERSION)/build M=$(PWD) $(MAKE_OPTS) EXTRA_CFLAGS="$(EXTRA_CFLAGS)" modules
+	@SIGSTATUS3=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS3 -eq 0 ]; then \
+			./AMDPPcert.sh 1 $(MODULE_NAME_KO); \
+		fi
+
+# make clean
+clean:
+	make -C /lib/modules/$(KERNEL_VERSION)/build M=$(PWD) $(MAKE_OPTS) EXTRA_CFLAGS="$(EXTRA_CFLAGS)" clean
+
+# make install
+install:
+	@mkdir -p /lib/modules/`uname -r`/kernel/drivers/extra
+	@rm  -f /lib/modules/`uname -r`/kernel/drivers/extra/$(MODULE_NAME_KO)
+	@cp $(MODULE_NAME_KO) /lib/modules/`uname -r`/kernel/drivers/extra/
+	@depmod -a
+	@if [ ! -z "$(MODPROBE_OUTPUT)" ]; then \
+		echo "Uninstalling AMDPowerProfiler Linux kernel module.";\
+		rmmod $(MODULE_NAME);\
+	fi
+	@modprobe $(MODULE_NAME) 2> $(PWD)/sign_status1; \
+		cat $(PWD)/sign_status1 | grep "Key was rejected by service"; \
+		echo $$? > $(PWD)/sign_status; SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 0 ]; then \
+			echo "ERROR: Secure Boot enabled, correct key is not yet enrolled in BIOS key table"; \
+			exit 1; \
+		else \
+			cat $(PWD)/sign_status1; \
+		fi
+# make dkms
+dkms:
+	@chmod a+x ./AMDPPcert.sh
+	@./AMDPPcert.sh 0 1; echo $$? > $(PWD)/sign_status;
+	@SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 1 ]; then \
+			exit 1; \
+		fi
+	@echo "Installing AMDPowerProfiler Linux kernel module version $(MODULE_VERSION)."
+	@sed -i -e '/^PACKAGE_VERSION=/ s/=.*/=\"$(MODULE_VERSION)\"/' dkms.conf
+	@dkms add -m $(MODULE_NAME) -v $(MODULE_VERSION) -q
+	@SIGSTATUS2=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS2 -eq 0 ] && [ -f /etc/dkms/framework.conf ]; then \
+		sed -i '/do_signing/!{n; /sign modules during build/ s/^/do_signing=0\n/}' /etc/dkms/framework.conf; \
+		fi
+	@dkms build -m $(MODULE_NAME) -v $(MODULE_VERSION)
+	@dkms install --force -m $(MODULE_NAME) -v $(MODULE_VERSION) -q
+	@SIGSTATUS3=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS3 -eq 0 ]; then \
+			if [ -f /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO).xz ]; then \
+				xz -d /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO).xz; \
+				rm -rf /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO).xz; \
+				./AMDPPcert.sh 1 /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO); \
+				xz -z /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO); \
+			elif [ -f /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO) ]; then \
+				./AMDPPcert.sh 1 /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO); \
+			else \
+				./AMDPPcert.sh 1 /lib/modules/`uname -r`/updates/dkms/$(MODULE_NAME_KO); \
+			fi \
+		fi
+	@echo "Loading AMDPowerProfiler Linux kernel module."
+	@modprobe $(MODULE_NAME) 2> $(PWD)/sign_status1; \
+		cat $(PWD)/sign_status1 | grep "Key was rejected by service"; \
+		echo $$? > $(PWD)/sign_status; SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 0 ]; then \
+			echo "ERROR: Secure Boot enabled, correct key is not yet enrolled in BIOS key table"; \
+			exit 1; \
+		else \
+			cat $(PWD)/sign_status1; \
+		fi
+	
+# make cleandkms
+cleandkms:
+	@if [ ! -z "$(MODPROBE_OUTPUT)" ]; then \
+		echo "Uninstalling AMDPowerProfiler Linux kernel module.";\
+		rmmod $(MODULE_NAME);\
+	fi
+	@if [ ! -z "$(PCORE_DKMS_STATUS)" ]; then \
+	    echo "Removing AMDPowerProfiler Linux kernel module.";\
+	    dkms remove -m $(MODULE_NAME) -v $(MODULE_VERSION) --all -q;\
+	fi
+
+# make rebuilddkms
+rebuilddkms:
+	$(MAKE) cleandkms; \
+	$(MAKE) dkms
diff --git a/drivers/powerprofiler/Makefile.bak b/drivers/powerprofiler/Makefile.bak
new file mode 100644
index 000000000000..74362282790e
--- /dev/null
+++ b/drivers/powerprofiler/Makefile.bak
@@ -0,0 +1,160 @@
+# Copyright (c) 2015 Advanced Micro Devices, Inc.  All Rights Reserved
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in
+# all copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+# THE SOFTWARE.
+ 
+# Module Name
+MODULE_NAME=AMDPowerProfiler
+# Module version
+MODULE_VERSION=$(shell cat AMDPowerProfilerVersion)
+
+# Module after compilation
+MODULE_NAME_KO=$(MODULE_NAME).ko
+
+# check is module inserted
+MODPROBE_OUTPUT=$(shell lsmod | grep $(MODULE_NAME))
+
+# check pcore dkms status
+PCORE_DKMS_STATUS=$(shell dkms status | grep $(MODULE_NAME) | grep $(MODULE_VERSION))
+PWD := $(shell pwd)
+# Compilation flags
+EXTRA_CFLAGS=-I$(src)/inc -I$(PWD)/src -mpopcnt -DKERNEL_MODULE
+# Compilation flags with debug enabled
+#EXTRA_CFLAGS=-I$(PWD)/inc -I$(PWD)/../inc -DKERNEL_MODULE -g -DDEBUG -mpopcnt
+
+subdir-ccflags-y += -I$(srctree)/$(src)/inc/ -I$(srctree)/$(src)/../inc
+# DKMS path
+PCORE_DKMS_PATH=/usr/src/$(MODULE_NAME)-$(MODULE_VERSION)
+
+# Kernel Version
+ifeq ($(KERNEL_VERSION),)
+KERNEL_VERSION=$(shell uname -r)
+endif
+
+# GCC 9 release extends the -Wmissing-attributes warnings(enabled by -Wall) 
+# due to which the module aliases pointing to _init and _exit is failing
+# “-Wno-missing-attributes” is added for GCC version >= 9.0 and kernel version <= 5.00
+G_VERSION=9
+K_VERSION=5
+KERNEL_MAJOR_VERSION=$(shell uname -r | cut -f1 -d.)
+GCCVERSION = $(shell gcc -dumpversion | cut -f1 -d.)
+ifeq ($(G_VERSION),$(firstword $(sort $(GCCVERSION) $(G_VERSION))))
+	ifeq ($(K_VERSION),$(lastword $(sort $(KERNEL_MAJOR_VERSION) $(K_VERSION))))
+		EXTRA_CFLAGS +=-Wno-missing-attributes
+	endif
+endif
+
+# Module needs to be compiled
+obj-m += $(MODULE_NAME).o
+
+# Fill object file names
+${MODULE_NAME}-objs :=  src/PmcDataBufferOps.o src/PmcProcessConfig.o src/PmcTimerConfig.o src/PmcUtils.o src/PwrAccessPmcData.o src/PwrCommonConfig.o src/PwrCommonHelper.o src/PwrCounterAccessInterface.o src/PwrDriverUtils.o src/PwrOsPrimitives.o src/PwrProfDebugHelper.o src/PwrProfEntry.o src/PwrProfModule.o src/PwrProfSharedMemOps.o src/PwrProfTimer.o src/PwrProfTimerHelper.o src/PwrSampleCollect.o
+
+# make
+all:
+	@chmod a+x ./AMDPPcert.sh
+	@./AMDPPcert.sh 0 1; echo $$? > $(PWD)/sign_status;
+	@SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 1 ]; then \
+			exit 1; \
+		fi
+	@make -C /lib/modules/$(KERNEL_VERSION)/build M=$(PWD) $(MAKE_OPTS) EXTRA_CFLAGS="$(EXTRA_CFLAGS)" modules
+	@SIGSTATUS3=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS3 -eq 0 ]; then \
+			./AMDPPcert.sh 1 $(MODULE_NAME_KO); \
+		fi
+
+# make clean
+clean:
+	make -C /lib/modules/$(KERNEL_VERSION)/build M=$(PWD) $(MAKE_OPTS) EXTRA_CFLAGS="$(EXTRA_CFLAGS)" clean
+
+# make install
+install:
+	@mkdir -p /lib/modules/`uname -r`/kernel/drivers/extra
+	@rm  -f /lib/modules/`uname -r`/kernel/drivers/extra/$(MODULE_NAME_KO)
+	@cp $(MODULE_NAME_KO) /lib/modules/`uname -r`/kernel/drivers/extra/
+	@depmod -a
+	@if [ ! -z "$(MODPROBE_OUTPUT)" ]; then \
+		echo "Uninstalling AMDPowerProfiler Linux kernel module.";\
+		rmmod $(MODULE_NAME);\
+	fi
+	@modprobe $(MODULE_NAME) 2> $(PWD)/sign_status1; \
+		cat $(PWD)/sign_status1 | grep "Key was rejected by service"; \
+		echo $$? > $(PWD)/sign_status; SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 0 ]; then \
+			echo "ERROR: Secure Boot enabled, correct key is not yet enrolled in BIOS key table"; \
+			exit 1; \
+		else \
+			cat $(PWD)/sign_status1; \
+		fi
+# make dkms
+dkms:
+	@chmod a+x ./AMDPPcert.sh
+	@./AMDPPcert.sh 0 1; echo $$? > $(PWD)/sign_status;
+	@SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 1 ]; then \
+			exit 1; \
+		fi
+	@echo "Installing AMDPowerProfiler Linux kernel module version $(MODULE_VERSION)."
+	@sed -i -e '/^PACKAGE_VERSION=/ s/=.*/=\"$(MODULE_VERSION)\"/' dkms.conf
+	@dkms add -m $(MODULE_NAME) -v $(MODULE_VERSION) -q
+	@SIGSTATUS2=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS2 -eq 0 ] && [ -f /etc/dkms/framework.conf ]; then \
+		sed -i '/do_signing/!{n; /sign modules during build/ s/^/do_signing=0\n/}' /etc/dkms/framework.conf; \
+		fi
+	@dkms build -m $(MODULE_NAME) -v $(MODULE_VERSION)
+	@dkms install --force -m $(MODULE_NAME) -v $(MODULE_VERSION) -q
+	@SIGSTATUS3=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS3 -eq 0 ]; then \
+			if [ -f /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO).xz ]; then \
+				xz -d /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO).xz; \
+				rm -rf /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO).xz; \
+				./AMDPPcert.sh 1 /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO); \
+				xz -z /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO); \
+			elif [ -f /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO) ]; then \
+				./AMDPPcert.sh 1 /lib/modules/`uname -r`/extra/$(MODULE_NAME_KO); \
+			else \
+				./AMDPPcert.sh 1 /lib/modules/`uname -r`/updates/dkms/$(MODULE_NAME_KO); \
+			fi \
+		fi
+	@echo "Loading AMDPowerProfiler Linux kernel module."
+	@modprobe $(MODULE_NAME) 2> $(PWD)/sign_status1; \
+		cat $(PWD)/sign_status1 | grep "Key was rejected by service"; \
+		echo $$? > $(PWD)/sign_status; SIGSTATUS1=`cat $(PWD)/sign_status | tr -d '\n'`; \
+                if [ $$SIGSTATUS1 -eq 0 ]; then \
+			echo "ERROR: Secure Boot enabled, correct key is not yet enrolled in BIOS key table"; \
+			exit 1; \
+		else \
+			cat $(PWD)/sign_status1; \
+		fi
+	
+# make cleandkms
+cleandkms:
+	@if [ ! -z "$(MODPROBE_OUTPUT)" ]; then \
+		echo "Uninstalling AMDPowerProfiler Linux kernel module.";\
+		rmmod $(MODULE_NAME);\
+	fi
+	@if [ ! -z "$(PCORE_DKMS_STATUS)" ]; then \
+	    echo "Removing AMDPowerProfiler Linux kernel module.";\
+	    dkms remove -m $(MODULE_NAME) -v $(MODULE_VERSION) --all -q;\
+	fi
+
+# make rebuilddkms
+rebuilddkms:
+	$(MAKE) cleandkms; \
+	$(MAKE) dkms
diff --git a/drivers/powerprofiler/dkms.conf b/drivers/powerprofiler/dkms.conf
new file mode 100644
index 000000000000..1c82f56a61f7
--- /dev/null
+++ b/drivers/powerprofiler/dkms.conf
@@ -0,0 +1,6 @@
+PACKAGE_NAME="AMDPowerProfiler"
+PACKAGE_VERSION="9.1"
+AUTOINSTALL="yes"
+
+BUILT_MODULE_NAME[0]="AMDPowerProfiler"
+DEST_MODULE_LOCATION[0]="/kernel/drivers/extra"
diff --git a/drivers/powerprofiler/inc/MsrList.h b/drivers/powerprofiler/inc/MsrList.h
new file mode 100644
index 000000000000..62e62c0032fe
--- /dev/null
+++ b/drivers/powerprofiler/inc/MsrList.h
@@ -0,0 +1,67 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file MsrList.h
+///
+//==================================================================================
+/*Core PMC*/
+{ 0xC0010200, 0xC001020B ,~0ULL },
+
+/*L3PMC*/
+{ 0xC0010230, 0xC001023B , ~0ULL },
+
+/*DF PMC*/
+{ 0xC0010240, 0xC0010247 , ~0ULL },
+
+/*TSCClock*/
+{ 0x00000010, 0x00000010, 0ULL },
+
+/*MPERFReadOnly*/
+{ 0xC00000E7, 0xC00000E7 , 0ULL },
+
+/*APERFReadOnly*/
+{ 0xC00000E8, 0xC00000E8, 0ULL },
+
+/*IRPERFReadOnly*/
+{ 0xC00000E9, 0xC00000E9, 0ULL },
+
+/*MPERF*/
+{ 0x000000E7, 0x000000E7, 0ULL },
+
+/*APERF*/
+{ 0x000000E8, 0x000000E8, 0ULL },
+
+/*HW Config*/
+{ 0xC0010015, 0xC0010015, 0x40000000ULL },
+
+/*PState Status*/
+{ 0xC0010063, 0xC0010063, 0ULL },
+
+/*PStateDef*/
+{ 0xC0010064, 0xC001006B , 0ULL },
+
+/*RAPLPwrUnit*/
+{ 0xC0010299, 0xC0010299 , 0ULL },
+
+/*CoreEnergyStat*/
+{ 0xC001029A, 0xC001029A, 0ULL },
+
+/*PkgEnergyStat*/
+{ 0xC001029B, 0xC001029B, 0ULL},
+
+/*Legacy Core PMC*/
+{ 0xC0010000, 0xC0010007, ~0ULL },
+
+/*CState Config to enable IBS in Zen2*/
+{ 0xC0010296, 0xC0010296, 0x00404040ULL },
+
+/*CPUID Extended Features(to enable IBS in Zen2)*/
+{ 0xC0011005, 0xC0011005, 0x040000000000ULL },
+
+/*LS Config(to enable IBS in Zen2)*/
+{ 0xC0011020, 0xC0011020, 0x0040000000000000ULL },
+
+/*DE Config(to enable IBS in Zen2)*/
+{ 0xC0011029, 0xC0011029, 0x00080000ULL }
+
diff --git a/drivers/powerprofiler/inc/MsrListZen4.h b/drivers/powerprofiler/inc/MsrListZen4.h
new file mode 100644
index 000000000000..1a65ad4aabe9
--- /dev/null
+++ b/drivers/powerprofiler/inc/MsrListZen4.h
@@ -0,0 +1,55 @@
+//==================================================================================
+// Copyright (c) 2022 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file MsrListZen4.h
+///
+//==================================================================================
+/*Core PMC*/
+{ 0xC0010200, 0xC001020B ,~0ULL },
+
+/*L3PMC*/
+{ 0xC0010230, 0xC001023B , ~0ULL },
+
+/*DF PMC*/
+{ 0xC0010240, 0xC001025F , ~0ULL },
+
+/*TSCClock*/
+{ 0x00000010, 0x00000010, 0ULL },
+
+/*MPERFReadOnly*/
+{ 0xC00000E7, 0xC00000E7 , 0ULL },
+
+/*APERFReadOnly*/
+{ 0xC00000E8, 0xC00000E8, 0ULL },
+
+/*IRPERFReadOnly*/
+{ 0xC00000E9, 0xC00000E9, 0ULL },
+
+/*MPERF*/
+{ 0x000000E7, 0x000000E7, 0ULL },
+
+/*APERF*/
+{ 0x000000E8, 0x000000E8, 0ULL },
+
+/*HW Config*/
+{ 0xC0010015, 0xC0010015, 0x40000000ULL },
+
+/*PState Status*/
+{ 0xC0010063, 0xC0010063, 0ULL },
+
+/*PStateDef*/
+{ 0xC0010064, 0xC001006B , 0ULL },
+
+/*RAPLPwrUnit*/
+{ 0xC0010299, 0xC0010299 , 0ULL },
+
+/*CoreEnergyStat*/
+{ 0xC001029A, 0xC001029A, 0ULL },
+
+/*PkgEnergyStat*/
+{ 0xC001029B, 0xC001029B, 0ULL},
+
+/*Legacy Core PMC*/
+{ 0xC0010000, 0xC0010007, ~0ULL }
+
diff --git a/drivers/powerprofiler/inc/PmcCommonDataTypes.h b/drivers/powerprofiler/inc/PmcCommonDataTypes.h
new file mode 100644
index 000000000000..557664ef3463
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcCommonDataTypes.h
@@ -0,0 +1,203 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcCommonDataTypes.h
+///
+//==================================================================================
+#pragma once
+
+#include <PmcTypes.h>
+#include <PmcOsTypes.h>
+
+#if defined(_WIN32)
+    #include <PwrProfInternal.h>
+#endif
+
+typedef struct
+{
+    /* Control value for PMC CTL Msr */
+    volatile uint64_t m_controlValue;
+    /* Count value for pre loading PMC COUNT Msr
+     * Saved count value when config is unloaded from counter*/
+    volatile uint64_t m_counterValue;
+} PmcConfig;
+
+/* PMC config group attributes */
+typedef enum
+{
+    PMC_CONFIG_GROUP_ATTR_TIMESTAMP = 0x1,
+    PMC_CONFIG_GROUP_ATTR_IRPERF    = 0x2,
+    PMC_CONFIG_GROUP_ATTR_MPERF     = 0x4,
+    PMC_CONFIG_GROUP_ATTR_APERF     = 0x8,
+    PMC_CONFIG_GROUP_ATTR_FCLK      = 0x10,
+    PMC_CONFIG_GROUP_ATTR_MAX,
+} PmcConfigGroupAttrs;
+
+typedef enum
+{
+    PMC_CLIENT_STATE_UNKNOWN,
+    PMC_CLIENT_STATE_INIT,
+    PMC_CLIENT_STATE_CONFIGURED,
+    PMC_CLIENT_STATE_RUNNING,
+    PMC_CLIENT_STATE_STOP_INITIATED,
+    PMC_CLIENT_STATE_STOPPED
+}PmcClientState;
+/* ToDo: Add group pmc type here? */
+typedef struct PmcConfigGroup
+{
+    /* Pointer to next configuration group in circular linked list */
+    struct PmcConfigGroup* m_pNext;
+    /* Number of valid pmc configurations in the array */
+    uint16_t        m_pmcConfigCnt;
+    /* PMC configuration array
+     * (Size of array is maximum available
+     * counters for PMC type) */
+    PmcConfig*      m_pPmcConfigArray;
+    /* Timestamp when this configuration was loaded */
+    uint64_t        m_loadTime;
+    /* Duration (delta time) for which this configuration
+     * last resided on the counters */
+    uint64_t        m_deltaTime;
+    /* Duration (delta time) for which this configuration
+     * last resided on the counters per DF Clk */
+    uint64_t        m_dfClkDelta;
+    uint64_t        m_dfClk;
+    /* Configuration group attributes (PmcConfigGroupAttrs) */
+    uint64_t        m_pmcConfigGroupAttrs;
+    /* Configuration group id - Unique id for for each pmc
+     * configuration group */
+    uint64_t        m_pmcConfigGroupId;
+    /* IRPerf */
+    uint64_t        m_irPerfDelta;
+    uint64_t        m_irPerf;
+    /* MPerf */
+    uint64_t        m_mPerfDelta;
+    uint64_t        m_mPerf;
+    /* APerf */
+    uint64_t        m_aPerfDelta;
+    uint64_t        m_aPerf;
+    /* UMC Counter values*/
+    uint32_t        m_umcMsrCount;
+    uint64_t*       m_pUmcMsrCountArray;
+} PmcConfigGroup;
+
+typedef struct
+{
+    /* Core id for this core context */
+    uint16_t m_coreId;
+
+    /* Socket id for this core context */
+    uint16_t m_socketId;
+
+    /* Circular linked list of all PMC configuration groups
+     * for each PMC type */
+    PmcConfigGroup* m_pPmcConfigGroupArray[PMC_PMU_MAX];
+
+    /* Number of PMC configuration groups for each PMC type.
+     * TODO: Duplicated here for ease of access. Check if we
+     * can be rid of it. */
+    uint16_t m_pmcConfigGroupCnt[PMC_PMU_MAX];
+
+    /* Total PMC configs for all group */
+    uint16_t m_totalPmcConfigGroupCnt;
+
+    /* Timer configuration */
+    PmcTimerConfig* m_pTimerConfig;
+    /* Sampling counter is decremented every timer interrupt
+     * and a sample collection is triggered when it is zero.
+     * After, it is reset to m_samplingCount. */
+    uint16_t m_currSamplingCounter[PMC_PMU_MAX];
+
+    /* Data buffer context for each PMC type */
+    PmcDataBufferContext* m_pDataBufferContext[PMC_PMU_MAX];
+
+    /* Reset counter values after sampling */
+    // TODO: Remove if unused.
+    bool m_resetAfterSampling;
+
+    /* Force reset PMCs before collection. Used by AMDuProfSys*/
+    bool m_resetPmc;
+
+    /* Dropped sample count. */
+    uint32_t m_droppedSampleCount[PMC_PMU_MAX];
+
+    /* Delta time between logged samples. */
+    uint64_t m_timeEnabled[PMC_PMU_MAX];
+    uint64_t m_timeEnabledBegin[PMC_PMU_MAX];
+
+    // Availability mask indicating if counter is available for configuration
+    uint32_t m_availabilityMask[PMC_PMU_MAX];
+
+    /* UMC sample record size */
+    uint32_t m_umcSampleRecordSize;
+    uint32_t m_umcCount;
+
+#if defined (_WIN32)
+    KEVENT m_event;
+#endif
+
+} CoreContext;
+
+typedef struct
+{
+    uint32_t m_clientId;
+
+    /* Core Mask array for each PMC type
+     * Array of pointers to core mask array
+     * of size CORE_MASK_ARRAY_SIZE */
+    uint64_t* m_pPmcCoreMaskArray[PMC_PMU_MAX];
+
+    /* UMC mask */
+    uint32_t  m_umcMaskArraySize;
+    uint32_t  m_umcMaskArray[PMC_MAX_SOCKET_COUNT];
+    uint32_t  m_firstCore[PMC_MAX_SOCKET_COUNT];
+
+    /* Multiplexing interval in ms */
+    uint64_t m_muxInterval;
+    /* Log interval in ms */
+    uint64_t m_logInterval;
+    /* Timer interval - Interval used for timer interrupt in ms */
+    uint64_t m_timerInterval;
+    /* Data buffer size. Must be a multiple of 2^x * (page size) */
+    uint32_t m_dataBufferSize[PMC_PMU_MAX];
+    /* Data buffer threshold (Number of bytes after which to wake
+     * up readers). Must be a multiple of page size. */
+    uint32_t m_dataBufferThreshold[PMC_PMU_MAX];
+
+    /* Sample record size for each PMC type.
+     * Required to reserve space in buffer */
+    uint32_t m_sampleRecordSize[PMC_PMU_MAX];
+    /* Total number of valid PMC configurations
+     * for each PMC type. Required for sample record
+     * size calculation. */
+    uint16_t m_totalPmcConfigCnt[PMC_PMU_MAX];
+    uint16_t m_totalPmcAttrCnt[PMC_PMU_MAX];
+
+    /* Number of PMC configuration groups for each PMC type. */
+    uint16_t m_pmcConfigGroupCnt[PMC_PMU_MAX];
+
+    /* Sampling count for each pmc type.
+     * Number of timer interrupts required
+     * to trigger sampling. */
+    uint16_t m_samplingCount[PMC_PMU_MAX];
+
+    /* Is multiplexing required for any of the pmc types? */
+    bool m_multiplex;
+
+    /* Windows specific field.
+     * Buffer fill count: indicates the number of per core/ccx/socket
+     * buffers with available chunks. */
+    volatile long m_bufferFillCount[PMC_PMU_MAX];
+    /* Buffer fill max count: Max value of m_bufferFillCount after
+     * driver sets event. */
+    long m_bufferMaxFillCount[PMC_PMU_MAX];
+
+    CoreContext* m_pCoreContext;
+
+    PmcClientState m_clientState;
+#if defined(_WIN32)
+    PPWRPROF_DEV_EXTENSION m_pDevExt;
+#endif
+
+} ClientContext;
diff --git a/drivers/powerprofiler/inc/PmcDataBuffer.h b/drivers/powerprofiler/inc/PmcDataBuffer.h
new file mode 100644
index 000000000000..a780586b14c0
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcDataBuffer.h
@@ -0,0 +1,29 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcDataBuffer.h
+///
+//==================================================================================
+#pragma once
+
+/* Linux specific header shared by Backend
+ * and Driver for buffer management. */
+
+/* Note: Number of pages should be a power of 2 */
+/* TODO: Make buffer size configurable?
+ * Get page size from OsPrimitive? */
+#define DATA_BUFFER_PAGE_SIZE   4096
+#define DATA_BUFFER_PAGES       2
+#define DATA_BUFFER_SIZE        DATA_BUFFER_PAGES * DATA_BUFFER_PAGE_SIZE
+
+/* TODO: This should not take more than 8 bytes
+ * Force alignment? */
+typedef struct
+{
+    uint64_t m_dirty : 1;
+    /* Size (bytes) of data occupied in chunk
+     * (excluding meta data) */
+    uint64_t m_size : 20;
+    uint64_t m_reserved : 43;
+} PmcBufferMetaData;
diff --git a/drivers/powerprofiler/inc/PmcDataBufferOps.h b/drivers/powerprofiler/inc/PmcDataBufferOps.h
new file mode 100644
index 000000000000..60dfa2176af5
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcDataBufferOps.h
@@ -0,0 +1,23 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcDataBufferOps.h
+///
+//==================================================================================
+#pragma once
+
+#include <PmcInterface.h>
+#include <PmcCommonDataTypes.h>
+
+void InitDataBufferWaitQueue(PmcDataBufferContext* pDataBufferCtx);
+void NotifyPendingRead(PmcDataBufferContext* pDataBufferCtx);
+
+int _CreatePmcFileDescriptors(ClientContext *pClientCtx,
+                              PmcPmuType type,
+                              uint64_t* pCoreMaskArray,
+                              int* pFdArray,
+                              uint32_t *pFdArrayIdx);
+
+int CreatePmcFileDescriptors(CountModeProfileConfig* pConfig,
+                             ClientContext* pClientContext);
diff --git a/drivers/powerprofiler/inc/PmcInterface.h b/drivers/powerprofiler/inc/PmcInterface.h
new file mode 100644
index 000000000000..2c6d232ca4a9
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcInterface.h
@@ -0,0 +1,187 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcInterface.h
+///
+//==================================================================================
+#pragma once
+
+#include "PmcTypes.h"
+
+#define INVALID_CLIENT_ID       0xffffffff
+#define PMC_CLIENT_ID           0x1
+
+// Maximum cores 16*64 (1024)
+#define PMC_CORE_MASK_ARRAY_SIZE    16
+#define PMC_CORE_MASK_BIT_WIDTH     64
+#define PMC_MAX_SUPPORTED_CORES     (PMC_CORE_MASK_ARRAY_SIZE * PMC_CORE_MASK_BIT_WIDTH)
+
+// Max fd should account for the following:
+// Max per core fd
+// Max per l3 complex fd
+// Max per data fabric fd
+#define PMC_FD_ARRAY_SIZE       1024
+
+#define MAX_CORE_PMC_COUNTERS   8 // 6 public and 2 debug counters
+#define MAX_L3_PMC_COUNTERS     6 // 6 public and 0 debug counters
+#define MAX_DF_PMC_COUNTERS     16 // 16 counters (4 public and 4 debug counters on Zen3 and older models)
+#define MAX_UMC_PMC_COUNTERS    4 // 4 counters per UMC
+
+/*
+ * TODO: Should we compile an internal version of
+ * driver with these macros defined?
+ * or have a flags to enable/disable with backend
+ */
+
+#define PMC_IRPERF_MSR          0xC00000E9
+#define PMC_MPERF_MSR           0x000000E7
+#define PMC_RO_MPERF_MSR        0xC00000E7
+#define PMC_APERF_MSR           0x000000E8
+#define PMC_RO_APERF_MSR        0xC00000E8
+#define PMC_TSC_MSR             0x00000010
+
+#define PMC_CFG_ENABLE     (1ULL << 22)
+
+#define CORE_PMC_COUNT          6
+#define CORE_PMC_CFG_BASE_MSR   0xC0010200
+#define CORE_PMC_COUNT_OFFSET   0x1
+#define CORE_PMC_STRIDE         0x2
+
+#define CORE_PMC_CFG_MSR(i)     CORE_PMC_CFG_BASE_MSR + i * CORE_PMC_STRIDE
+#define CORE_PMC_COUNT_MSR(i)   CORE_PMC_CFG_MSR(i) + CORE_PMC_COUNT_OFFSET
+
+#define CHL3_PMC_COUNT          6
+#define CHL3_PMC_CFG_BASE_MSR   0xC0010230
+#define CHL3_PMC_COUNT_OFFSET   0x1
+#define CHL3_PMC_STRIDE         0x2
+
+#define CHL3_PMC_CFG_MSR(i)     CHL3_PMC_CFG_BASE_MSR + i * CHL3_PMC_STRIDE
+#define CHL3_PMC_COUNT_MSR(i)   CHL3_PMC_CFG_MSR(i) + CHL3_PMC_COUNT_OFFSET
+
+#define DF_PMC_COUNT            4
+#define DF_PMC_CFG_BASE_MSR     0xC0010240
+#define DF_PMC_COUNT_OFFSET     0x1
+#define DF_PMC_STRIDE           0x2
+
+#define DF_PMC_CFG_MSR(i)       DF_PMC_CFG_BASE_MSR + i * DF_PMC_STRIDE
+#define DF_PMC_COUNT_MSR(i)     DF_PMC_CFG_MSR(i) + DF_PMC_COUNT_OFFSET
+
+// Note: UMC MSRs are only valid for Zen4 and later
+#define UMC_PMC_COUNT           4
+#define UMC_PMC_CFG_BASE_MSR    0xC0010800
+#define UMC_PMC_COUNT_OFFSET    0x1
+#define UMC_PMC_STRIDE          0x2
+
+#define UMC_PMC_CFG_MSR(i)      UMC_PMC_CFG_BASE_MSR + i * UMC_PMC_STRIDE
+#define UMC_PMC_COUNT_MSR(i)    UMC_PMC_CFG_MSR(i) + UMC_PMC_COUNT_OFFSET
+
+#define CORE_PMC_DEBUG_COUNT            2
+#define CORE_PMC_DEBUG_CFG_BASE_MSR     0xC0010188
+#define CORE_PMC_DEBUG_COUNT_OFFSET     0x1
+#define CORE_PMC_DEBUG_STRIDE           0x2
+
+#define CORE_PMC_DEBUG_CFG_MSR(i)       CORE_PMC_DEBUG_CFG_BASE_MSR + i * CORE_PMC_DEBUG_STRIDE
+#define CORE_PMC_DEBUG_COUNT_MSR(i)     CORE_PMC_DEBUG_CFG_MSR(i) + CORE_PMC_DEBUG_COUNT_OFFSET
+
+#define DF_PMC_DEBUG_COUNT          4
+#define DF_PMC_DEBUG_CFG_BASE_MSR   0xC0010190
+#define DF_PMC_DEBUG_COUNT_OFFSET   0x1
+#define DF_PMC_DEBUG_STRIDE         0x2
+
+#define DF_PMC_DEBUG_CFG_MSR(i)         DF_PMC_DEBUG_CFG_BASE_MSR + i * DF_PMC_DEBUG_STRIDE
+#define DF_PMC_DEBUG_COUNT_MSR(i)       DF_PMC_DEBUG_CFG_MSR(i) + DF_PMC_DEBUG_COUNT_OFFSET
+
+#define CORE_PMC_MAX_COUNT          CORE_PMC_COUNT + CORE_PMC_DEUG_COUNT
+#define DF_PMC_MAX_COUNT            CORE_PMC_COUNT + CORE_PMC_DEUG_COUNT
+
+#define MUX_INTERVAL_DEFAULT        16   /* ms */
+#define LOG_INTERVAL_DEFAULT        1000 /* ms */
+
+typedef enum
+{
+    CLIENT_TYPE_INVALID,
+    CLIENT_TYPE_PMC,
+    CLIENT_TYPE_PWR_PROFILER,
+    CLIENT_TYPE_MAX,
+} ClientType;
+
+typedef enum
+{
+    GROUP_TYPE_INVALID = 0,
+    GROUP_TYPE_CORE_PMC,
+    GROUP_TYPE_L3_PMC,
+    GROUP_TYPE_DF_PMC,
+    GROUP_TYPE_UMC_PMC,
+    GROUP_TYPE_MAX,
+} GroupType;
+
+typedef enum
+{
+    GROUP_ATTR_INVALID      = 0,
+    /* Collect TSC for group */
+    GROUP_ATTR_TIMESTAMP    =  0x1,
+    /* Collect IRPerf MSR value for group */
+    GROUP_ATTR_IRPERF       =  0x2,
+    /* Collect MPerf MSR value for group */
+    GROUP_ATTR_MPERF        =  0x4,
+    /* Collect APerf MSR value for group */
+    GROUP_ATTR_APERF        =  0x8,
+    /* Collect FCLK for group */
+    GROUP_ATTR_FCLK         =  0x10,
+    GROUPT_ATTR_MAX
+
+} GroupAttributes;
+
+#define PMC_GROUP_ATTR_WIDTH    16
+
+typedef union
+{
+    struct
+    {
+        uint64_t m_groupType        :   8;
+        uint64_t m_groupConfigCount :   8;
+        uint64_t m_groupAttributes  :   16;
+        uint64_t m_groupId          :   32;
+
+    } m_header;
+
+    uint64_t m_hdr;
+
+} CountModeGroupHeader;
+
+typedef struct
+{
+    CountModeGroupHeader m_configHeader;
+
+    union
+    {
+        uint64_t m_corePmcConfigArray[MAX_CORE_PMC_COUNTERS];
+        uint64_t m_l3PmcConfigArray[MAX_L3_PMC_COUNTERS];
+        uint64_t m_dfPmcConfigArray[MAX_DF_PMC_COUNTERS];
+        uint64_t m_umcPmcConfigArray[MAX_UMC_PMC_COUNTERS];
+    } m_cfgArray;
+
+} CountModeGroupConfig;
+
+typedef struct
+{
+    uint32_t m_clientId;
+    uint32_t m_status;
+    uint64_t m_muxInterval;
+    uint64_t m_logInterval;
+    uint64_t m_corePmcCoreMaskArray[PMC_CORE_MASK_ARRAY_SIZE];
+    uint64_t m_l3PmcCoreMaskArray[PMC_CORE_MASK_ARRAY_SIZE];
+    uint64_t m_dfPmcCoreMaskArray[PMC_CORE_MASK_ARRAY_SIZE];
+    uint64_t m_umcPmcCoreMaskArray[PMC_CORE_MASK_ARRAY_SIZE];
+    uint32_t m_umcMask[PMC_MAX_SOCKET_COUNT];
+    uint32_t m_pmcPerUmc;
+    uint32_t m_dataBufferSize[PMC_PMU_MAX];
+    uint32_t m_dataBufferThreshold[PMC_PMU_MAX];
+#if defined (__linux__)
+    int      m_fdArray[PMC_FD_ARRAY_SIZE];
+#endif
+    uint32_t m_groupCount;
+    uint64_t m_pConfigArray;
+    bool m_resetPmc;
+} CountModeProfileConfig;
diff --git a/drivers/powerprofiler/inc/PmcOsTypes.h b/drivers/powerprofiler/inc/PmcOsTypes.h
new file mode 100644
index 000000000000..c0880a88e203
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcOsTypes.h
@@ -0,0 +1,47 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcOsTypes.h
+///
+//==================================================================================
+#pragma once
+
+#include <linux/types.h>
+#include <linux/wait.h>
+#include <linux/hrtimer.h>
+#include <linux/ktime.h>
+
+typedef struct
+{
+    struct hrtimer m_hrTimer;
+    ktime_t m_time;
+} PmcTimerConfig;
+
+typedef struct
+{
+    /* Core id of this per core buffer */
+    uint32_t m_coreId;
+    /* Pointer to buffer */
+    void *m_pBuffer;
+    /* Size of buffer (bytes) */
+    uint64_t m_bufferSize;
+    /* Offset for writing into the buffer */
+    uint32_t m_offset;
+    /* Chunk Size (Multiple of Page Size) */
+    uint32_t m_chunkSize;
+    /* Flag to indicate pending read notifications */
+    bool m_pendingRead;
+
+    /* Linux specific
+     * Wait queue for this buffer
+     * Readers waiting to read from this buffer
+     * add themselves to this queue using poll_wait()
+     * and are woken up once data is available. */
+    wait_queue_head_t m_bufferWaitQueue;
+    /* Poll status returned by PmcPoll() */
+    atomic_t m_pollStatus;
+    /* Count of mmap() calls */
+    atomic_t m_mmapCount;
+
+} PmcDataBufferContext;
diff --git a/drivers/powerprofiler/inc/PmcProcessConfig.h b/drivers/powerprofiler/inc/PmcProcessConfig.h
new file mode 100644
index 000000000000..fb8d1f823912
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcProcessConfig.h
@@ -0,0 +1,85 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcProcessConfig.h
+///
+//==================================================================================
+#pragma once
+
+#include <PmcInterface.h>
+#include <PmcCommonDataTypes.h>
+
+// TODO: Remove this now that we have a similar file for windows
+#if defined(__linux__)
+    #include <PmcDataBufferOps.h>
+#endif
+
+typedef struct GroupBuffer
+{
+    CountModeGroupConfig* m_pBuffer;
+    // Running group Idx
+    uint32_t m_idx;
+    // total number of groups across all IOCTL_COUNT_MODE_CONFIG_EXTND calls
+    uint32_t m_totalGroups;
+}GroupBuffer;
+
+int AddPmcConfigGroup(CoreContext* pCoreCtx,
+                      PmcPmuType type,
+                      PmcConfigGroup* pPmcConfigGroup);
+
+int AllocatePmcConfigGroup(PmcConfigGroup** ppPmcConfigGroup,
+                           uint64_t pmcConfigArray[],
+                           uint32_t pmcConfigCount,
+                           uint16_t maxPmcCnt,
+                           uint16_t groupAttrs,
+                           uint64_t groupId,
+                           uint32_t availabilityMask,
+                           uint32_t umcMask,
+                           PmcPmuType type);
+
+void FreePmcConfigGroup(ClientContext* pClientCtx);
+
+int AllocateCoreContext(ClientContext* pClientCtx);
+void FreeCoreContext(ClientContext* pClientCtx);
+
+int AllocateCoreMaskArray(ClientContext* pClientCtx);
+void FreeCoreMaskArray(ClientContext* pClientCtx);
+
+int AllocateDataBufferContext(ClientContext* pClientCtx);
+void FreeDataBufferContext(ClientContext* pClientCtx);
+
+int ProcessCountModeProfileConfig(ClientContext* pClientCtx,
+                                  CountModeProfileConfig* pConfig);
+
+int ReadPmcConfigGroup(PmcConfigGroup* pPmcConfigGroup, PmcPmuType type, uint32_t umcMask);
+int PmcSampleDataCallBack(CoreContext* pCoreCtx,
+                          PmcPmuType type,
+                          uint32_t recordSize);
+
+int MultiplexPmcConfigGroup(CoreContext* pCoreCtx, PmcPmuType type);
+void ResetPmcCounters(CoreContext* pCoreCtx, PmcPmuType type);
+void* PmcGetDataBuffer(PmcDataBufferContext* pCtx, uint64_t recordSize);
+int PmcCallBack(ClientContext* pClientCtx, CoreContext* pCoreCtx);
+void ResetPmcConfigGroup(CoreContext* pCoreCtx, PmcPmuType type);
+uint32_t GetMaxPmcCount(PmcPmuType type, uint16_t* pDebugPmcCnt);
+uint64_t GetDfClk(uint32_t coreId);
+int LoadPmcConfig(PmcConfigGroup* pPmcConfigGroup, PmcPmuType type, uint32_t umcCount, bool reset);
+void ClearPmcConfig(void* pCtx);
+uint64_t SetPmcConfigAttrs(uint8_t groupAttrs);
+void PmcFlushDataBuffer(void* pCtx);
+int PmcWriteSampleData(CoreContext* pCoreCtx, PmcPmuType type, char* pBuffer);
+int GetGroupAttrCount(uint8_t groupAttr);
+void GetPmcAvailabilityMask(void* pInfo);
+
+int AllocateClientContext(uint32_t clientId);
+void FreeClientContext(uint32_t clientId);
+
+int AllocateUmcMaskArray(ClientContext* pClientCtx);
+void FreeUmcMaskArray(ClientContext* pClientCtx);
+
+int PmcStartProfiler(void);
+int PmcStopProfiler(void);
+void PmcClearProfiler(void);
+int PmcPauseProfiler(void);
+int PmcResumeProfiler(void);
diff --git a/drivers/powerprofiler/inc/PmcTimerConfig.h b/drivers/powerprofiler/inc/PmcTimerConfig.h
new file mode 100644
index 000000000000..c81763249397
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcTimerConfig.h
@@ -0,0 +1,46 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcTimerConfig.h
+///
+//==================================================================================
+#pragma once
+
+#include <PmcCommonDataTypes.h>
+
+/*
+ * PmcSetupTimer - Allocate space for timer configuration
+ * structure and intialize it for a specified core mask.
+ */
+int PmcSetupTimer(ClientContext* pClientCtx);
+
+/*
+ * PmcDestroyTimer - Free memory for timer configuration
+ * strutcts and cancel timer.
+ */
+void PmcDestroyTimer(ClientContext* pClientCtx);
+
+/*
+ * PmcStartTimerOnCore - Start timer on a specifc core.
+ * Should be invoked on the core.
+ */
+void PmcStartTimerOnCore(CoreContext* pCoreCtx);
+
+/*
+ * PmcStartTimer - Start timer on all cores for a specified
+ * core mask.
+ */
+int PmcStartTimer(ClientContext* pClientCtx);
+
+/*
+ * PmcStopTimerOnCore - Stop timer on a specific core.
+ * Should be invoked on the core.
+ */
+void PmcStopTimerOnCore(CoreContext* pCoreCtx);
+
+/*
+ * PmcStopTimer - Stop timer on all cores for a specified
+ * core mask.
+ */
+int PmcStopTimer(ClientContext* pClientCtx);
diff --git a/drivers/powerprofiler/inc/PmcTypes.h b/drivers/powerprofiler/inc/PmcTypes.h
new file mode 100644
index 000000000000..2ea8ec957040
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcTypes.h
@@ -0,0 +1,112 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcSample.h
+///
+//==================================================================================
+#pragma once
+
+#if (__KERNEL__)
+    #include <linux/types.h>
+#else
+    #include <stdbool.h>
+    #include <stdint.h>
+#endif
+
+#define PMC_MAX_SOCKET_COUNT    4
+
+typedef enum
+{
+    PMC_PMU_INVALID = -1,
+    PMC_PMU_CORE,
+    PMC_PMU_L3,
+    PMC_PMU_DF,
+    PMC_PMU_UMC,
+    PMC_PMU_MAX,
+} PmcPmuType;
+
+/* Data to include in Raw file header:
+ * Magic Number
+ * File Header version
+ * System Date and Time
+ * System Info:
+ *   - CPU model/family
+ *   - <other information>
+ * Number of configuration groups
+ * Configuration information:
+ *  - Configuration Group Header
+ *    - Control values for events in group
+ *    - <other information>
+ */
+typedef struct
+{
+    // TODO: Add more parameters here.
+    uint64_t m_magicNumber;
+    uint64_t m_version;
+    uint64_t m_size;
+    uint32_t m_family;
+    uint32_t m_model;
+    uint64_t m_time;
+    // PSTATE register value
+    uint64_t m_pstateReg;
+    // TSC Frequency (Windows specific)
+    uint64_t m_tscFrequency;
+    uint32_t m_pmcPerUmc;
+    uint32_t m_umcMaskArraySize;
+    uint32_t m_umcMaskArray[PMC_MAX_SOCKET_COUNT];
+
+    // Configuration Information
+    uint64_t m_numOfConfigGroups;
+
+    // Making total header side 128 bytes for future expansion
+    uint64_t m_fill[5];
+    uint64_t m_configData[1];
+
+} PmcHeader;
+
+typedef union
+{
+    struct
+    {
+        // Sample size in bytes
+        uint32_t m_sampleSize;
+        uint32_t m_reserved;
+
+    } m_header;
+
+    uint64_t m_hdr;
+
+} PmcSampleHeader;
+
+// Group header in Pmc Sample data
+#define PMC_SAMPLE_HDR_GROUP_ID_WIDTH   48
+#define PMC_SAMPLE_HDR_GROUP_ID_MASK    0xffffffffffff
+
+#define PMC_SAMPLE_HDR_ATTR_WIDTH   16
+#define PMC_SAMPLE_HDR_ATTR_MASK    0xffff
+#define PMC_SAMPLE_HDR_ATTR_SHIFT   48
+
+typedef struct
+{
+    PmcSampleHeader m_sampleHeader;
+
+    /* Timestamp when the sample was collected
+     * For multiple config groups this is time when
+     * the first configuration group was loaded??
+     * Only required when multiplexing? */
+    uint64_t m_time;
+    /* Core Id on which the sample is collected
+     * TODO: Can this be moved into sample header? */
+    uint32_t m_coreId;
+    /* Socket Id on which the sample is collected
+     * Used for processing UMC type samples */
+    uint32_t m_socketId;
+    /* Delta time (Timestamp when current sample is logged)
+     * - (Timestamp when last sample was logged)*/
+    uint64_t m_deltaTimeEnabled;
+
+    /* PMC sample data */
+    uint64_t m_data[1];
+
+} PmcSample;
diff --git a/drivers/powerprofiler/inc/PmcUtils.h b/drivers/powerprofiler/inc/PmcUtils.h
new file mode 100644
index 000000000000..c9434296651e
--- /dev/null
+++ b/drivers/powerprofiler/inc/PmcUtils.h
@@ -0,0 +1,28 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcUtils.h
+///
+//==================================================================================
+#pragma once
+
+#include <PmcTypes.h>
+#include <PmcInterface.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+const char* GetPmcTypeString(PmcPmuType type);
+
+uint64_t* GetCoreMaskArray(CountModeProfileConfig* pConfig,
+                           PmcPmuType type);
+
+uint64_t* GetPmcConfigArray(CountModeGroupConfig* pConfig);
+
+PmcPmuType GetPmcType(GroupType groupType);
+
+#ifdef __cplusplus
+}
+#endif
\ No newline at end of file
diff --git a/drivers/powerprofiler/inc/PwrAccessPmcData.h b/drivers/powerprofiler/inc/PwrAccessPmcData.h
new file mode 100644
index 000000000000..bd0672ee6b1c
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrAccessPmcData.h
@@ -0,0 +1,30 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrAccessPmcData.cpp
+///
+//==================================================================================
+#pragma once
+#include <PwrProfInternal.h>
+#include <PwrCommonDataTypes.h>
+
+typedef struct PmcCounters
+{
+    uint32   m_controlMSR;
+    uint32   m_dataMSR;
+} PmcCounters;
+
+// InitializePMCCounters
+bool InitializePMCCounters(PmcCounters* pPmc);
+
+// ReadPmcCounterData: Read PMC counter values
+uint32 ReadPmcCounterData(PmcCounters* pPmc, uint64* pData);
+
+// ResetPMCCounters: Reset PCM counter values
+bool ResetPMCCounters(PmcCounters* pPmc);
+
+// ResetPMCControl: Reset PMC counter control data
+bool ResetPMCControl(PmcCounters* pPmc);
+
+uint32 EncodePMCEvent(uint16 eventSelect, uint8 unitMask);
diff --git a/drivers/powerprofiler/inc/PwrCommonConfig.h b/drivers/powerprofiler/inc/PwrCommonConfig.h
new file mode 100644
index 000000000000..e3a1863a67ae
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrCommonConfig.h
@@ -0,0 +1,21 @@
+//==================================================================================
+// Copyright (c) 2016 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrCommonConfig.h
+///
+//==================================================================================
+#pragma once
+#include <PwrDriverInternal.h>
+#include <PwrCommonDataTypes.h>
+
+// ConfigureSourceProfiling: Configuration for source code profiling
+void ConfigureSourceProfiling(CoreData* pCoreData);
+
+// CloseSourceProfiling: Close the configuration for source code profiling
+void CloseSourceProfiling(CoreData* pCoreData);
+
+// PwrGetIpcData: collect IPC load parameters
+void PwrGetIpcData(PmcCounters* pSrc, uint64* pData);
+
+void PwrReadZpIpcData(uint64* pData);
diff --git a/drivers/powerprofiler/inc/PwrCommonDataTypes.h b/drivers/powerprofiler/inc/PwrCommonDataTypes.h
new file mode 100644
index 000000000000..43ea76c634ef
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrCommonDataTypes.h
@@ -0,0 +1,895 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrCommonDataTypes.h
+///
+//==================================================================================
+#pragma once
+
+#include "PwrDriverTypedefs.h"
+#include "PmcInterface.h"
+#include "PwrVersion.h"
+
+#define FAMILY_EXTENDED_VALUE 0x0f
+#define INVALID_UINT32_VALUE 0xFFFFFFFF
+
+// CPUID
+#define CPUID_FnAdvancePowerManagementInformation 0x80000007
+#define CPUID_FnAdvancePowerManagementInformation_EDX_EffFreqRO (1 << 10)
+#define CPUID_FnAmdExtendedFeatures_ECX_PerfCtrExtCore (1 << 23)
+#define CPUID_FnFeatureId 1
+#define CPUID_FnThermalAndPowerManagement 6
+#define CPUID_NodeIdentifiers_EBX_ThreadsPerCore (0xFF << 8)
+#define CPUID_FeatureId_EBX_LogicalProcessorCount 0xFF << 16
+#define CPUID_FnThermalAndPowerManagement_ECX_EffFreq  (1 << 0)
+#define CPUID_FnThreadPerSocketInformation 0x80000008
+#define CPUID_FnThreadPerSocketInformation_ECX_ThreadCnt (0xFF)
+#define CPUID_FnIdentifiers  0x8000001E
+#define CPUID_FnBrandIdIdentifier 0x80000001
+#define CPUID_FnSizeID  0x80000008
+#define CPUID_FnExtdPerfmonAndDebug 0x80000022
+#define CPUID_FnLargFuncExtNum 0x80000000
+
+#define MAX_CORE_CNT                (1024)
+#define PWR_CORE_MASK_SIZE          (MAX_CORE_CNT / 64)
+#define PWR_CORE_MASK_BITS_COUNT    (64)
+#define PWR_MAX_SOCKET_COUNT        (4)
+#define COUNTERID_MAX_CNT           (200)
+
+#define PWR_INTERNAL_COUNTER_BASE   (2 * sizeof(uint32) + PWR_MAX_MARKER_CNT * sizeof(MarkerTag))
+#define PWR_MAX_GROUP_COUNT (8192)
+#define PWR_MAX_SAMPLING_PERIOD (600000)
+
+// Count mode driver errors
+#define ERROR_PMC_INVALID_CLIENTID (0x80090000)
+#define ERROR_PMC_MUXPMCCFGGRP_NULL_CFGGRP (0x80090001)
+#define ERROR_PMC_ALLOCATEDATABUFFERCONTEXT_NULL_CORECTX (0x80090002)
+#define ERROR_PMC_ALLOCATEDATABUFFERCONTEXT_NULL_DATABUFFERCTX (0x80090003)
+#define ERROR_PMC_ALLOCATEPMCCFGGRP_NULL_PMCCFGGRP (0x80090004)
+#define ERROR_PMC_ALLOCATEPMCCFGGRP_NULL_CFGARRY (0x80090005)
+#define ERROR_PMC_ALLOCATEPMCCFGGRP_PMCNOTCONFIGURED (0x80090006)
+#define ERROR_PMC_ALLOCATEPMCCFGGRP_NULL_UMCCOUNTARRYA (0x80090007)
+#define ERROR_PMC_ALLOCATECORECONTEXT_NULL_CORECTXARRAY (0x80090008)
+#define ERROR_PMC_ALLOCATEUMCMASKARRAY_NULL_UMCMASKARRY (0x80090009)
+#define ERROR_PMC_ALLOCATECOREMASKARRY_NULLCOREMASK (0x8009000A)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_INVALIDPARAMS (0x8009000B)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_NULL_COREMASKARRAY (0x8009000C)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_INVALIDSOCKETID (0x8009000D)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_ALLOCPMCCFGGRP (0x8009000E)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_ALLOCPMCCFGGRP_NULL_COREMASK_OR_PMCCFG_ARRAY (0x8009000F)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_ENABLEIRPERF (0x80090010)
+#define ERROR_PMC_ALLOCCLIENTCONTEXT_NULL (0x80090011)
+#define ERROR_PMC_STARTPROFILE_NULL_PMCCLIENTCTX (0x80090012)
+#define ERROR_PMC_STOPPROFILE_NULL_CLIENTCTX_CORECTX (0x80090013)
+#define ERROR_PMC_PMCMAP_INVALID_PARAMS (0x80090014)
+#define ERROR_PMC_PMCMAP_VMSIZE_GREATERTHANBUFFERSIZE (0x80090015)
+#define ERROR_PMC_PMCMAP_NULL_DATABUFFER (0x80090016)
+#define ERROR_PMC_PMCMAP_REMAPPFN_RANGE (0x80090017)
+#define ERROR_PMC_CREATEPMCDESC_INVALID_PARAMS (0x80090018)
+#define ERROR_PMC_CREATEPMCDESC_NULL_CORECTX (0x80090019)
+#define ERROR_PMC_CREATEPMCDESC_NULL_PRIVATEDATA (0x8009001A)
+#define ERROR_PMC_CREATEPMCDESC_NULL_PARAMS (0x8009001B)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_NULL_CORECONTEXT (0x8009001C)
+#define ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_NULL_GRPCFG (0x8009001D)
+#define ERROR_PMC_INVALID_STATE (0x8009001E)
+#define ERROR_PMC_TIMERCFG_NULL_CLIENTCTX (0x8009001F)
+#define ERROR_PMC_REGISTER_NULL_CLIENT (0x80090020)
+#define ERROR_PMC_REGISTER_INVALID_CLIENT (0x80090021)
+#define ERROR_PMC_COUNTMODE_ALLOC (0x80090022)
+#define ERROR_PMC_COUNTMODE_COPY (0x80090023)
+#define ERROR_PMC_COUNTMODE_NULL_GRPCFG (0x80090024)
+#define ERROR_PMC_COUNTMODE_FD_COPY (0x80090025)
+#define ERROR_PMC_COUNTMODE_EXT_COPY (0x80090026)
+#define ERROR_PMC_COUNTMODE_EXT_ALLOC (0x80090027)
+#define ERROR_PMC_COUNTMODE_CLEAR_COPY (0x80090028)
+
+#define ERROR_PWR_REGISTER_INVALID_TYPE (0x800900E0)
+#define ERROR_PWR_REGISTER_INVALID_CLIENT (0x800900E1)
+#define ERROR_PWR_UNREGISTER_INVALID_PARAMS (0x800900E2)
+#define ERROR_PWR_ADDPROFCFG_COPY (0x800900E3)
+#define ERROR_PWR_RESUME_COPY (0x800900E4)
+#define ERROR_PWR_START_COPY (0x800900E5)
+#define ERROR_PWR_PAUSE_COPY (0x800900E6)
+#define ERROR_PWR_STOP_COPY (0x800900E7)
+#define ERROR_PWR_FILE_HDR_COPY (0x800900E8)
+#define ERROR_PWR_DATA_BUFFER_COPY (0x800900E9)
+#define ERROR_PWR_PCI_COPY (0x800900EA)
+#define ERROR_PWR_PCI_OUT_COPY (0x800900EB)
+#define ERROR_PWR_MSR_COPY (0x800900EC)
+#define ERROR_PWR_MSR_OUT_COPY (0x800900ED)
+#define ERROR_PWR_MMIO_COPY (0x800900EE)
+#define ERROR_PWR_MMIO_OUT_COPY (0x800900EF)
+#define ERROR_PWR_MMIO_READ (0x800900F0)
+#define ERROR_PWR_FD_COPY (0x800900F1)
+#define ERROR_PWR_SYSINFO_COPY (0x800900F2)
+#define ERROR_PWR_SYSINFO_GET (0x800900F3)
+#define ERROR_PWR_IOCTL_INVALID (0x800900F4)
+#define ERROR_PWR_SMN_COPY (0x800900F5)
+#define ERROR_PWR_SMN_OUT_COPY (0x800900F6)
+
+#define ERROR_PWR_HYPERV_UMC (0x800900F7)
+#define ERROR_PWR_INVALID_STATE (0x800900F8)
+#define ERROR_PWR_IOCTL_NOT_SUPPORTED (0x800900F9)
+
+//Maximum number of available APU P-States
+#define AMDT_MAX_PSTATES 8
+
+// IOCTL_CONFIG_EXTND_SIZE is based on the IOCTL allowed size to transfer bytes from
+// backend to the driver. In windows, maximum one page can be transferred. In Linux, recent
+// kernel allows upto 2048. However, older kernel allows 1024 bytes
+// Actual HEADER_BUFFER_SIZE size is below 400. However, for historical reason, we reserved a
+// bigger buffer.
+// TODO: To avoid HLK, only Linux HEADER_BUFFER_SIZE size is decreased now. We can keep a minimum
+// size for both windows and Linux
+#define AMDT_MAX_PSTATES 8
+#if defined(_WIN32)
+#define IOCTL_CONFIG_EXTND_SIZE 10
+#define HEADER_BUFFER_SIZE (1940)
+#else
+#define IOCTL_CONFIG_EXTND_SIZE 6
+#define HEADER_BUFFER_SIZE (800)
+#endif
+
+/// Header buffer size
+
+#define PLATFORM_SMU_CNT (5)
+#define MAX_PATH_SIZE (260)
+
+
+/// The enumeration used to retrieve data from the __cpuid intrinsic
+typedef enum
+{
+    /// The offset of EAX data
+    PWR_EAX_OFFSET,
+    /// The offset of EBX data
+    PWR_EBX_OFFSET,
+    /// The offset of ECX data
+    PWR_ECX_OFFSET,
+    /// The offset of EDX data
+    PWR_EDX_OFFSET,
+    /// The number of values in the CPUID array
+    PWR_NUM_CPUID_OFFSETS
+} RegisterOffset;
+
+// PwrZenType:
+typedef enum PwrZenType
+{
+    PWR_ZEN1,
+    PWR_ZEN2,
+    PWR_ZEN3,
+    PWR_ZEN4
+} PwrZenType;
+
+// PwrZPSocketType: Platform socket types
+typedef enum PwrZPSocketType
+{
+    PWR_SOCKET_TYPE_ZP_FP5 = 0x00,
+    PWR_SOCKET_TYPE_ZP_SP4 = 0x01,
+    PWR_SOCKET_TYPE_ZP_AM4 = 0x02,
+    PWR_SOCKET_TYPE_ZP_SP3 = 0x04,
+    PWR_SOCKET_TYPE_ZP_SP3R2 = 0x07
+} PwrZPSocketType;
+
+// PwrCZSocketType: Platform socket types
+typedef enum PwrCZSocketType
+{
+    PWR_SOCKET_TYPE_CZ_FP4 = 0x00,
+} PwrCZSocketType;
+
+// PwrKVSocketType: Platform socket types
+typedef enum PwrKVSocketType
+{
+    PWR_SOCKET_TYPE_KV_FP3 = 0x00,
+    PWR_SOCKET_TYPE_KV_FM2R2 = 0x01
+} PwrKVSocketType;
+
+// PwrMLSocketType: Platform socket types
+typedef enum PwrMLSocketType
+{
+    PWR_SOCKET_TYPE_ML_FT3B = 0x00,
+    PWR_SOCKET_TYPE_ML_FP4 = 0x02
+} PwrMLSocketType;
+
+typedef enum PwrBasicCounterIds
+{
+    COUNTERID_SAMPLE_ID,
+    COUNTERID_RECORD_ID,
+    COUNTERID_SAMPLE_TIME,
+    COUNTERID_BASIC_CNT
+} PwrBasicCounterIds;
+
+typedef enum PwrNodeCounterIds
+{
+    COUNTERID_PID,
+    COUNTERID_TID,
+    COUNTERID_CEF,
+    COUNTERID_CSTATE_RES,    //TODO: remove this enum as not used.
+    COUNTERID_PSTATE,
+    COUNTERID_SOFTWARE_PSTATE,
+    COUNTERID_PERCORE_END = COUNTERID_SOFTWARE_PSTATE,
+    COUNTERID_CORE_POWER,
+    COUNTERID_PKG_POWER,
+    COUNTERID_PKG_TEMPERATURE,
+    COUNTERID_NODE_MAX_CNT
+} PwrNodeCounterIds;
+
+#define PWR_PERCORE_COUNTER_MASK ~(~0ULL << (COUNTERID_PERCORE_END +1) )
+
+///The maximum number of clients that PwrProf supports
+#define MAX_CLIENT_COUNT 1
+
+//  PwrProf's error codes
+typedef enum
+{
+    /// An error occurred
+    PROF_ERROR = -1,
+    /// No errors occurred
+    PROF_SUCCESS = 0x00,
+    /// An argument was invalid
+    PROF_INVALID_ARG = 0x01,
+    /// Unable to create a file with that name
+    PROF_INVALID_FILENAME_FORMAT = 0x03,
+    /// Unable to write to the file
+    PROF_FILE_WRITE_ERROR = 0x05,
+    /// The configuration is not available
+    PROF_INVALID_OPERATION = 0x06,
+    /// Memory is not available for buffer allocation
+    PROF_BUFFER_NOT_ALLOCATED = 0x08,
+    /// The client application crashed during a profile
+    PROF_CRITICAL_ERROR = 0xDEAD
+} PWRPROF_ERROR_CODES;
+
+
+/// These enumerated masks cover the possible range of states the driver is in
+typedef enum
+{
+    /// The current client is not configured for anything
+    STATE_NOT_CONFIGURED = 0x0000,
+    /// The output file has been set for the next profile
+    STATE_OUTPUT_FILE_SET = 0x0001,
+    /// The call-stack sampling has been set for the next profile
+    STATE_CSS_SET = 0x0002,
+    /// The process id filter has been set for the next profile
+    STATE_PID_FILTER_SET = 0x0004,
+    /// At least one event configuration has been added for the next
+    /// profile
+    STATE_TBP_SET = 0x0008,
+    /// The profile was started and is in process
+    STATE_PROFILING = 0x0010,
+    /// The profile was started and is currently paused
+    STATE_PAUSED = 0x0020,
+    /// The profile is currently stopping
+    STATE_STOPPING = 0x0040
+} PWRPROF_STATE;
+
+
+typedef enum PMCEvents
+{
+    PMC_EVENT_CPU_CYCLE_NOT_HALTED,
+    PMC_EVENT_RETIRED_MICRO_OPS,
+    PMC_EVENT_MAX_CNT
+} PMCEvents;
+
+/// \struct OUTPUT_FILE_DESCRIPTOR Holds the file names for the next profile
+typedef struct
+{
+    uint32 m_clientId;
+    uint32 m_pathSize;
+    wchar_t m_pathName[MAX_PATH_SIZE];
+    uint32 m_status;
+} OUTPUT_FILE_DESCRIPTOR, *POUTPUT_FILE_DESCRIPTOR;
+
+#define PROFILE_MASK_LEN (3)
+
+/// Profiling modes
+typedef enum
+{
+    /// Offline profiling mode
+    PROF_MODE_OFFLINE   = 0x0000,
+    /// Online profiling mode
+    PROF_MODE_ONLINE    = 0x0001,
+} PROF_MODE;
+
+/// \struct PROFILER_PROPERTIES Holds information about the current profile
+typedef struct
+{
+    uint32 m_clientId;
+    uint32 m_mode;
+    uint64 m_abort;
+    uint32 m_status;
+} PROFILER_PROPERTIES, *PPROFILER_PROPERTIES;
+
+typedef struct
+{
+    uint32 m_clientId;
+    // field not used
+    uint32 m_fill;
+    // Total number of groups
+    // This should be valid only for the first IOCTL call
+    uint32 m_groupCnt;
+    // groups within each ioctl call
+    uint32 m_size;
+    CountModeGroupConfig  m_data[IOCTL_CONFIG_EXTND_SIZE];
+} COUNT_MODE_CONFIG_EXTND;
+
+#if defined(_WIN32)
+    #define PWR_CURRENT_CORE (~0UL)
+#else
+    #define PWR_CURRENT_CORE (-1)
+#endif
+
+/// \struct ACCESS_PCI to access Pci device directly from user space
+typedef struct
+{
+    bool     m_isReadAccess;
+    uint32   m_address;
+    uint32   m_data;
+} ACCESS_PCI, *PACCESS_PCI;
+
+typedef struct
+{
+    bool     m_isReadAccess;
+    bool     m_isExtended;
+    bool     m_isBus;
+    union
+    {
+        uint32 m_socket;
+        uint32 m_busId;
+    };
+    uint32   m_address;
+    uint32   m_data;
+} ACCESS_SMN, *PACCESS_SMN;
+
+/// \struct ACCESS_MSR to access MSR directly from user space
+typedef struct
+{
+    bool     m_isReadAccess;
+    uint32   m_core;
+    uint32   m_regId;
+    uint64   m_data;
+} ACCESS_MSR, *PACCESS_MSR;
+
+/// \struct ACCESS_MMIO to access Memory Mapped space
+typedef struct
+{
+    bool     m_isReadAccess;
+    uint64   m_addr;
+    uint32   m_data;
+    uint32   m_status;
+} ACCESS_MMIO, *PACCESS_MMIO;
+
+/// \struct FILE_HEADER
+/// Mainly used for online profiling mode
+typedef struct
+{
+    uint32 m_clientId;
+    /// Buffer id, used to identify requested buffer in case header spans
+    /// in more than 1 buffer, first buffer id is 0 and so on
+    uint32 m_bufferId;
+    uint8  m_buffer[HEADER_BUFFER_SIZE];
+    uint32 m_bufferCnt;
+    uint32 m_status;
+} FILE_HEADER, *PFILE_HEADER;
+
+typedef struct PwrApicInfo
+{
+    uint32 m_extdApic;
+    uint32 m_physicalId;
+    uint32 m_nodeId;
+} PwrApicInfo;
+
+typedef struct PwrExtPerfMonAndDbgInfo
+{
+    bool        m_isLbrExtV2;
+    bool        m_isPerfMonV2;
+    uint32_t    m_numOfUmcPmc;
+    uint32_t    m_numOfDfPmc;
+    uint32_t    m_lbrV2StackSize;
+    uint32_t    m_numOfCorePmc;
+    uint32_t    m_activeUmcMask;
+    uint32_t    m_numOfL3Pmc;
+} PwrExtPerfMonAndDbgInfo;
+
+typedef struct MMIOBusMap
+{
+    uint32 m_threadId;
+    uint32 m_bus;
+} MMIOBusMap;
+
+// PwrZenTargetInfo
+typedef struct PwrZenTargetInfo
+{
+    uint32      m_totalPhysicalCores;
+    uint32      m_totalThreads;
+    uint32      m_physicalCoresPerSocket;
+    uint32      m_threadsPerSocket;
+    bool        m_isSmtEnabled;
+    uint32      m_isRaplAvailable;
+    uint32      m_energyUnit;
+    MMIOBusMap  m_mmio[PWR_MAX_SOCKET_COUNT];
+    uint32      m_firstCore[PWR_MAX_SOCKET_COUNT];
+    PwrApicInfo m_apic[MAX_CORE_CNT];
+    uint64      m_pstateReg;
+    bool        m_isZen2;
+    bool        m_isZen3;
+    bool        m_isZen4AndAbove;
+    uint32_t    m_coreShiftWidth;
+    uint32_t    m_coreMaskWidth;
+    uint32_t    m_ccdShiftWidth;
+    uint32_t    m_ccdMaskWidth;
+    uint32_t    m_ccxShiftWidth;
+    uint32_t    m_ccxMaskWidth;
+    uint32_t    m_socketShiftWidth;
+    uint32_t    m_socketMaskWidth;
+    PwrExtPerfMonAndDbgInfo m_perfMonInfo[PWR_MAX_SOCKET_COUNT];
+} PwrZenTargetInfo;
+
+typedef struct PwrNonAmdTargetInfo
+{
+    uint32 m_cores;
+} PwrNonAmdTargetInfo;
+
+/// \struct TARGET_SYSTEM_INFO
+/// Target HW information
+typedef struct
+{
+    uint32 m_isZen;
+    uint32 m_isAmd;
+    uint32 m_family;
+    uint32 m_model;
+    uint32 m_socketType;
+    uint32 m_socketCount;
+    bool   m_isCefAvailable;
+    bool   m_isGuest;
+    union
+    {
+        PwrZenTargetInfo  m_zen;
+        PwrNonAmdTargetInfo m_nonAmd;
+    };
+    uint32 m_status;
+} TARGET_SYSTEM_INFO, *PTARGET_SYSTEM_INFO;
+
+/// \struct DATA_BUFFERS
+/// Mainly used for online profiling mode
+typedef struct
+{
+    /// The registered client id
+    uint32 ulClientId;
+    /// Buffer id, used to identify requested buffer in case sample data spans
+    /// in more than 1 buffer, latest buffer id is 0 then -1, -2...so on
+    int32 lBufferId;
+    /// Buffer will contain sample data, the size of buffer
+    /// should be >= DATA_PAGE_BUFFER_SIZE
+    uint64 uliBuffer;
+    /// Start offset of the data collected after last call
+    uint32 ulStartOffset;
+    /// Byte to be consumed after the start offset
+    uint32 ulByteToBeConsumed;
+    /// Sample buffer collected since last call
+    uint32 ulavailableBuffCnt;
+    /// The return status
+    uint32 ulStatus;
+} DATA_BUFFER, *PDATA_BUFFER;
+
+// Common function implementation between driver and backend
+// These functions are inteded to have same logic across driver and backend
+// to avoid different logic and maintainace purpose
+
+// DecodeCURegisterStatus: Decode the number of compute units and number of active cores
+// in that compute unit.
+#define AMDT_CU_STATUS1 0x00010001
+#define AMDT_CU_STATUS2 0x00030003
+#define AMDT_CU_STATUS3 0x00010000
+#define AMDT_CU_STATUS4 0x00030000
+
+// PState frequency masks
+#define AMDT_CPUFID_MASK        0x3FULL
+#define AMDT_CPUDID_MASK        0x1C0ULL
+#define AMDT_CPUDID_BITSHIFT    6
+
+// PState
+#define AMDT_PSTATE_BASE_REGISTER                   0xC0010064
+#define AMDT_PSTATE_CORE_FREQ_DIVISOR_ID_MASK       0x3F00ULL
+#define AMDT_PSTATE_CORE_FREQ_DIVISOR_ID_SHIFT      8
+#define AMDT_PSTATE_CORE_FREQ_MULTIPLIER_ID_MASK    0xFFULL
+
+
+// Page Buffer
+// Buffer to hold the profile and header data
+// Common structure between driver and backend
+typedef struct PageBuffer
+{
+    uint64   m_recCnt;
+    atomic   m_currentOffset;
+    atomic   m_consumedOffset;
+    union
+    {
+        uint8*   m_pBuffer;
+        uint64   m_dummy;
+    };
+    atomic   m_maxValidOffset;
+    uint32   m_fill;
+} PageBuffer;
+
+
+/*
+1h 1h -1 compute unit is enabled; both cores of the compute unit are enabled.\
+3h 3h -2 compute units are enabled; both cores of each compute unit are enabled.\
+1h 0h -1 compute unit is enabled; core 0 of the compute unit is enabled; core 1 of the\
+compute unit is disabled.\
+3h 0h 2 compute units are enabled; core 0 of each compute unit is enabled; core 1 of\
+each compute unit is disabled.\
+*/
+#define DecodeCURegisterStatus(reg, pCuCnt, pCorePerCu)\
+    if(reg == (reg & AMDT_CU_STATUS1)){*pCuCnt = 1; *pCorePerCu = 2;}\
+    else if (reg == (reg & AMDT_CU_STATUS2)){*pCuCnt = 2;*pCorePerCu = 2;}\
+    else if (reg == (reg & AMDT_CU_STATUS3)) { *pCuCnt = 1;*pCorePerCu = 1;}\
+    else if (reg == (reg & AMDT_CU_STATUS4)) {*pCuCnt = 2; *pCorePerCu = 1; }
+
+// ExtendedPciAddrSpace: PCI config address encoder
+typedef union ExtendedPciAddrSpace
+{
+    // \brief The elements that make up a PCI address in PCI config space
+    struct
+    {
+        // base register address to access
+        uint32 regNo : 8;
+        // function number to access
+        uint32 function : 3;
+        // device number to access
+        uint32 device : 5;
+        // bus number to access
+        uint32 busNo : 8;
+        // extended register number to access
+        uint32 extRegNo : 4;
+        // reserved, must be 0
+        uint32 reserved : 3;
+        // Configuration space enable, 1 = IO read and write accesses to
+        // IOCFC are translated into configuration cycles at the
+        // configuration address
+        uint32 configEn : 1;
+    } element;
+    // The equivalent IO-space configuration address made up of each \ref Element
+    uint32 address;
+} ExtendedPciAddrSpace;
+
+// EncodeExtendedConfigSpaceAddress: Encode PCI address to extended PCI config speace.
+#define GET_EXTENDED_PCICS_ADDRESS(b, d, f, r, out) {\
+        ExtendedPciAddrSpace p;\
+        p.address = 0U;\
+        p.element.configEn = 1U;\
+        p.element.extRegNo = (r >> 8) & 0xFU;\
+        p.element.regNo = r & 0x00FCU;\
+        p.element.busNo = b;\
+        p.element.device = d;\
+        p.element.function = f;\
+        out = p.address;   }
+
+typedef struct PwrCefInfo
+{
+    uint64 m_p0State;
+    uint64 m_aperf;
+    uint64 m_mperf;
+    uint64 m_tsc;
+} PwrCefInfo;
+
+// Error code for power profile API access
+typedef enum
+{
+    RAW_STATUS_ERROR = -1,
+    RAW_STATUS_SUCCESS = 0,
+    RAW_READ_ERROR = 1,
+    RAW_WRITE_ERROR = 2,
+    RAW_UNKNOWN_ERROR = 3,
+} RAW_Status;
+
+#define RAWFILE_MAGIC 0
+#define MAJOR_VERSION 3
+#define MINOR_VERSION 4
+#define MICRO_VERSION 1
+#define PROFILE_VERSION (MAJOR_VERSION << 24)|(MINOR_VERSION << 16)| MICRO_VERSION
+#define RAW_FILE_VERSION 1
+#define SECTION_HDR_CNT 1
+#define MAX_SECTION_HDR_CNT 12
+#define MAX_POWER_CFG 10
+#define FILE_BUFFER_SIZE (4*1024)
+
+#define MAX_SAMPLE_ATTRIBUTE 20 //will this be sufficient
+#define MAX_RAW_DATA_SIZE (MAX_SAMPLE_ATTRIBUTE * sizeof(uint64))
+#define CONTEXT_RECORD_LEN sizeof(RawRecordHdr) + sizeof(uint64) + sizeof(ContextData)
+#define MARKER_RECORD_LEN (sizeof(RawRecordHdr) + sizeof(MarkerTag))
+
+// SectionHrdTableInfo
+//
+// This structure holds the starting address and size of each section
+// Currently there is only one section table.
+// There could be more than one section header table in future.
+typedef struct SectionHrdTableInfo
+{
+    uint32   m_sectionTabOff;  // offset of section header table in file;
+    uint32   m_sectionTabSize; // size of the section header table in file;
+} SectionHrdTableInfo;
+
+// RawFileHeader
+//
+// We can also use MAJOR and MINOR VERSION NUMBER - 16 bits each and
+// consturct a 32-bit VERSION from these MAJOR and MINOR version numbers
+#define RAW_FILE_VERSION      1
+
+#define MAX_SECTION_HDR_TABLE 2
+typedef struct RawFileHeader
+{
+    uint64   m_magicNum;
+    uint32   m_versionNum;
+    uint32   m_rawFileVersion;
+    uint16   m_sectionTabCnt;
+    uint32   m_rawDataOffset;
+    uint32   m_family;
+    uint32   m_model;
+    uint64   m_rawRecordCount;
+    uint64   m_sessionStart;
+    uint64   m_sessionEnd;
+    uint64   m_startPerfCounter;
+    uint64   m_perfFreq;
+    SectionHrdTableInfo m_tabInfo[1];
+} RawFileHeader;
+
+// SectionType
+//
+// Not all sections are mandatory...
+// Following sections are optional
+//    1.RAW_FILE_SECTION_RUN_INFO
+//    2.RAW_FILE_SECTION_CPU_INFO
+//    3.RAW_FILE_SECTION_CPU_TOPOLOGY
+// For CPU profile following could be necessary
+//      1.Sampling mode requires - EVENT_ATTRIBUTE, SAMPLE_ID & SAMPLE_DATA sections
+//      2.Counting mode requires - EVENT_ATTRIBUTE & COUNTER_DATA sections
+//      3.Sampling and Sampling mode requires -
+//        EVENT_ATTRIBUTE, SAMPLE_ID, SAMPLE_DATA & COUNTER_DATA sections
+//  For Power profile following could be necessary
+//        RAW_FILE_SECTION_POWER_CONFIG, SAMPLE_ID, SAMPLE_DATA sections
+
+#define RAW_FILE_SECTION_RUN_INFO (1 << 0)
+#define RAW_FILE_SECTION_CPU_INFO (1 << 1)
+#define RAW_FILE_SECTION_CPU_TOPOLOGY (1<<2)
+#define RAW_FILE_SECTION_SAMPLE_CONFIG (1<<3)
+#define RAW_FILE_SECTION_SAMPLE_REC_INFO (1<<4)
+#define RAW_FILE_SECTION_TI_REC_INFO (1<<5)
+#define RAW_FILE_SECTION_MAX ((uint32)1<<31)
+//SectionHdrInfo
+//SectionType could be one of SectionType
+typedef struct SectionHdrInfo
+{
+    uint32   m_sectionType;
+    uint32   m_misc;            // _UNUSED_ field
+    uint64   m_sectionOffset;
+    uint64   m_sectionSize;
+} SectionHdrInfo;
+
+// SectionRunInfo Section :Optional
+//
+//   contains details about the machine, processor, OS
+//   name/path of the application launched
+//   start and end time of the profile
+//
+//
+//
+#define MAX_NAME_SIZE    64
+typedef struct SectionRunInfo
+{
+    uint64   m_startTime;
+    uint64   m_endTime;
+    // This can contain null terminated 64 byte length strings (65 chars)
+    wchar_t   m_sysName[MAX_NAME_SIZE];    // OS implementation - Linux
+    wchar_t   m_releases[MAX_NAME_SIZE];   // Release - 2.6.38-8-generic
+    wchar_t   m_version[MAX_NAME_SIZE];    // version - Ubuntu
+    wchar_t   m_nodeName[MAX_NAME_SIZE];   // machine name - capike01
+    wchar_t   m_machine[MAX_NAME_SIZE];    // hw type - x86_64
+    wchar_t   m_fileName[MAX_NAME_SIZE];   // launched application - should be the last field
+} SectionRunInfo;
+
+//SectionCpuInfo: This is an optional section to hold cpu details.
+//
+// TBD: Do we need vendor info ?
+//
+#define MAX_CPUID_VALUE    4
+
+typedef struct SectionCpuInfo
+{
+    uint32     m_function;
+    uint32     m_value[MAX_CPUID_VALUE]; // when CA_CPUID_VALUE_MAX gets modified, ensure
+    uint32     m_filler[3];
+} SectionCpuInfo;
+
+//SectionCpuTopologyInfo: This is an optional section to hold cpu topology info.
+typedef struct SectionCpuTopologyInfo
+{
+    uint32     m_coreId;
+    uint32     m_processorId;
+    uint32     m_numaNodId;
+    uint32     m_filler;
+} SectionCpuTopologyInfo;
+
+//SectionSampleInfo: This structure define the first record chunck offset.
+typedef struct SectionSampleInfo
+{
+    uint64   m_firstChunkOffset;
+    uint64   m_recordCount;
+    uint64   m_size;
+} SectionSampleInfo;
+
+//SectionTiInfo: This structure define the first TI chunck offset.
+typedef struct SectionTiInfo
+{
+    uint64  m_firstChunkOffset;
+    uint64  m_recordCount;
+    uint64  m_size;
+} SectionTiInfo;
+
+//Chunk type: describe the types of records followed by chunk marker
+typedef enum
+{
+    CHUNK_TYPE_SAMPLE,
+    CHUNK_TYPE_TI
+} ChunkType;
+
+// ProfileRecordType
+//
+// Type of the profile
+typedef enum
+{
+    REC_TYPE_INVALID = 0,
+    REC_TYPE_SAMPLE_DATA,
+    REC_TYPE_CHUNK_MARKER,
+    REC_TYPE_CONTEXT_DATA,
+    REC_TYPE_MARKER_DATA,
+    REC_TYPE_MAX_CNT
+} ProfileRecordType;
+
+// RawRecordHrd
+//
+// RawRecordHrd holds the information about raw record followed
+// by this header
+typedef struct RawRecordHdr
+{
+    uint16  m_recordType;
+    uint16  m_recordLen;
+    uint32  m_coreId;
+} RawRecordHdr;
+
+typedef enum
+{
+    PROFILE_TYPE_TIMELINE,
+    PROFILE_TYPE_APP_ANALYSIS,
+} ProfileType;
+
+// RawPowerConfig
+
+typedef struct _ProfileConfig
+{
+    uint16 m_sampleId;
+    uint16 m_attrCnt;
+    uint32 m_fill;
+    uint32 m_profileType;
+    uint32 m_maskCnt;
+    uint64 m_mask[PWR_CORE_MASK_SIZE];
+    // in milli seconds
+    uint64 m_samplingPeriod;
+    // Only node counters
+    uint64 m_counterMask;
+} ProfileConfig;
+
+// PROF_CONFIGS
+typedef struct
+{
+    uint32 m_clientId;
+    uint32 m_pid;
+    uint32 m_profileType;
+    uint32 m_status;
+    ProfileConfig m_config;
+} PROF_CONFIGS, * PPROF_CONFIGS;
+
+// RawPowerConfigTable
+//
+// Table to describe more than one configuration for a profile session
+// m_configCnt provides the number of configuration used for the profile session
+typedef struct ProfileConfigList
+{
+    uint32            m_configCnt;
+    PROF_CONFIGS*     m_profileConfig;
+} ProfileConfigList;
+
+//RawBufferInfo
+//
+//This structure holds the information regarding the buffer comming from driver
+typedef struct RawBufferInfo
+{
+#ifndef _DBG_TOOL_
+    ULARGE_INTEGER uliBuffer;
+#else
+    ULARGE_INT     uliBudder;
+#endif
+    uint32         ulvalidLength;
+} RawBufferInfo;
+
+// Context Data
+// Os context data for every sample
+typedef struct ContextData
+{
+    uint32     m_processId;
+    uint32     m_threadId;
+    uint64     m_timeStamp;
+    uint64     m_ip;
+    uint32     m_isKernel;
+    uint32     m_fill;
+    uint64     m_pmcData[PMC_EVENT_MAX_CNT];
+} ContextData;
+
+// PwrInternalAddr: Internal counters PCI address
+typedef struct PwrInternalAddr
+{
+    uint32 m_cstateRes;
+    uint32 m_sviTelemetry;
+    uint32 m_sviNBTelemetry;
+    uint32 m_timingControl4;
+    uint32 m_timingControl6;
+    uint32 m_coreEnergyMsr;
+    uint32 m_packageEnergyMsr;
+} PwrInternalAddr;
+
+
+#define PWR_MAX_MARKER_CNT          10
+#define PWR_MARKER_BUFFER_SIZE      32
+
+// TODO: This should be ENUM
+// Maker states
+#define PWR_MARKER_DISABLE              0
+#define PWR_MARKER_ENABLE               1
+#define PWR_MARKER_ENABLE_INITIATED     2
+#define PWR_MARKER_DISABLE_INITIATED    3
+
+// MarkerTag Data
+// Start and stop marker tag
+typedef struct MarkerTag
+{
+    uint32     m_markerId;
+    uint32     m_pid;
+    uint32     m_state;
+    uint32     m_fill;
+    uint64     m_ts;
+    uint8      m_name[PWR_MARKER_BUFFER_SIZE];
+    uint8      m_userBuffer[PWR_MARKER_BUFFER_SIZE];
+} MarkerTag;
+
+typedef struct
+{
+    uint32 m_clientId;
+    uint32 m_type;
+    uint64 m_event;
+} EventInfo;
+
+typedef struct
+{
+    uint32 m_count;
+    int    m_fd[MAX_CORE_CNT];
+}SharedFdInfo;
+
+typedef struct
+{
+    uint32 m_startMsrAddr;
+    // for single MSR, start and end will be same
+    uint32 m_endMsrAddr;
+    uint64 m_writeMask;
+}WhitelistedMsrInfo;
+
+typedef enum
+{
+    PWR_UNCONFIGURED,
+    PWR_REGISTERED,
+    PWR_CONFIGURED,
+    PWR_RUNING,
+    PWR_PAUSED,
+    PWR_STOPPED,
+    PWR_STATE_MAX
+} PwrProfState;
diff --git a/drivers/powerprofiler/inc/PwrCounterAccessInterface.h b/drivers/powerprofiler/inc/PwrCounterAccessInterface.h
new file mode 100644
index 000000000000..f9ee649ac46c
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrCounterAccessInterface.h
@@ -0,0 +1,46 @@
+//==================================================================================
+// Copyright (c) 2016 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrCounterAccessInterface.h
+///
+//==================================================================================
+#pragma once
+#include <PwrDriverTypedefs.h>
+#include <PwrDriverInternal.h>
+
+#define MPERF_MSR_ADDRESS      0x000000E7
+#define APERF_MSR_ADDRESS      0x000000E8
+#define P0STATE_MSR_ADDRESS    0xC0010064
+#define MPERF_RO_MSR_ADDRESS   0xC00000E7
+#define APERF_RO_MSR_ADDRESS   0xC00000E8
+#define TSC_MSR_ADDRESS        0x00000010
+
+// CollectBasicCounters: Read basic counters such as sample id, sample spec, timestamp
+bool CollectBasicCounters(CoreData* pCoreCfg,
+                          uint32* pLength);
+
+// CollectPerCoreCounters: Read core specific counters values
+bool CollectNodeCounters(CoreData* pCoreCfg, uint32* pLength);
+
+// InitializeGenericCounterAccess:
+void InitializeGenericCounterAccess(uint32 core);
+
+// CloseGenericCounterAccess
+void CloseGenericCounterAccess(void);
+
+// GetBasicCounterSize
+uint32 GetBasicCounterSize(void);
+
+// GetNodeCounterSize
+uint32 GetNodeCounterSize(uint32 counterId);
+
+void PwrInitializeEffectiveFrequency(uint32 core);
+
+void PwrInitializeBoostedPstate(void);
+
+void PwrReadInitialValues(uint32 threadId);
+
+void PwrInitailizePrevROCefData(int core);
+
+void PwrReadCefROCounters(uint32 core, PwrCefInfo* pCef, bool isCefROSupported, uint32 boostedPstateCnt);
diff --git a/drivers/powerprofiler/inc/PwrDriverInternal.h b/drivers/powerprofiler/inc/PwrDriverInternal.h
new file mode 100644
index 000000000000..826121bddbe1
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrDriverInternal.h
@@ -0,0 +1,62 @@
+//==================================================================================
+// Copyright (c) 2016 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrDriverInternal.h
+///
+//==================================================================================
+#pragma once
+#include <PwrProfInternal.h>
+#include <PwrCommonDataTypes.h>
+#include <PwrAccessPmcData.h>
+
+/// Header buffer size
+
+// Client Data
+// This struct is created when a client registers with the
+// driver. Only one client can be registered with driver due
+// to the SMU limitaiton.
+typedef struct ClientData
+{
+    uint32      m_clientId;
+    uint32      m_validClient;
+    uint32      m_isOffline;
+    uint32      m_configCount;
+    uint32      m_profileState;
+    PageBuffer  m_header;
+    OsClientCfg m_osClientCfg;
+    uint32      m_clientType;
+#if defined (_WIN32)
+    uint32      m_profileType;
+#endif
+} ClientData;
+
+// CoreData
+//
+// This structure holds the data for percore configurations.
+// In windows this structure will be created for configured cores
+// In case of Linux this structure will be created for all available
+// cores in the platform
+typedef struct CoreData
+{
+    uint32               m_clientId;
+    uint32               m_sampleId;
+    uint32               m_profileType;
+    uint32               m_samplingInterval;
+    uint32               m_recLen;
+    uint32               m_coreId;
+    uint32               m_bufferSize;
+    uint32               m_skipFirst;
+    ContextData          m_contextData;
+    PageBuffer*          m_pCoreBuffer;
+    PTARGET_SYSTEM_INFO  m_pSysInfo;
+    uint64               m_counterMask;
+    #if defined (_WIN32)
+    PcoreConfig          m_pcoreCfg;
+    #else
+    struct hrtimer       m_hrTimer;
+    ktime_t              m_interval;
+    #endif
+    PmcCounters          m_pmc[PMC_EVENT_MAX_CNT];
+} CoreData;
+
diff --git a/drivers/powerprofiler/inc/PwrDriverIoctls.h b/drivers/powerprofiler/inc/PwrDriverIoctls.h
new file mode 100644
index 000000000000..5c4b57d2db09
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrDriverIoctls.h
@@ -0,0 +1,145 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfDriver.h
+///
+//==================================================================================
+#pragma once
+
+#if defined(__FreeBSD__)
+#include <sys/ioctl.h>
+#else
+#include <linux/ioctl.h>
+#endif
+#include <PwrCommonDataTypes.h>
+
+#define PWR_PROF_MAJOR_NUMBER  0xCC
+
+/// \def IOCTL_GET_VERSION returns the version encoded in a ULONG64 *
+/// Use InvokeOut
+/// Handled by \ref IoctlGetVersionHandler
+#define IOCTL_GET_VERSION \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 1,unsigned long*)
+
+/// \def IOCTL_REGISTER_CLIENT obtains the client id used for interactions,
+/// both IOCTL and shared memory
+/// Use InvokeOut and a ULONG *
+/// Handled by \ref IoctlRegisterClient
+#define IOCTL_REGISTER_CLIENT \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 2,unsigned long*)
+
+
+/// \def IOCTL_SET_OUTPUT_FILE sets the file path and prd header for the
+/// sampling output files
+/// Use InvokeInOut and \ref OUTPUT_FILE_DESCRIPTOR
+/// Handled by \ref IoctlSetOutputFileHandler
+#define IOCTL_SET_OUTPUT_FILE   \
+    _IOWR(PWR_PROF_MAJOR_NUMBER,3,POUTPUT_FILE_DESCRIPTOR)
+
+
+/// \def IOCTL_ADD_PROF_CONFIGS sets the profiling configurations to profile when
+/// the profiler starts.
+/// Use InvokeInOut and \ref PROF_CONFIGS
+/// Handled by \ref IoctlAddProfConfigsHandler
+#define IOCTL_ADD_PROF_CONFIGS \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 4, PPROF_CONFIGS)
+
+
+/// \def IOCTL_START_PROFILER starts the profile.
+/// Use InvokeInOut and \ref PROFILER_PROPERTIES
+/// Handled by \ref IoctlStartProfilerHandler
+#define IOCTL_START_PROFILER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER,5, PPROFILER_PROPERTIES)
+
+
+/// \def IOCTL_PAUSE_PROFILER pauses the profile.
+/// A faster method is to set the appropriate (1 << clientId) shared memory bit
+/// or to set the shared memory key
+/// Use InvokeInOut and ULONG client id in, ULONG profile state out
+/// Handled by \ref IoctlPauseProfilerHandler
+#define IOCTL_PAUSE_PROFILER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 6, PPROFILER_PROPERTIES)
+
+
+/// \def IOCTL_RESUME_PROFILER resumes the profile.
+/// A faster method is to clear the appropriate (1 << clientId) shared memory
+/// bit or to clear the shared memory key
+/// Use InvokeInOut and ULONG client id in, ULONG profile state out
+/// Handled by \ref IoctlResumeProfilerHandler
+#define IOCTL_RESUME_PROFILER   \
+    _IOWR(PWR_PROF_MAJOR_NUMBER,7 , PPROFILER_PROPERTIES)
+
+
+/// \def IOCTL_GET_FILE_HEADER_BUFFER is to get the file header data
+/// Use InvokeInOut and \ref FILE_HEADER
+/// Handled by \ref IoctlGetFileHeaderBufferHandler
+#define IOCTL_GET_FILE_HEADER_BUFFER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 8, PFILE_HEADER)
+
+/// \def IOCTL_GET_DATA_BUFFER is to get the sample data buffer
+/// Use InvokeInOut and \ref DATA_BUFFER
+/// Handled by \ref IoctlGetDataBufferHandler
+#define IOCTL_GET_DATA_BUFFER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 9,PDATA_BUFFER)
+
+
+/// \def IOCTL_STOP_PROFILER stops the profile.  It will also clear the state
+/// of the clientId.
+/// Use InvokeInOut and ULONG client id in, ULONG profile status out
+/// Handled by \ref IoctlStopProfilerHandler
+#define IOCTL_STOP_PROFILER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 10,PPROFILER_PROPERTIES)
+
+
+/// \def IOCTL_UNREGISTER_CLIENT frees the client id used for interactions,
+/// it will immediately stop and finish any current profile
+/// Use InvokeIn and a ULONG *
+/// Handled by \ref IoctlUnegisterClient
+#define IOCTL_UNREGISTER_CLIENT \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 11, PPROFILER_PROPERTIES)
+
+// \def IOCTL_ACCESS_PCI_DEVICE provides access to PCI devices,
+/// Use InvokeInOut and \ref ACCESS_PCI
+/// Handled by \ref IoctlAccessPciDevice
+#define IOCTL_ACCESS_PCI_DEVICE \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 15, PACCESS_PCI)
+
+#define IOCTL_ACCESS_MSR \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 16, PACCESS_MSR)
+/// \def IOCTL_ACCESS_MMIO provides access to MMIO address space
+/// Use InvokeInOut and \ref ACCESS_MMIO
+/// Handled by \ref IoctlAccessMMIO
+#define IOCTL_ACCESS_MMIO \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 17, PACCESS_MMIO)
+
+/// \def IOCTL_SET_AND_GET_FD create an annonymous inode and
+/// return a  file descriptor for the file.
+#define IOCTL_SET_AND_GET_FD \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 18, int*)
+
+/// \def IOCTL_GET_TARGET_SYSTEM_INFO_BUFFER provides the system information
+/// Use InvokeInOut and ULONG*
+/// Handled by \ref IoctlSetEvent
+/// NOT IN USE. A place holder, to be in sync with Windows driver
+#define IOCTL_GET_TARGET_SYSTEM_INFO_BUFFER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 19, TARGET_SYSTEM_INFO)
+
+/// \def IOCTL_COUT_MODE_PROFILE_CONFIG configures driver to profile
+/// in count mode and return an array of file descriptor for data collection
+/// Use InvokeInOut and CountModeProfileConfig
+/// Handled by \ref
+#define IOCTL_COUNT_MODE_PROFILE_CONFIG \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 20, CountModeProfileConfig)
+
+/// \def IOCTL_CLEAR_PROFILER clears the profiler configuration
+/// Use InvokeInOut and \ref PROFILER_PROPERTIES
+/// Handled by \ref
+#define IOCTL_CLEAR_PROFILER \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 21, PPROFILER_PROPERTIES)
+
+#define IOCTL_COUNT_MODE_CONFIG_EXTND \
+        _IOWR(PWR_PROF_MAJOR_NUMBER, 22, PPROFILER_PROPERTIES)
+
+#define IOCTL_ACCESS_SMN \
+    _IOWR(PWR_PROF_MAJOR_NUMBER, 23, PACCESS_SMN)
diff --git a/drivers/powerprofiler/inc/PwrDriverTypedefs.h b/drivers/powerprofiler/inc/PwrDriverTypedefs.h
new file mode 100644
index 000000000000..62e2d02a6118
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrDriverTypedefs.h
@@ -0,0 +1,118 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrDriverTypedefs.h
+///
+//==================================================================================
+#pragma once
+#define SMU_REG_ADDRESS_UNDEFINED 0xFFFFFF
+#ifdef _WIN32
+typedef __int8  int8;
+typedef __int16 int16;
+typedef __int32 int32;
+typedef __int64 int64;
+
+typedef unsigned __int8  uint8;
+typedef unsigned __int16 uint16;
+typedef unsigned __int32 uint32;
+typedef unsigned __int64 uint64;
+
+typedef unsigned __int8  uint8_t;
+typedef unsigned __int16 uint16_t;
+typedef unsigned __int32 uint32_t;
+typedef unsigned __int64 uint64_t;
+typedef uint8 byte;
+typedef uint32 atomic;
+
+// Atomic Operations
+#define ATOMIC_SET(x, y) InterlockedExchange((volatile LONG*)x, y)
+#define ATOMIC_GET(x, y) InterlockedExchange((volatile LONG*)x, y)
+#define ATOMIC_CMPEXCHANGE(x, y, z) InterlockedCompareExchange((LONG volatile*)x, y, z)
+#define WRITE_DWORD(x,y)  *(uint32*)(x) = y
+#define READ_DWORD(x)     (*(uint32*)(x))
+
+#else
+
+#ifdef KERNEL_MODULE
+    #include <linux/types.h>
+    #include <linux/string.h>
+    #include <linux/kernel.h>
+    typedef int wchar_t;
+    #define STATUS_SUCCESS 0
+    #define STATUS_NO_MEMORY -1
+    #define STATUS_INVALID_PARAMETER -2
+    #define STATUS_ACCESS_DENIED -3
+#else
+    #include <stdint.h>
+#endif
+
+typedef int8_t  int8;
+typedef int16_t int16;
+typedef int32_t int32;
+typedef int64_t int64;
+
+typedef uint8_t  uint8;
+typedef uint16_t uint16;
+typedef uint32_t uint32;
+typedef uint64_t uint64;
+typedef uint8_t  byte;
+#ifdef __KERNEL__
+    typedef atomic_t atomic;
+#else
+    typedef uint32 atomic;
+#endif
+
+// Atomic functions
+#ifdef __KERNEL__
+    #define ATOMIC_SET(x, y)    atomic_set(x, y)
+#else
+    #define ATOMIC_SET(x, y)    __sync_lock_test_and_set(x, y)
+#endif
+
+#define ATOMIC_GET(x, y)    *(int *)x  = atomic_read(&y)
+// if current value of *x is z, then write y into *x
+#define ATOMIC_CMPEXCHANGE(x, y, z) __sync_val_compare_and_swap((int*)&x, z, y)
+
+#define WRITE_DWORD(x,y)    write_dword(x,y)
+#define READ_DWORD(x)       read_dword(x)
+
+#define INVALID_HANDLE_VALUE -1
+// For Compatability with Windows types
+
+typedef union _ULARGE_INTEGER
+{
+
+    struct
+    {
+        uint32_t LowPart;
+        uint32_t HighPart;
+    };
+    struct
+    {
+        uint32_t LowPart;
+        uint32_t HighPart;
+    } u;
+    uint64_t    QuadPart;
+
+} ULARGE_INTEGER;
+
+typedef union _LARGE_INTEGER
+{
+    struct
+    {
+        int32_t LowPart;
+        int32_t  HighPart;
+    };
+    struct
+    {
+        int32_t LowPart;
+        int32_t HighPart;
+    } u;
+    int64_t QuadPart;
+} LARGE_INTEGER, *PLARGE_INTEGER;
+
+typedef int HANDLE;
+
+#endif // For __linux__
+
diff --git a/drivers/powerprofiler/inc/PwrDriverUtils.h b/drivers/powerprofiler/inc/PwrDriverUtils.h
new file mode 100644
index 000000000000..8e8c253b476c
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrDriverUtils.h
@@ -0,0 +1,205 @@
+//==================================================================================
+// Copyright (c) 2016 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrDriverUtils.h
+///
+//==================================================================================
+#pragma once
+#include <PwrDriverInternal.h>
+#include <PwrCommonDataTypes.h>
+
+typedef union CpuInfo
+{
+    struct _info
+    {
+        /// Bits[3:0] The Cpu stepping
+        uint32 stepping : 4;
+        /// Bits[7:4] The Cpu base model (model bits [3:0])
+        uint32 model : 4;
+        /// Bits[11:8] The Cpu base family
+        uint32 family : 4;
+        /// Bits[15:12] Reserved
+        uint32 unknown1 : 4;
+        /// Bits[19:16] The Cpu extended model (model bits[7:4])
+        uint32 extModel : 4;
+        /// Bits[27:20] The Cpu extended family (family = family + extFamily)
+        uint32 extFamily : 8;
+        /// Bits[31:28] Reserverd
+        uint32 unknown2 : 4;
+    } info;
+    /// The value of the EAX register
+    uint32 eax;
+} CpuInfo;
+
+
+// GetTargetCoreCount
+uint32 GetTargetCoreCount(void);
+
+//GetCpuModelFamily - get CPU family id and model id
+void GetCpuModelFamily(uint32* family, uint32* model);
+
+//Is profile stopping
+bool IsStoping(void);
+
+//AccessPciAddress: Read or Write PCI address
+bool AccessPciAddress(PACCESS_PCI pData);
+
+//AccessMSRAddress: Read or write generic MSR
+bool AccessMSRAddress(PACCESS_MSR pData);
+
+// GetBitsCount: Count number of bits set
+void GetBitsCount(uint64 mask, uint32* pCount);
+
+//Is profile stopping
+bool IsStarted(void);
+
+// IsCefSupported
+bool IsCefSupported(void);
+
+// IsROCefAvailable
+bool IsROCefAvailable(void);
+
+uint64 GmmxGetBaseAddress(uint32 gpuAddr);
+
+
+// Raw data file functions
+bool GetRequiredBufferLength(CoreData* cfg, uint32* pLength);
+
+#if defined(__linux__)
+void AccessPci(PACCESS_PCI pData);
+
+void AccessMSR(PACCESS_MSR pData);
+
+void ReadCpuSignature(CpuSignature* cpu);
+
+CpuSignature* GetCpuSignature(void);
+
+bool IsAmd(CpuSignature* cpu);
+
+uint GetFamilyValue(CpuSignature* cpu);
+
+uint GetModelValue(CpuSignature* cpu);
+
+long CheckHwSupport(void);
+
+uint32 GetCuCountPerNode(void);
+
+void IRPerfDpc(void* info);
+
+uint32 GetMarkerKey(uint8* str);
+
+void GetMarkerRecords(MarkerTag* pTags, uint32* pCount);
+#endif
+
+int32 WriteSampleData(CoreData* cfg);
+
+int32 WriteRawBufferHeader(RawFileHeader* pHeader, uint16 sectionCnt);
+
+int32 WriteSectionHeaders(SectionHdrInfo* secHeader, uint64 secHeaderMask);
+
+int32 UpdateBufferHeader(ClientData* pClient, uint16 field);
+
+int32 WriteSampleCfgInfo(ClientData* pData, PROF_CONFIGS* pSrcCfg);
+
+int32 WriteSampleInfo(ClientData* pClient);
+
+int32 WriteSections(ClientData* pClient, PROF_CONFIGS* pSrcCfg, uint64 secMask);
+
+int32 WriteHeader(ClientData* pClient, PROF_CONFIGS* pSrcCfg);
+
+bool IsPMCCounterAvailable(void);
+
+uint32 PwrGetLogicalProcessCount(void);
+
+bool PwrIsSmtEnabled(void);
+
+// PwrEnablePerf: Enable perf bit
+void PwrEnablePerf(bool enable);
+
+
+// PwrReadCpuId : Read the Cpuid instruction
+uint32 PwrReadCpuId(RegisterOffset regId, uint32 functionId);
+
+// Get ccx count
+uint32_t GetCcxCount(void);
+
+// Get socket count
+uint32_t GetSocketCount(void);
+
+// Get node Id
+uint32_t GetNodeIdForCore(uint32_t coreId);
+
+// Get socket Id
+uint32_t GetSocketIdForCore(uint32_t coreId);
+
+// Get zen version
+uint32_t GetZenVersion(void);
+
+// GetTargetSystemInfo: Get the target system info
+void GetTargetSystemInfo(PTARGET_SYSTEM_INFO* pTargetInfo, bool reset);
+
+// PwrIsRAPLAvailable: Check is RAPL counters are available
+// Available only on family17
+bool PwrIsRAPLAvailable(void);
+
+// PwrIsHyperVisor: check if hypervisor is enabled
+bool PwrIsHyperVisor(void);
+
+// PwrIsIGPUAvailable: Check if iGPU is available with B0D1F0x18 register
+// refer to the BKDG for this register. Available only in family 15 & 16
+bool PwrIsIGPUAvailable(void);
+
+void PwrSetExtendedApicId(TARGET_SYSTEM_INFO* pTargetInfo);
+
+void PwrSetExtPerfMonAndDbgInfo(TARGET_SYSTEM_INFO* pTargetInfo);
+
+// PwrGetSetBitIndex: Get the index of nth set set
+uint32 PwrGetSetBitIndex(uint32 setBitId, uint32 bitMask);
+
+// Read SMN Interface
+void SmnRead(uint32 bus, uint32 address, uint32* pData);
+
+// Write SMN Interface
+void SmnWrite(uint32 bus, uint32 address, uint32 data);
+
+bool AccessSMN(TARGET_SYSTEM_INFO* pTargetInfo, ACCESS_SMN* pSmn);
+
+// Access MMIO word
+bool AccessMMIO(ACCESS_MMIO* pMMIO);
+
+uint32 GetFirstBitSet(uint64 num);
+
+uint32 GetBitCount(uint64 val);
+
+uint32 GetBitCountExt(uint64* pVal);
+
+uint32 ReadPCIDev(uint32 bus, uint32 device, uint32 func, uint32 reg);
+
+void WritePCIDev(uint32 bus, uint32 device, uint32 func, uint32 reg, uint32 data);
+
+bool EnableIRPerf(PTARGET_SYSTEM_INFO pTargetInfo);
+
+void InitStatus(void);
+
+bool IsExtApicIsAvailable(void);
+
+bool IsExtnTopology(void);
+
+uint32 CoreMaskWidth(void);
+
+uint32 ThreadsPerCcx(void);
+
+bool IsIrPerfAvailable(void);
+
+bool IsAMDPlatform(void);
+
+bool IsRAPLAvailable(void);
+
+bool IsHyperVisor(void);
+
+bool IsHost(void);
+
+bool IsRootPartition(void);
+
+
diff --git a/drivers/powerprofiler/inc/PwrOsPrimitives.h b/drivers/powerprofiler/inc/PwrOsPrimitives.h
new file mode 100644
index 000000000000..7520e04bbb3f
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrOsPrimitives.h
@@ -0,0 +1,163 @@
+//==================================================================================
+// Copyright (c) 2019 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrOsPremitives.h
+///
+//==================================================================================
+#pragma once
+// LOCAL INCLUDES
+#include <PwrDriverTypedefs.h>
+#ifdef _WIN32
+    #include <ntifs.h>
+
+    #ifdef DEBUG
+        #define DRVPRINT(fmt, ...)    DbgPrint( "PwrProf: %s, "fmt "\n",__FUNCTION__, __VA_ARGS__)
+    #else
+        #define DRVPRINT(fmt, ...) {}
+    #endif
+    #define DRVPRINTERROR(fmt, ...)    DbgPrint( "PwrProf: %s, "fmt "\n",__FUNCTION__, __VA_ARGS__)
+    #define WriteMemBarrier()
+#endif
+#if defined (__linux__)
+    #ifdef DEBUG
+        #define DRVPRINT(fmt, ...)   printk("%s:%d " fmt "\n", __FUNCTION__, __LINE__, ##__VA_ARGS__);
+    #else
+        #define DRVPRINT(fmt, ...) {}
+    #endif
+    #define DRVPRINTERROR(fmt, ...)   printk("%s:%d " fmt "\n", __FUNCTION__, __LINE__, ##__VA_ARGS__);
+    #include <asm/barrier.h>
+    #define WriteMemBarrier()   smp_wmb()
+#endif
+
+// While DF internal ini is configured it needs a big pool of memory
+#define DATA_PAGE_BUFFER_SIZE 1638400 // 400 X 4096
+#define MCFG_BASE_ADDRESS  0xC0010058
+
+// LOCAL DEFINES
+typedef union _PciExtendedConfigurationSpaceAddress
+{
+    // \brief The elements that make up a PCI address in PCI config space
+    struct
+    {
+        // base register address to access
+        unsigned int m_reg : 8;
+        // function number to access
+        unsigned int m_function : 3;
+        // device number to access
+        unsigned int m_device : 5;
+        // bus number to access
+        unsigned int m_bus : 8;
+        // extended register number to access
+        unsigned int m_extReg : 4;
+        // reserved, must be 0
+        unsigned int m_reserved : 3;
+        // Configuration space enable, 1 = IO read and write accesses to
+        // IOCFC are translated into configuration cycles at the
+        // configuration address
+        unsigned int m_configEn : 1;
+    } element;
+    // The equivalent IO-space configuration address made up of each \ref Element
+    uint32 m_address;
+} PciExtendedConfigurationSpaceAddress;
+
+//MemoryPool: create memory pool for internal use
+typedef struct
+{
+    void* m_pBase;
+    uint32 m_offset;
+    uint32 m_size;
+} MemoryPool;
+
+typedef struct
+{
+    bool m_isIrperf;
+    bool m_isMperf;
+    bool m_isAperf;
+    bool m_isRapl;
+}MsrStatus;
+
+#if defined (__linux__)
+    #include <asm/io.h>
+    extern MemoryPool g_sessionPool;
+    #define SESSION_POOL_SIZE 1024
+
+    // Create memory pool
+    bool CreateMemoryPool(MemoryPool* pPool, uint32 size);
+
+    // Get buffer from the pool
+    uint8* GetMemoryPoolBuffer(MemoryPool* pPool, uint32 size);
+
+    // Delete the memory pool
+    bool ReleaseMemoryPool(MemoryPool* pPool);
+
+    void PrepareAffinityMask(cpumask_t* pm_affinity, uint64 mask[]);
+
+    int GetCoreId(void);
+
+#else
+    // CreateMemoryPool: Create memory pool
+    bool CreateMemoryPool();
+
+    // GetMemoryPoolBuffer: Get buffer from the pool
+    void* GetMemoryPoolBuffer(uint32 size, bool resetMem);
+
+    // ReleaseMemoryPoo: lDelete the memory pool
+    bool ReleaseMemoryPool();
+
+    // ResetPoolMemory: Set the memory to 0
+    void ResetPoolMemory(void* pBuffer, uint32 size);
+#endif
+
+// SetMsrStatus: check availability of Msr
+void SetMsrStatus(void);
+
+uint64 ReadMSR(uint32 reg);
+
+void WriteMSR(uint32 reg, uint64 val);
+
+uint32 ReadPCI(uint32 addr);
+
+void WritePCI(uint32 addr, uint32 data);
+
+bool MapMMIOSpace(uint64  address, size_t  size, uint64* pMapAddress, uint64* pMapSize);
+
+bool UnmapMMIOSpace(uint64 mappedAddress, uint64 mappedSize);
+
+void ReadCPUID(int32* pInfo, uint32 identifier);
+
+void ReadCPUIDEx(int32* pInfo, uint32 indentifier, uint32 sub);
+
+void GetTimeStamp(uint64* pTime);
+
+uint32 GetOnlineCpus(void);
+
+uint32 GetCurrentCoreId(void);
+
+void GetPerformanceCounter(uint64* pPerfCounter, uint64* pFrequency);
+
+bool AcquirePCMCountersLock(void);
+
+bool ReleasePCMCountersLock(void);
+
+bool DeferedCoreExecution(uint32 core, void* pRoutine, void* pContext);
+
+int ExecuteOnCore(int coreId, void* pFunc, void* arg);
+
+void* AllocateMemory(uint32_t size);
+
+int GetCoreCount(void);
+
+void FreeMemory(void* obj);
+
+uint64_t GetTimestamp(void);
+
+void WritePCI32(uint32 address, uint32 data, uint32 mask);
+
+uint32 ReadMMIO(uint32 addr, uint64_t* val, bool map);
+
+uint32 WriteMMIO(uint32 addr, uint32 data, bool map);
+
+void readCPUID(uint32 index, uint32 index2, uint32* peax, uint32* pebx, uint32* pecx, uint32* pedx);
+
+void AccessPciExt(uint32 addr, uint32* pData, bool isRead);
diff --git a/drivers/powerprofiler/inc/PwrProfAsm.h b/drivers/powerprofiler/inc/PwrProfAsm.h
new file mode 100644
index 000000000000..869b214eeeb3
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfAsm.h
@@ -0,0 +1,408 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfAsm.c
+///
+//==================================================================================
+
+#pragma once
+#ifdef __x86_64
+
+#undef read_cr2
+#define read_cr2() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__ ( \
+                               "movq %%cr2,%0\n\t" \
+                               :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#undef read_cr3
+#define read_cr3() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%cr3,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr0() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr0,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr1() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr1,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr2() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr2,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr3() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr3,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr4() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr4,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr5() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr5,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr6() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr6,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr7() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movq %%dr7,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#undef write_cr2
+#undef write_cr3
+#define write_cr2(x) __asm__ __volatile__("movq %0,%%cr2": :"r" (x));
+#define write_cr3(x) __asm__ __volatile__("movq %0,%%cr3": :"r" (x));
+#define write_dr0(x) __asm__ __volatile__("movq %0,%%dr0": :"r" (x));
+#define write_dr1(x) __asm__ __volatile__("movq %0,%%dr1": :"r" (x));
+#define write_dr2(x) __asm__ __volatile__("movq %0,%%dr2": :"r" (x));
+#define write_dr3(x) __asm__ __volatile__("movq %0,%%dr3": :"r" (x));
+#define write_dr4(x) __asm__ __volatile__("movq %0,%%dr4": :"r" (x));
+#define write_dr5(x) __asm__ __volatile__("movq %0,%%dr5": :"r" (x));
+#define write_dr6(x) __asm__ __volatile__("movq %0,%%dr6": :"r" (x));
+#define write_dr7(x) __asm__ __volatile__("movq %0,%%dr7": :"r" (x));
+
+#ifndef AMD_TARGET_PUBLIC
+#define rdsasmsrd(msr,ebxValue,esiValue,password,result) ({ \
+        __asm__ __volatile__( \
+                              "rdmsr\n" \
+                              :"=a"(result) \
+                              :"b"(ebxValue), "c"(msr), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+
+#define rdsasmsrq(msr,ebxValue,esiValue,password,result) ({ \
+        __asm__ __volatile__( \
+                              "rdmsr\n" \
+                              "shlq $32, %%rdx\n" \
+                              "movl %%eax, %%eax\n" \
+                              "orq  %%rdx, %%rax\n" \
+                              :"=A"(result) \
+                              :"b"(ebxValue), "c"(msr), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+
+#define wrsasmsrd(msr,ebxValue,esiValue,password,value) ({ \
+        __asm__ __volatile__( \
+                              "wrmsr\n" \
+                              : \
+                              :"a"(value), "b"(ebxValue), "c"(msr), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+
+#define wrsasmsrq(msr,ebxValue,esiValue,password,value) ({ \
+        __asm__ __volatile__( \
+                              "movq %%rax, %%rdx\n" \
+                              "shrq $32, %%rdx\n" \
+                              "wrmsr\n" \
+                              : \
+                              :"A"(value), "b"(ebxValue), "c"(msr), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+#endif
+#define flushtlball_and_wrmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "movq %%cr4,%%rbx\n\t" \
+                              "xorq $0x00000040, %%rbx\n\t" \
+                              "movq %%rbx, %%cr4\n\t" \
+                              "xorq $0x00000040, %%rbx\n\t" \
+                              "movq %%rbx, %%cr4\n\t" \
+                              "wrmsr\n\t" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "D"(val3), "S"(val4) \
+                              :"rbx" \
+                            ); \
+    })
+
+#define flushtlblocal_and_wrmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "movq %%cr3,%%rbx\n\t" \
+                              "movq %%rbx,%%cr3\n\t" \
+                              "wrmsr\n" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "D"(val3), "S"(val4) \
+                              :"rbx" \
+                            ); \
+    })
+
+#define read_qword(address) ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__ ( \
+                               "movq (%1),%0\n\t" \
+                               :"=a" (__dummy) \
+                               :"r" (address) \
+                             ); \
+        __dummy; \
+    })
+
+#define write_qword(address,value) __asm__ __volatile__("movq %0,(%1)": :"a" (value), "r" (address) );
+
+#else
+
+#define read_cr2() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%cr2,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+#define read_cr3() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%cr3,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr0() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr0,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr1() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr1,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr2() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr2,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr3() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr3,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr4() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr4,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr5() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr5,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr6() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr6,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define read_dr7() ({ \
+        unsigned long __dummy; \
+        __asm__ __volatile__( \
+                              "movl %%dr7,%0\n\t" \
+                              :"=r" (__dummy)); \
+        __dummy; \
+    })
+
+#define write_cr2(x) __asm__ __volatile__("movl %0,%%cr2": :"r" (x));
+#define write_cr3(x) __asm__ __volatile__("movl %0,%%cr3": :"r" (x));
+#define write_dr0(x) __asm__ __volatile__("movl %0,%%dr0": :"r" (x));
+#define write_dr1(x) __asm__ __volatile__("movl %0,%%dr1": :"r" (x));
+#define write_dr2(x) __asm__ __volatile__("movl %0,%%dr2": :"r" (x));
+#define write_dr3(x) __asm__ __volatile__("movl %0,%%dr3": :"r" (x));
+#define write_dr4(x) __asm__ __volatile__("movl %0,%%dr4": :"r" (x));
+#define write_dr5(x) __asm__ __volatile__("movl %0,%%dr5": :"r" (x));
+#define write_dr6(x) __asm__ __volatile__("movl %0,%%dr6": :"r" (x));
+#define write_dr7(x) __asm__ __volatile__("movl %0,%%dr7": :"r" (x));
+
+#ifndef AMD_TARGET_PUBLIC
+#define rdsasmsrd(msr,ebxValue,esiValue,password,result) ({ \
+        __asm__ __volatile__( \
+                              "rdmsr\n" \
+                              :"=a"(result) \
+                              :"b"(ebxValue), "c"(msr), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+
+#define rdsasmsrq(msr,ebxValue,esiValue,password,result) ({ \
+        __asm__ __volatile__( \
+                              "rdmsr\n" \
+                              :"=A"(result) \
+                              :"b"(ebxValue), "c"(msr), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+
+#define wrsasmsrd(msr,ebxValue,esiValue,password,value) ({ \
+        __asm__ __volatile__( \
+                              "wrmsr\n" \
+                              : \
+                              :"a"(value), "c"(msr), "b"(ebxValue), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+
+#define wrsasmsrq(msr,ebxValue,esiValue,password,value) ({ \
+        __asm__ __volatile__( \
+                              "wrmsr\n" \
+                              : \
+                              :"A"(value), "c"(msr), "b"(ebxValue), "D"(password), "S"(esiValue) \
+                            ); \
+    })
+#endif
+#define flushtlball_and_wrmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "movl %%cr4,%%ebx\n\t" \
+                              "xorl $0x00000040, %%ebx\n\t" \
+                              "movl %%ebx, %%cr4\n\t" \
+                              "xorl $0x00000040, %%ebx\n\t" \
+                              "movl %%ebx, %%cr4\n\t" \
+                              "wrmsr\n\t" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "D"(val3), "S"(val4) \
+                              :"ebx" \
+                            ); \
+    })
+
+#define flushtlblocal_and_wrmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "movl %%cr3,%%ebx\n\t" \
+                              "movl %%ebx,%%cr3\n\t" \
+                              "wrmsr\n" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "D"(val3), "S"(val4) \
+                              :"ebx" \
+                            ); \
+    })
+
+#endif
+
+#define rdmsrq(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "rdmsr\n" \
+                              :"=a"(val1), "=d"(val2), "=S"(val3), "=D"(val4) \
+                              :"c"(msr) \
+                            ); \
+    })
+
+#define wrmsrq(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "wrmsr\n" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "S"(val3), "D"(val4) \
+                            ); \
+    })
+
+#define rdmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "rdmsr\n" \
+                              :"=a"(val1), "=d"(val2) \
+                              :"c"(msr), "D"(val3), "S"(val4) \
+                            ); \
+    })
+
+#define wrmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "wrmsr\n" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "D"(val3), "S"(val4) \
+                            ); \
+    })
+
+#define flushcache_and_wrmsrpw(msr,val1,val2,val3,val4) ({ \
+        __asm__ __volatile__( \
+                              "wbinvd\n" \
+                              "wrmsr\n" \
+                              : \
+                              :"c"(msr), "a"(val1), "d"(val2), "D"(val3), "S"(val4) \
+                            ); \
+    })
+
+#define read_byte(address) ({ \
+        unsigned char __dummy; \
+        __asm__ __volatile__ ( \
+                               "movb (%1),%0\n\t" \
+                               :"=a" (__dummy) \
+                               :"r" (address) \
+                             ); \
+        __dummy; \
+    })
+
+#define read_word(address) ({ \
+        unsigned short int __dummy; \
+        __asm__ __volatile__ ( \
+                               "movw (%1),%0\n\t" \
+                               :"=a" (__dummy) \
+                               :"r" (address) \
+                             ); \
+        __dummy; \
+    })
+
+#define read_dword(address) ({ \
+        unsigned int __dummy; \
+        __asm__ __volatile__ ( \
+                               "movl (%1),%0\n\t" \
+                               :"=a" (__dummy) \
+                               :"r" (address) \
+                             ); \
+        __dummy; \
+    })
+
+#define write_byte(address,value) __asm__ __volatile__("movb %0,(%1)": :"a" (value), "r" (address) );
+#define write_word(address,value) __asm__ __volatile__("movw %0,(%1)": :"a" (value), "r" (address) );
+#define write_dword(address,value) __asm__ __volatile__("movl %0,(%1)": :"a" (value), "r" (address) );
+
diff --git a/drivers/powerprofiler/inc/PwrProfCpuid.h b/drivers/powerprofiler/inc/PwrProfCpuid.h
new file mode 100644
index 000000000000..669e41f21826
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfCpuid.h
@@ -0,0 +1,68 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfCpuid.h
+///
+//==================================================================================
+#pragma once
+
+#define CPUID_FnVendorIdentification 0
+#define CPUID_FnBasicFeatures 1
+// LogicalProcessorCount: logical processor count
+#define CPUID_FnBasicFeatures_EBX_LogicalProcessorCount_OFFSET 16
+#define CPUID_FnBasicFeatures_EBX_LogicalProcessorCount (0xFF << CPUID_FnBasicFeatures_EBX_LogicalProcessorCount_OFFSET)
+// LocalApicId: initial local APIC physical ID
+#define CPUID_FnBasicFeatures_EBX_LocalApicId_OFFSET 24
+#define CPUID_FnBasicFeatures_EBX_LocalApicId (0xFF << CPUID_FnBasicFeatures_EBX_LocalApicId_OFFSET)
+// Hypervisor: used by hypervisor to indicate guest status
+#define CPUID_FnBasicFeatures_ECX_Hypervisor (1 << 31)
+// APIC: advanced programmable interrupt controller (APIC) exists and is enabled
+#define CPUID_FnBasicFeatures_EDX_APIC (1 << 9)
+#define CPUID_FnThermalAndPowerManagement 6
+// ARAT: always running APIC timer
+#define CPUID_FnThermalAndPowerManagement_EAX_ARAT (1 << 2)
+// EffFreq: effective frequency interface
+#define CPUID_FnThermalAndPowerManagement_ECX_EffFreq (1 << 0)
+#define CPUID_FnExtendedVendorIdentification 0x80000000
+#define CPUID_FnAmdExtendedFeatures 0x80000001
+// IBS: Instruction Based Sampling
+#define CPUID_FnAmdExtendedFeatures_ECX_IBS (1 << 10)
+// PerfCtrExtCore: core performance counter extensions support
+#define CPUID_FnAmdExtendedFeatures_ECX_PerfCtrExtCore (1 << 23)
+// PerfCtrExtNB: NB performance counter extensions support
+#define CPUID_FnAmdExtendedFeatures_ECX_PerfCtrExtNB (1 << 24)
+// PerfCtrExtL2I: L2I performance counter extensions support
+#define CPUID_FnAmdExtendedFeatures_ECX_PerfCtrExtL2I (1 << 28)
+#define CPUID_FnSizeIdentifiers 0x80000008
+// ApicIdCoreIdSize: APIC ID size
+#define CPUID_FnSizeIdentifiers_ECX_ApicIdCoreIdSize_OFFSET 12
+#define CPUID_FnSizeIdentifiers_ECX_ApicIdCoreIdSize (0xF << CPUID_FnSizeIdentifiers_ECX_ApicIdCoreIdSize_OFFSET)
+#define CPUID_FnL1CacheIdentifiers 0x80000005
+#define CPUID_FnL2L3CacheIdentifiers 0x80000006
+#define CPUID_FnProcessorCapabilities 0x80000007
+#define CPUID_FnTLB1GIdentifiers 0x80000019
+#define CPUID_FnIbsIdentifiers 0x8000001B
+// RdWrOpCnt: read write of op counter supported
+#define CPUID_FnIbsIdentifiers_EAX_RdWrOpCnt (1 << 3)
+// BrnTrgt: branch target address reporting supported
+#define CPUID_FnIbsIdentifiers_EAX_BrnTrgt (1 << 5)
+// OpCntExt: IbsOpCurCnt and IbsOpMaxCnt extend by 7 bits
+#define CPUID_FnIbsIdentifiers_EAX_OpCntExt (1 << 6)
+// RipInvalidChk: invalid RIP indication supported
+#define CPUID_FnIbsIdentifiers_EAX_RipInvalidChk (1 << 7)
+#define CPUID_FnIdentifiers 0x8000001E
+#define CPUID_FnIdentifiers_ECX_NodeId 0xF
+
+#define CPUID_FnHyperVFeature 0x40000003
+
+#define CPUID_MASK_TOPO_EXTN 0x400000
+#define CPUID_MASK_HYPERVISOR 0x80000000
+#define CPUID_FnProcessorVendorAndLargestStdFuncNum 0x0
+#define CPUID_HypervisorMask 0x80000000
+#define CPUID_FnExtendedTopology 0x0000000B
+#define CPUID_FnAdvancePowerManagementInfo 0x80000007
+#define CPUID_FnFeatureRapl (1 << 14)
+#define CPUID_FnCacheProperties 0x8000001D
+
+
diff --git a/drivers/powerprofiler/inc/PwrProfDebugHelper.h b/drivers/powerprofiler/inc/PwrProfDebugHelper.h
new file mode 100644
index 000000000000..2cbd1c66f8d3
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfDebugHelper.h
@@ -0,0 +1,18 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfDebugHelper.h
+///
+//==================================================================================
+#pragma once
+
+#ifdef DEBUG
+
+    void PrintPageBuffer(const PageBuffer* pPageBuffer);
+    void PrintSmuInfo(const SmuInfo* pSmuInfo);
+    void PrintSmuList(const SmuList* pSmuList);
+    void PrintClientData(const ClientData* pClientData);
+    void PrintCoreData(const CoreData* pCoreData);
+
+#endif // DEBUG
diff --git a/drivers/powerprofiler/inc/PwrProfInternal.h b/drivers/powerprofiler/inc/PwrProfInternal.h
new file mode 100644
index 000000000000..29e7c10cade0
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfInternal.h
@@ -0,0 +1,49 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfInternal.h
+///
+//==================================================================================
+#pragma once
+
+// SYSTEM INCLUDES
+#include <linux/hrtimer.h>
+#include <linux/timer.h>
+#include <linux/ktime.h>
+#include <linux/spinlock.h>
+
+// LOCAL INCLUDES
+#include <PwrProfAsm.h>
+#include <PwrCommonDataTypes.h>
+
+typedef enum
+{
+    // Family is an 8-bit value and is defined as:
+    // Family[7:0] = ({0000b,BaseFamily[3:0]} + ExtFamily[7:0]).
+    CpuBaseFamily_MASK = 0xFU << 8,
+    CpuExtFamily_MASK = 0xFFU << 20,
+
+    // Model is an 8-bit value and is defined as:
+    // Model[7:0] = {ExtModel[3:0], BaseModel[3:0]}.
+    CpuBaseModel_MASK = 0xFU << 4,
+    CpuExtModel_MASK = 0xFU << 16,
+
+    CpuStepping_MASK = 0xFU << 0,
+} Mask;
+
+
+typedef struct _CpuSignature
+{
+    uint  m_value;
+    bool  m_isHypervisor;
+} CpuSignature;
+
+typedef struct
+{
+    cpumask_t           m_affinity;
+    bool                m_paused;
+    bool                m_stopped;
+    pid_t               m_parentPid;
+} OsClientCfg;
+
diff --git a/drivers/powerprofiler/inc/PwrProfSharedMemOps.h b/drivers/powerprofiler/inc/PwrProfSharedMemOps.h
new file mode 100644
index 000000000000..afbf449d1e2d
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfSharedMemOps.h
@@ -0,0 +1,20 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfSharedMemOps.h
+///
+//==================================================================================
+#pragma once
+
+int CreateAnonInodeFd(unsigned int cpuId);
+
+typedef struct PwrMmapCtx
+{
+    unsigned int     m_cpuId;
+    atomic_t         m_mmapCount;
+    unsigned int     m_order;
+    size_t           m_mmapSize;
+    uint64_t         m_mmapAddress;
+    unsigned int     m_flags;
+}PwrMmapCtx;
\ No newline at end of file
diff --git a/drivers/powerprofiler/inc/PwrProfTimer.h b/drivers/powerprofiler/inc/PwrProfTimer.h
new file mode 100644
index 000000000000..e9589f9ff308
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfTimer.h
@@ -0,0 +1,51 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfTimer.h
+///
+//==================================================================================
+#pragma once
+
+#include <PwrDriverTypedefs.h>
+#include <PwrCommonDataTypes.h>
+
+// Configure Timer for sampling period specified, set the callback
+// function to be invoked when sampling duration expires.
+int ConfigureTimer(PROF_CONFIGS* config, uint32 clientId);
+
+// Unconfigure timer, delete it from timer list
+int UnconfigureTimer(uint32 clientId);
+
+// Invoked when profiling starts, add a timer for sampling time.
+int StartTimer(uint32 clientId);
+
+// Stop timer for the specified client id release the memory allocated for timer.
+int StopTimer(uint32 clientId);
+
+// Pause Timer for the specified client id
+int PauseTimer(uint32 clientId);
+
+
+//Resume Timer for the specified client id
+int ResumeTimer(uint32 clientId);
+
+// Get header buffer for the kernel space convert it into user space.
+int GetHeaderBuffer(PFILE_HEADER fileHeader);
+
+// Get data buffer for the counter
+int GetDataBuffer(PDATA_BUFFER dataBuffer);
+
+bool CheckParentPid(pid_t parentPid);
+
+void SetInstructionPointer(uint32* isKernel, uint64* ip);
+
+int SampleDataCallback(ClientData* pClientData);
+
+void StartHrTimer(void);
+
+enum hrtimer_restart HrTimerCallback(struct hrtimer* timer_for_restart);
+
+void InitHrTimer(uint32 cpu);
+
+void Initialize(void);
diff --git a/drivers/powerprofiler/inc/PwrProfTimerHelper.h b/drivers/powerprofiler/inc/PwrProfTimerHelper.h
new file mode 100644
index 000000000000..98c8ebf09278
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrProfTimerHelper.h
@@ -0,0 +1,40 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfTimerHelper.c
+///
+//==================================================================================
+#pragma once
+
+#include <PwrDriverInternal.h>
+
+// AllocateAndInitClientData
+//
+// Allocate and Initialise Client Data
+int AllocateAndInitClientData(ClientData** ppClientData,
+                              uint32 clientId,
+                              cpumask_t affinity,
+                              pid_t parentPID,
+                              const PROF_CONFIGS* config);
+
+// IntialiseCoreData
+//
+// Initialise and  per core data
+int IntializeCoreData(CoreData* pCoreClientData,
+                      int index,
+                      bool* isFirstConfig,
+                      uint32 clientId,
+                      uint32 coreId,
+                      PROF_CONFIGS* config);
+
+// FreeClientData
+//
+// Free Memmory set by client data
+void FreeClientData(ClientData* pClientData);
+
+// FreeCoreData
+//
+// Free Memory created for each core
+void FreeCoreData(CoreData* pCoreClientData);
+
diff --git a/drivers/powerprofiler/inc/PwrSharedBufferConfig.h b/drivers/powerprofiler/inc/PwrSharedBufferConfig.h
new file mode 100644
index 000000000000..a456173d7e12
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrSharedBufferConfig.h
@@ -0,0 +1,100 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrSharedBufferConfig.h
+///
+//==================================================================================
+#pragma once
+
+#define DEFAULT_PAGE_SIZE 4096
+
+#define PWRPROF_MAX_MEM_ORDER  32
+
+#define PWRPROF_CORE_BUFFER_SIZE (8192)
+
+inline static unsigned int PwrGetSharedBufferSize(unsigned int coreCnt)
+{
+#if defined(_WIN32)
+    unsigned int order = 0;
+    unsigned int size = PWRPROF_CORE_BUFFER_SIZE * coreCnt;
+
+
+    for (order = 0; order < PWRPROF_MAX_MEM_ORDER; order++)
+    {
+        unsigned int blockSize = (1UL << order) * DEFAULT_PAGE_SIZE;
+
+        if (blockSize > size)
+        {
+            size = blockSize;
+            break;
+        }
+    }
+
+#else
+    unsigned int size = PWRPROF_CORE_BUFFER_SIZE * 3;
+    (void)coreCnt;
+#endif
+
+    return size;
+}
+
+/* Pmc per core buffer size calculation
+ * Allocate enough space to accomadate 128 event sets for core pmc
+ * Sample size for core events (using 4 attributes per group and max counters occupancy)
+ *  Sample Header - 8 bytes
+ *  Time stamp - 8 bytes
+ *  Core Id - 8 bytes
+ *  Group Attr size - 8 bytes * 4 Attrs * 128 event groups -> 4096 bytes
+ *  Counter values - 8 bytes * 8 counters * 128 event groups -> 8192 bytes
+ *  Group Header size - 8 bytes * 128 event groups -> 1024 bytes
+ *  Total size per core - 13,336 bytes  (~4 pages)
+ *
+ * Assuming max 128 event sets for L3
+ *  Total size per core - 13,336 bytes (~4 pages)
+ *
+ * Assuming max 2048 event sets for Df (max 16 counters)
+ *  Total size - 344,088 bytes (~85 pages rounded to 128 pages)
+ *
+ * Max buffer size:
+ * Assuming a maximum of 1024 cores
+ *  Max size for core -> 4 * 1024 pages
+ *
+ * Assuming max 128 l3 complexs/ccxs
+ * Max size for l3 -> 4 * 128 pages
+ *
+ * Assuming max 2 sockets
+ *  Max size for df -> 128 * 2 pages
+ *
+ * Max buffer size -> 4864 pages
+       Rounded to nearest power of 2 multiple of page size 8192 pages(2^13 pages ~ 32MB)
+ */
+
+// Allocate 4 required pages per core for core pmc
+#define PMC_CORE_BUFFER_SIZE            (4 * DEFAULT_PAGE_SIZE)
+
+// Allocate 4 required pages per core for l3 pmc
+#define PMC_L3_BUFFER_SIZE              (4 * DEFAULT_PAGE_SIZE)
+
+// Allocate 26 required pages per core for df pmc
+#define PMC_DF_BUFFER_SIZE              (128 * DEFAULT_PAGE_SIZE)
+
+#define PMC_UMC_BUFFER_SIZE             (64 * DEFAULT_PAGE_SIZE)
+inline static unsigned int PmcGetSharedBufferSize(unsigned int coreCnt, unsigned int ccxCnt, unsigned int socketCnt)
+{
+    unsigned int order = 0;
+    unsigned int size = (PMC_CORE_BUFFER_SIZE * coreCnt + PMC_L3_BUFFER_SIZE * ccxCnt + PMC_DF_BUFFER_SIZE * socketCnt + PMC_UMC_BUFFER_SIZE * socketCnt);
+
+    for (order = 0; order < PWRPROF_MAX_MEM_ORDER; order++)
+    {
+        unsigned int blockSize = (1UL << order) * DEFAULT_PAGE_SIZE;
+
+        if (blockSize > size)
+        {
+            size = blockSize;
+            break;
+        }
+    }
+
+    return size;
+}
\ No newline at end of file
diff --git a/drivers/powerprofiler/inc/PwrVersion.h b/drivers/powerprofiler/inc/PwrVersion.h
new file mode 100644
index 000000000000..08ae873a0d31
--- /dev/null
+++ b/drivers/powerprofiler/inc/PwrVersion.h
@@ -0,0 +1,37 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrVersion.h
+///
+//==================================================================================
+#pragma once
+
+// Driver version
+/// \def DRIVER_VERSION The version format is:
+/// [31-24]: pwr prof major, [23-16]: pwr prof minor, [15-0]: pwr prof build
+#define PCORE_MAJOR_VERSION  5
+#define PCORE_MINOR_VERSION  7
+#define PCORE_BUILD_VERSION  0
+#define PWRPROF_MAJOR_VERSION  10
+#define PWRPROF_MINOR_VERSION  5
+#define PWRPROF_BUILD_VERSION  0
+
+// Linux version
+// Once version is changed backend and driver needs to be updated
+// Major version should be changed after every release
+// Minor version should be changed for any change in driver code
+// Please update the version number in file located at ../Linux/AMDPowerProfilerVersion
+#define LINUX_PWR_DRV_MAJOR 10
+#define LINUX_PWR_DRV_MINOR 5
+
+#define POWER_PROFILE_DRIVER_VERSION \
+    ((uint64)PCORE_MAJOR_VERSION << 56) | ((uint64)PCORE_MINOR_VERSION << 48) | ((uint64)PCORE_BUILD_VERSION << 32) \
+    | ((uint64)PWRPROF_MAJOR_VERSION << 28) | ((uint64)PWRPROF_MINOR_VERSION << 24) | ((uint64)PWRPROF_BUILD_VERSION << 20)
+
+
+#define PWRPROF_MAJOR_MASK      0xf
+#define PWRPROF_MAJOR_SHIFT     28
+
+#define PWRPROF_MINOR_MASK      0xf
+#define PWRPROF_MINOR_SHIFT     24
diff --git a/drivers/powerprofiler/src/PmcDataBufferOps.c b/drivers/powerprofiler/src/PmcDataBufferOps.c
new file mode 100644
index 000000000000..d8f76d022c84
--- /dev/null
+++ b/drivers/powerprofiler/src/PmcDataBufferOps.c
@@ -0,0 +1,343 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcDataBufferOps.c
+///
+//==================================================================================
+
+#include <linux/fs.h>
+#include <linux/poll.h>
+#include <linux/anon_inodes.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/wait.h>
+#include <linux/version.h>
+// Note: This is included to avoid
+// compilation failure on older kernels
+#include <linux/sched.h>
+
+#include <PmcDataBufferOps.h>
+#include <PwrOsPrimitives.h>
+#include <PwrCommonDataTypes.h>
+
+/* MmapOpen is usually called to initialize the vm area
+ * and when a new reference to vma is made (during process fork) */
+static void PmcMmapOpen(struct vm_area_struct *vma)
+{
+    PmcDataBufferContext *pDataBufferCtx = NULL;
+
+    if (vma != NULL && vma->vm_file != NULL && vma->vm_file->private_data != NULL)
+    {
+        pDataBufferCtx = (PmcDataBufferContext*)vma->vm_file->private_data;
+        atomic_inc(&pDataBufferCtx->m_mmapCount);
+    }
+}
+
+static void PmcMmapClose(struct vm_area_struct *vma)
+{
+    PmcDataBufferContext *pDataBufferCtx = NULL;
+    void *pDataBuffer = NULL;
+    unsigned long numOfPages = 0;
+    uint32_t idx = 0;
+
+    if (vma != NULL && vma->vm_file != NULL)
+    {
+        pDataBufferCtx = (PmcDataBufferContext*)vma->vm_file->private_data;
+
+        if (pDataBufferCtx != NULL)
+        {
+            DRVPRINT("vma(%p) pDataBufferCtx(%p) pBuffer(%p)", vma, pDataBufferCtx, pDataBufferCtx->m_pBuffer);
+
+            atomic_dec(&pDataBufferCtx->m_mmapCount);
+
+            pDataBuffer = pDataBufferCtx->m_pBuffer;
+
+            if (pDataBuffer != NULL)
+            {
+                if (0 == atomic_read(&pDataBufferCtx->m_mmapCount))
+                {
+                    numOfPages = (pDataBufferCtx->m_bufferSize) >> PAGE_SHIFT;
+
+                    for(idx = 0; idx < numOfPages * PAGE_SIZE; idx += PAGE_SIZE)
+                    {
+                        ClearPageReserved(virt_to_page(((unsigned long)pDataBuffer) + idx));
+                    }
+
+                    kfree(pDataBuffer);
+                }
+                else
+                {
+                    DRVPRINT("Error: unexpected mmap count (%d)", atomic_read(&pDataBufferCtx->m_mmapCount));
+                }
+            }
+            else
+            {
+                DRVPRINT("Error: Invalid Data Buffer. pDataBuffer(%p)", pDataBuffer);
+            }
+        }
+        else
+        {
+            DRVPRINT("Error: Invalid Data Buffer Context. pDataBufferContext(%p)", pDataBufferCtx);
+        }
+
+        DRVPRINT("pDataBufferCtx(%p) pBuffer(%p) pDataBuffer(%p) mmapCount(%d)",
+            pDataBufferCtx, pDataBufferCtx->m_pBuffer, pDataBuffer, atomic_read(&pDataBufferCtx->m_mmapCount));
+    }
+}
+
+// TODO: Function signature varies for linux versions
+// using the latest version for now
+// This function gets called when the mapped region is accessed
+// the first time.
+// Since we are using remap_pfn_range while allocating memory,
+// this function shouldn't get called
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
+    static vm_fault_t PmcMmapFault(struct vm_fault *vmf)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
+    static int PmcMmapFault(struct vm_fault* vmf)
+#else
+    static int PmcMmapFault(struct vm_area_struct* vma, struct vm_fault* vmf)
+#endif
+{
+    int retVal = VM_FAULT_SIGBUS;
+    DRVPRINT("Error: Unexpected call(%d)", retVal);
+
+    return retVal;
+}
+
+struct vm_operations_struct PmcMmapVmOps =
+{
+    .open = PmcMmapOpen,
+    .close = PmcMmapClose,
+    .fault = PmcMmapFault,
+};
+
+
+static int PmcMmap(struct file *pFile, struct vm_area_struct *vma)
+{
+    int retVal = 0;
+    uint32_t node = 0;
+    void *pDataBuffer = NULL;
+    PmcDataBufferContext *pDataBufferCtx = NULL;
+    unsigned long numOfPages = 0;
+    unsigned long vmSize = 0;
+    uint32_t idx = 0;
+    unsigned long pfn = 0;
+
+    if (pFile == NULL || vma == NULL || pFile->private_data == NULL)
+    {
+        DRVPRINT("Error: (pFile == NULL || vma == NULL || pFile->private_data == NULL)");
+        retVal = ERROR_PMC_PMCMAP_INVALID_PARAMS;
+    }
+
+    if (retVal == 0)
+    {
+        pDataBufferCtx = (PmcDataBufferContext*)pFile->private_data;
+
+        vma->vm_ops = &PmcMmapVmOps;
+        vma->vm_file->private_data = pFile->private_data;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+        vm_flags_set(vma, VM_DONTCOPY);
+#else
+        vma->vm_flags |= VM_DONTCOPY;
+#endif
+
+        vmSize = (vma->vm_end - vma->vm_start);
+        node = cpu_to_node(pDataBufferCtx->m_coreId);
+
+        if (vmSize > pDataBufferCtx->m_bufferSize)
+        {
+            DRVPRINT("Error: Size not matching vmSize(%lu) bufferSize(%lld)", vmSize, pDataBufferCtx->m_bufferSize);
+            retVal = ERROR_PMC_PMCMAP_VMSIZE_GREATERTHANBUFFERSIZE;
+        }
+    }
+
+    if (retVal == 0)
+    {
+        numOfPages = (pDataBufferCtx->m_bufferSize) >> PAGE_SHIFT;
+
+        pDataBuffer = kmalloc_node(PAGE_SIZE * numOfPages, GFP_KERNEL, node);
+
+        if (pDataBuffer == NULL)
+        {
+            DRVPRINT("Error: Allocation failed(%p) pageSize(%lu) pages (%lu)", pDataBuffer, PAGE_SIZE, numOfPages);
+            retVal = ERROR_PMC_PMCMAP_NULL_DATABUFFER;
+        }
+    }
+
+    if (retVal == 0)
+    {
+        for (idx = 0; idx < numOfPages * PAGE_SIZE; idx += PAGE_SIZE)
+        {
+            SetPageReserved(virt_to_page(((unsigned long)pDataBuffer) + idx));
+        }
+
+        pfn = virt_to_phys((void *)pDataBuffer)>>PAGE_SHIFT;
+        retVal = remap_pfn_range(vma, vma->vm_start, pfn, vmSize, vma->vm_page_prot);
+
+        if (retVal < 0)
+        {
+            DRVPRINT("Error: could not map the address area\n");
+            retVal = ERROR_PMC_PMCMAP_REMAPPFN_RANGE;
+        }
+    }
+
+    if (retVal == 0)
+    {
+        memset(pDataBuffer,0, numOfPages * PAGE_SIZE);
+        pDataBufferCtx->m_pBuffer = pDataBuffer;
+        atomic_inc(&pDataBufferCtx->m_mmapCount);
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+static unsigned int PmcPoll(struct file *pFile, poll_table *wait)
+{
+    unsigned int pollStatus = 0;
+    PmcDataBufferContext* pDataBufferCtx = pFile->private_data;
+
+    /* Add thread to buffer waitqueue */
+    poll_wait(pFile, &pDataBufferCtx->m_bufferWaitQueue, wait);
+
+    // TODO: Return POLLHUP if profiler has stopped
+    pollStatus = atomic_xchg(&pDataBufferCtx->m_pollStatus, 0);
+
+    return pollStatus;
+}
+
+/* TODO: Remove operations we will not be implementing */
+struct file_operations pmcFops =
+{
+    .poll       = PmcPoll,
+    .mmap       = PmcMmap
+};
+
+void InitDataBufferWaitQueue(PmcDataBufferContext* pDataBufferCtx)
+{
+    init_waitqueue_head(&pDataBufferCtx->m_bufferWaitQueue);
+}
+
+void NotifyPendingRead(PmcDataBufferContext* pDataBufferCtx)
+{
+    atomic_set(&pDataBufferCtx->m_pollStatus, POLL_IN);
+
+    /* TODO: Add a timeout here? */
+    wake_up_interruptible(&pDataBufferCtx->m_bufferWaitQueue);
+}
+
+int _CreatePmcFileDescriptors(ClientContext *pClientCtx,
+                              PmcPmuType type,
+                              uint64_t* pCoreMaskArray,
+                              int* pFdArray,
+                              uint32_t *pFdArrayIdx)
+{
+    int retVal = 0;
+    int i = 0;
+    int j = 0;
+    int coreId = 0;
+    void* privateData = NULL;
+    CoreContext *pCoreCtx = NULL;
+    uint64_t coreMask = 0;
+    int fd = -1;
+
+    DRVPRINT("pClientCtx(%p) type(%d) pCoreMaskArray(%p) pFdArray(%p) pFdArrayIdx(%p)",
+            pClientCtx, type, pCoreMaskArray, pFdArray, pFdArrayIdx);
+
+    if (pClientCtx == NULL || pCoreMaskArray == NULL || pFdArray ==  NULL || pFdArrayIdx == NULL)
+    {
+        retVal = ERROR_PMC_CREATEPMCDESC_INVALID_PARAMS;
+    }
+
+    for (i = 0, coreId = 0; i < PMC_CORE_MASK_ARRAY_SIZE && !retVal; i++)
+    {
+        coreMask = pCoreMaskArray[i];
+
+        for (j = 0; j < PMC_CORE_MASK_BIT_WIDTH && !retVal; j++, coreId++)
+        {
+            if (coreMask & (1ULL << j))
+            {
+                pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+                if (pCoreCtx == NULL)
+                {
+                    DRVPRINT("Error: pCoreCtx == NULL, coreId (%d)", coreId);
+                    retVal = ERROR_PMC_CREATEPMCDESC_NULL_CORECTX;
+                    break;
+                }
+
+                privateData = (void*)pCoreCtx->m_pDataBufferContext[type];
+
+                if (privateData == NULL)
+                {
+                    DRVPRINT("Error: privateData == NULL, coreId (%d)", coreId);
+                    retVal = ERROR_PMC_CREATEPMCDESC_NULL_PRIVATEDATA;
+                    break;
+                }
+
+                fd = anon_inode_getfd("Pmc Driver",
+                                      &pmcFops,
+                                      privateData,
+                                      O_RDWR | O_CLOEXEC);
+
+                /*TODO: Is fd == 0 a valid scenario? */
+                if (fd < 0)
+                {
+                    retVal = fd;
+                }
+
+                if (!retVal)
+                {
+                    pFdArray[*pFdArrayIdx] = fd;
+                    (*pFdArrayIdx)++;
+                }
+
+                DRVPRINT("fd[%d](%d)", *pFdArrayIdx, fd);
+            }
+        }
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+int CreatePmcFileDescriptors(CountModeProfileConfig* pConfig,
+                             ClientContext* pClientCtx)
+{
+    PmcPmuType type = PMC_PMU_INVALID;
+    int retVal = 0;
+    uint32_t fdArrayIdx = 0;
+
+    DRVPRINT("pConfig(%p) pClientCtx(%p)", pConfig, pClientCtx);
+
+    if (pClientCtx == NULL || pConfig == NULL)
+    {
+        retVal = ERROR_PMC_CREATEPMCDESC_NULL_PARAMS;
+    }
+
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && !retVal; type++)
+    {
+        /* Skip if there are no valid configurations for pmc type */
+        if (pClientCtx->m_pmcConfigGroupCnt[type] == 0)
+        {
+            continue;
+        }
+
+        retVal = _CreatePmcFileDescriptors(pClientCtx,
+                                           type,
+                                           pClientCtx->m_pPmcCoreMaskArray[type],
+                                           pConfig->m_fdArray,
+                                           &fdArrayIdx);
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+// TODO: Do i need to close() fds allocated with anon_inode_getfd?
diff --git a/drivers/powerprofiler/src/PmcProcessConfig.c b/drivers/powerprofiler/src/PmcProcessConfig.c
new file mode 100644
index 000000000000..ae4662ef8921
--- /dev/null
+++ b/drivers/powerprofiler/src/PmcProcessConfig.c
@@ -0,0 +1,2811 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcProcessConfig.c
+///
+//==================================================================================
+
+// Project Includes:
+#include <PmcProcessConfig.h>
+#include <PmcUtils.h>
+#include <PmcTimerConfig.h>
+#include <PwrOsPrimitives.h>
+#include <PmcDataBuffer.h>
+#include <PmcDataBufferOps.h>
+#include <PwrCommonDataTypes.h>
+#include <PwrDriverUtils.h>
+
+#if defined(_WIN32)
+    #include <errno.h>
+#endif
+
+#if defined(__linux__)
+    #include <linux/cpumask.h>
+#endif
+
+#define PMC_IRPERF_MAX_VALUE    0xFFFFFFFFFFFFULL
+#define PMC_MPERF_MAX_VALUE     0xFFFFFFFFFFFFULL
+#define PMC_APERF_MAX_VALUE     0xFFFFFFFFFFFFULL
+
+#if defined (_WIN32)
+    #include <intrin.h>
+    #define POPCNT(x)   __popcnt(x)
+#elif defined (__linux__)
+    #define POPCNT(x)   __builtin_popcount(x)
+#endif
+
+/*
+ * Note: There can only be one registered client at a time
+ * with current implementation. In future, this can be a
+ * changed to a list of clients
+ */
+extern ClientContext* g_pPmcClientContext;
+
+
+static uint32 g_PmcAperfMsr = PMC_APERF_MSR;
+static uint32 g_PmcMperfMsr = PMC_MPERF_MSR;
+static bool g_halPmcAcquired = false;
+
+/* Number of PMCs can vary for sockets. This function
+ * returns the maximum of all sockets */
+uint32_t GetMaxPmcCount(PmcPmuType type, uint16_t* pDebugPmcCnt)
+{
+    PTARGET_SYSTEM_INFO pTargetSystemInfo = NULL;
+    uint32_t pmcCount = 0;
+    uint32_t umcCount = 0;
+    GetTargetSystemInfo(&pTargetSystemInfo, false);
+
+    if (NULL != pTargetSystemInfo)
+    {
+        switch (type)
+        {
+            case PMC_PMU_CORE:
+                pmcCount = pTargetSystemInfo->m_zen.m_perfMonInfo[0].m_numOfCorePmc;
+                *pDebugPmcCnt = IsHyperVisor() ? 0 : CORE_PMC_DEBUG_COUNT;
+                break;
+
+            case PMC_PMU_L3:
+                pmcCount = pTargetSystemInfo->m_zen.m_perfMonInfo[0].m_numOfL3Pmc;
+                *pDebugPmcCnt = 0;
+                break;
+
+            case PMC_PMU_DF:
+                pmcCount = pTargetSystemInfo->m_zen.m_perfMonInfo[0].m_numOfDfPmc;
+                *pDebugPmcCnt = 0;
+                break;
+
+            case PMC_PMU_UMC:
+                // Note: This will fail if socket 0 has no active UMCs
+                umcCount = POPCNT(pTargetSystemInfo->m_zen.m_perfMonInfo[0].m_activeUmcMask);
+                pmcCount = (umcCount != 0) ? pTargetSystemInfo->m_zen.m_perfMonInfo[0].m_numOfUmcPmc / umcCount : 0;
+                *pDebugPmcCnt = 0;
+                break;
+
+            default:
+                break;
+        }
+    }
+
+    return pmcCount;
+}
+
+/*
+    Get mask of available PMCs. If resetPmc flag is set mark all PMCs as available.
+    Note: Must be obtained before any pmc counters are configured
+*/
+void GetPmcAvailabilityMask(void* pInfo)
+{
+    CoreContext* pCoreCtx = (CoreContext*)pInfo;
+    int type = PMC_PMU_INVALID;
+    uint32_t msrIdx = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint64_t msrValue = 0;
+    bool isL3DfAllowed = true;
+
+    // In VM guest mode L3 and DF are disabled
+    if (IsHyperVisor() && !IsHost())
+    {
+        isL3DfAllowed = false;
+    }
+
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && type != PMC_PMU_UMC; type++)
+    {
+        pmcCnt = GetMaxPmcCount((PmcPmuType)type, &debugPmcCnt);
+
+        for (msrIdx = 0; msrIdx < pmcCnt; msrIdx++)
+        {
+            switch (type)
+            {
+                case PMC_PMU_CORE:
+                    msrValue = ReadMSR(CORE_PMC_CFG_MSR(msrIdx));
+                    break;
+
+                case PMC_PMU_L3:
+                    if (isL3DfAllowed)
+                    {
+                        msrValue = ReadMSR(CHL3_PMC_CFG_MSR(msrIdx));
+                    }
+                    break;
+
+                case PMC_PMU_DF:
+                    if (isL3DfAllowed)
+                    {
+                        msrValue = ReadMSR(DF_PMC_CFG_MSR(msrIdx));
+                    }
+                    break;
+
+                default:
+                    break;
+            }
+
+            /* Mark all PMCs as available if m_resetPmc is true*/
+            if ((msrValue & PMC_CFG_ENABLE) == 0 || pCoreCtx->m_resetPmc == true)
+            {
+                pCoreCtx->m_availabilityMask[type] |= (1 << msrIdx);
+            }
+        }
+    }
+}
+
+// TODO: Move this function to Utils?
+uint64_t GetDfClk(uint32_t coreId)
+{
+    uint64_t fclk = 0;
+    uint32_t node = 0;
+    uint32_t zenVer = 0;
+
+    node = GetNodeIdForCore(coreId);
+    zenVer = GetZenVersion();
+
+    if (zenVer == PWR_ZEN2 || zenVer == PWR_ZEN3)
+    {
+        // FCLK in SSP:
+        //     Low  - Bus 0, Device 0x18, Function 0x5, Offset 0x1D0
+        //     High - Bus 0, Device 0x18, Function 0x5, Offset 0x1D4
+        uint32_t low = 0;
+        uint32_t hi = 0;
+        uint32_t dev = 0x18 + node;
+
+        low = ReadPCIDev(0x0, dev, 0x5, 0x1D0);
+        hi = ReadPCIDev(0x0, dev, 0x5, 0x1D4);
+
+        fclk = low;
+        fclk |= ((uint64_t)(hi & 0xFF) << 32);
+    }
+    else if (zenVer >= PWR_ZEN4)
+    {
+        // FCLK in Stones:
+        //     Low  - Bus 0, Device 0x18, Function 0x5, Offset 0x1D8
+        //     High - Bus 0, Device 0x18, Function 0x5, Offset 0x1DC
+        uint32_t low = 0;
+        uint32_t hi = 0;
+        uint32_t dev = 0x18 + node;
+
+        low = ReadPCIDev(0x0, dev, 0x5, 0x1D8);
+        hi = ReadPCIDev(0x0, dev, 0x5, 0x1DC);
+
+        fclk = low;
+        fclk |= ((uint64_t)(hi & 0xFF) << 32);
+    }
+
+    return fclk;
+}
+
+void ResetPmcConfigGroup(CoreContext* pCoreCtx, PmcPmuType type)
+{
+    uint16_t msrIdx = 0;
+    uint16_t configGroupIdx = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint16_t maxPmcCnt = 0;
+    uint16_t configGroupCnt = 0;
+    uint16_t pmcConfigCnt = 0;
+    PmcConfigGroup* pPmcConfigGroup = NULL;
+    PmcConfig* pPmcConfigArray = NULL;
+    uint32_t umcMsrCount = 0;
+    uint32_t umcMsrCountArrayIdx = 0;
+
+    pmcCnt = GetMaxPmcCount(type, &debugPmcCnt);
+    maxPmcCnt = pmcCnt + debugPmcCnt;
+
+    configGroupCnt = pCoreCtx->m_pmcConfigGroupCnt[type];
+    pPmcConfigGroup = pCoreCtx->m_pPmcConfigGroupArray[type];
+
+    /* Iterate through all pmc config groups */
+    for (configGroupIdx = 0; (configGroupIdx < configGroupCnt) && (NULL != pPmcConfigGroup); configGroupIdx++)
+    {
+        /* Reset delta tsc/irperf/mperf/aperf/fclk */
+        pPmcConfigGroup->m_deltaTime = 0;
+        pPmcConfigGroup->m_dfClkDelta = 0;
+        pPmcConfigGroup->m_irPerfDelta = 0;
+        pPmcConfigGroup->m_mPerfDelta = 0;
+        pPmcConfigGroup->m_aPerfDelta = 0;
+
+        pmcConfigCnt = pPmcConfigGroup->m_pmcConfigCnt;
+        pPmcConfigArray = pPmcConfigGroup->m_pPmcConfigArray;
+
+        if (NULL != pPmcConfigArray)
+        {
+            /* Iterate through all the pmc configs */
+            for (msrIdx = 0; (msrIdx < maxPmcCnt) && (pmcConfigCnt != 0) && type != PMC_PMU_UMC; msrIdx++)
+            {
+                if (pPmcConfigArray[msrIdx].m_controlValue == 0)
+                {
+                    continue;
+                }
+
+                pmcConfigCnt--;
+                pPmcConfigArray[msrIdx].m_counterValue = 0;
+            }
+
+            if (PMC_PMU_UMC == type)
+            {
+                umcMsrCount = pPmcConfigGroup->m_umcMsrCount;
+
+                for (umcMsrCountArrayIdx = 0; umcMsrCountArrayIdx < umcMsrCount; umcMsrCountArrayIdx++)
+                {
+                    pPmcConfigGroup->m_pUmcMsrCountArray[umcMsrCountArrayIdx] = 0;
+                }
+            }
+
+            pPmcConfigGroup = pPmcConfigGroup->m_pNext;
+        }
+    }
+}
+
+int PmcCallBack(ClientContext* pClientCtx, CoreContext* pCoreCtx)
+{
+    int retVal = 0;
+    int type = PMC_PMU_INVALID;
+    PmcConfigGroup* pPmcConfigGroup = NULL;
+    uint64_t dfClk = 0;
+    uint64_t tsc = 0;
+    uint64_t irPerf = 0;
+    uint64_t mPerf = 0;
+    uint64_t aPerf = 0;
+    uint64_t delta = 0;
+    uint32_t recordSize = 0;
+
+    DRVPRINT("pClientCtx(%p) pCoreCtx(%p)", pClientCtx, pCoreCtx);
+
+    if (pCoreCtx == NULL)
+    {
+        // Already check from the caller. Not supposed to come here.
+        // Just passing through in case it is NULL for some reason.
+        return 0;
+    }
+
+    /* Save count values */
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && !retVal; type++)
+    {
+        /* Skip if pmc type does not have a valid configuration */
+        if (pCoreCtx->m_pPmcConfigGroupArray[type] == NULL)
+        {
+            continue;
+        }
+
+        /* Decrement sampling counter */
+        pCoreCtx->m_currSamplingCounter[type]--;
+
+        /* Save counter values
+         *  - Before sample collection
+         *  - Before multiplexing
+         */
+        if ((pCoreCtx->m_currSamplingCounter[type] == 0) || (pCoreCtx->m_pmcConfigGroupCnt[type] > 1))
+        {
+            /* Save count of current pmc config group */
+            retVal = ReadPmcConfigGroup(pCoreCtx->m_pPmcConfigGroupArray[type], (PmcPmuType)type, pCoreCtx->m_umcCount);
+        }
+    }
+
+    /* Multiplex */
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && !retVal; type++)
+    {
+        pPmcConfigGroup = pCoreCtx->m_pPmcConfigGroupArray[type];
+
+        /* Skip if pmc type does not have a valid configuration */
+        if (pPmcConfigGroup == NULL)
+        {
+            continue;
+        }
+
+        /* For more than one event group */
+        if (pCoreCtx->m_pmcConfigGroupCnt[type] > 1)
+        {
+            /* Note: Multiplex before writing sample data to
+             * accurately capture delta time, which is captured once
+             * the current group is unloaded during multiplexing. */
+            retVal = MultiplexPmcConfigGroup(pCoreCtx, (PmcPmuType)type);
+        }
+        /* For single event group */
+        else if (pCoreCtx->m_pmcConfigGroupCnt[type] == 1)
+        {
+            /* Reset count values before logging sample if
+             * multiplexing is not required. */
+            if (pCoreCtx->m_currSamplingCounter[type] == 0)
+            {
+                /* Reset counters */
+                ResetPmcCounters(pCoreCtx, (PmcPmuType)type);
+
+                tsc = ReadMSR(PMC_TSC_MSR);
+
+                /* Capture delta time before logging sample. */
+                if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_TIMESTAMP)
+                {
+                    pPmcConfigGroup->m_deltaTime = tsc - pPmcConfigGroup->m_loadTime;
+                    pPmcConfigGroup->m_loadTime = tsc;
+                }
+
+                /* Capture df clk delta time before logging sample. */
+                if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_FCLK)
+                {
+                    dfClk = GetDfClk(pCoreCtx->m_coreId);
+                    pPmcConfigGroup->m_dfClkDelta =  dfClk - pPmcConfigGroup->m_dfClk;
+                    pPmcConfigGroup->m_dfClk = dfClk;
+                }
+
+                /* Capture IRPerf delta */
+                if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_IRPERF)
+                {
+                    irPerf = ReadMSR(PMC_IRPERF_MSR);
+
+                    // Check if irperf has rolled over
+                    if (irPerf < pPmcConfigGroup->m_irPerf)
+                    {
+                        delta = PMC_IRPERF_MAX_VALUE - pPmcConfigGroup->m_irPerf;
+                        delta += irPerf;
+                    }
+                    else
+                    {
+                        delta = irPerf - pPmcConfigGroup->m_irPerf;
+                    }
+
+                    pPmcConfigGroup->m_irPerfDelta = delta;
+                    pPmcConfigGroup->m_irPerf = irPerf;
+                }
+
+                /* Capture MPerf delta */
+                if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_MPERF)
+                {
+                    mPerf = ReadMSR(g_PmcMperfMsr);
+
+                    // Check if mperf has rolled over
+                    if (mPerf < pPmcConfigGroup->m_mPerf)
+                    {
+                        delta = PMC_MPERF_MAX_VALUE - pPmcConfigGroup->m_mPerf;
+                        delta += mPerf;
+                    }
+                    else
+                    {
+                        delta = mPerf - pPmcConfigGroup->m_mPerf;
+                    }
+
+                    pPmcConfigGroup->m_mPerfDelta = delta;
+                    pPmcConfigGroup->m_mPerf = mPerf;
+                }
+
+                /* Capture APerf delta */
+                if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_APERF)
+                {
+                    aPerf = ReadMSR(g_PmcAperfMsr);
+
+                    // Check if aperf has rolled over
+                    if (aPerf < pPmcConfigGroup->m_aPerf)
+                    {
+                        delta = PMC_APERF_MAX_VALUE - pPmcConfigGroup->m_aPerf;
+                        delta += aPerf;
+                    }
+                    else
+                    {
+                        delta = aPerf - pPmcConfigGroup->m_aPerf;
+                    }
+
+                    pPmcConfigGroup->m_aPerfDelta = delta;
+                    pPmcConfigGroup->m_aPerf = aPerf;
+                }
+
+                /* Capture time enabled for single config group. */
+                pCoreCtx->m_timeEnabled[type] = tsc - pCoreCtx->m_timeEnabledBegin[type];
+                pCoreCtx->m_timeEnabledBegin[type] = tsc;
+            }
+        }
+        else
+        {
+            DRVPRINTERROR("Error: Invalid config group count value(%u)", pCoreCtx->m_pmcConfigGroupCnt[type]);
+        }
+    }   
+
+    /* Collect sample */
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && !retVal; type++)
+    {
+        /* Skip if pmc type does not have a valid configuration */
+        if (pCoreCtx->m_pPmcConfigGroupArray[type] == NULL)
+        {
+            continue;
+        }
+
+        /* If core has a valid configuration and sampling
+         * counter is zero */
+        if (pCoreCtx->m_currSamplingCounter[type] == 0)
+        {
+            recordSize = (type == PMC_PMU_UMC) ? pCoreCtx->m_umcSampleRecordSize : pClientCtx->m_sampleRecordSize[type];
+
+            retVal = PmcSampleDataCallBack(pCoreCtx, (PmcPmuType)type,
+                                           recordSize);
+
+            /* Reset sampling count */
+            pCoreCtx->m_currSamplingCounter[type] = pClientCtx->m_samplingCount[type];
+
+            ResetPmcConfigGroup(pCoreCtx, (PmcPmuType)type);
+        }
+    }
+
+    return retVal;
+}
+
+/* Note: Sample record size is fixed for a specific pmc type.
+ * Modifying pmc configuration will require
+ * recalculation of sample record size. */
+static void SetSampleRecordSize(ClientContext* pClientCtx)
+{
+    int type = PMC_PMU_INVALID;
+    uint32_t sampleSize = 0;
+    uint32_t coreId = 0;
+    uint32_t socketId = 0;
+    uint32_t numOfCores = (uint32_t)GetCoreCount();
+    uint64_t coreMask = 0;
+    uint32_t umcCount = 0;
+    uint32_t coreMaskArrayIdx = 0;
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    for (sampleSize = 0, type = PMC_PMU_CORE; type < PMC_PMU_MAX && type != PMC_PMU_UMC; type++)
+    {
+        /* Skip if there is no valid config for pmc type */
+        if (pClientCtx->m_pmcConfigGroupCnt[type] == 0)
+        {
+            continue;
+        }
+
+        /* Exclude size of variable element: m_data */
+        sampleSize = sizeof(PmcSample) - sizeof(uint64_t);
+
+        /* Include PMC configuration group header */
+        sampleSize += pClientCtx->m_pmcConfigGroupCnt[type] * sizeof(uint64_t);
+
+        sampleSize += sizeof(uint64_t) * pClientCtx->m_totalPmcConfigCnt[type];
+        sampleSize += sizeof(uint64_t) * pClientCtx->m_totalPmcAttrCnt[type];
+
+        pClientCtx->m_sampleRecordSize[type] = sampleSize;
+
+        DRVPRINT("SampleSize[%d](%u)", type, sampleSize);
+    }
+
+    /* Sample record size for UMC will vary for each socket depending
+     * on the number of active UMCs */
+    if (PMC_PMU_UMC == type)
+    {
+        CoreContext* pCoreCtx = NULL;
+
+        for (coreId = 0; coreId < numOfCores; coreId++)
+        {
+            coreMaskArrayIdx = coreId / PMC_CORE_MASK_BIT_WIDTH;
+            coreMask = (coreMaskArrayIdx < PMC_CORE_MASK_ARRAY_SIZE) ? pClientCtx->m_pPmcCoreMaskArray[type][coreMaskArrayIdx] : 0;
+
+            // Check if this coreId is set in coreMask
+            if ((coreMask & (1ULL << (coreId - (coreMaskArrayIdx * PMC_CORE_MASK_BIT_WIDTH)))) == 0)
+            {
+                continue;
+            }
+
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+            /* Exclude size of variable element: m_data */
+            sampleSize = sizeof(PmcSample) - sizeof(uint64_t);
+
+            /* Include PMC configuration group header */
+            sampleSize += (pClientCtx->m_pmcConfigGroupCnt[type] * sizeof(uint64_t));
+
+            // Get socketId for the core
+            socketId = GetSocketIdForCore(coreId);
+
+            // Get umcCount for socket
+            umcCount = POPCNT(pClientCtx->m_umcMaskArray[socketId]);
+
+            sampleSize += (sizeof(uint64_t) * pClientCtx->m_totalPmcConfigCnt[type] * umcCount);
+            sampleSize += (sizeof(uint64_t) * pClientCtx->m_totalPmcAttrCnt[type]);
+
+            if (NULL != pCoreCtx)
+            {
+                pCoreCtx->m_umcSampleRecordSize = sampleSize;
+                pCoreCtx->m_umcCount = umcCount;
+                pCoreCtx->m_socketId = socketId;
+            }
+
+            DRVPRINT("SampleSize[%d](%u) coreId(%u) socketId(%u)", type, sampleSize, coreId, socketId);
+        }
+    }
+}
+
+int GetGroupAttrCount(uint8_t groupAttr)
+{
+    int count = 0;
+    int i = 0;
+
+    for (i = 0; i < PMC_GROUP_ATTR_WIDTH; i++)
+    {
+        count += (groupAttr & (1 << i)) ? 1 : 0;
+    }
+
+    return count;
+}
+
+int PmcWriteSampleData(CoreContext* pCoreCtx,
+                       PmcPmuType type,
+                       char* pBuffer)
+{
+    PmcSample* pSample = NULL;
+    uint16_t msrIdx = 0;
+    PmcConfig* pPmcConfig = NULL;
+    uint16_t configCnt = 0;
+    int i = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint16_t maxPmcCnt = 0;
+    uint64_t pmcConfigGroupAttrs = 0;
+    uint32_t umcIdx = 0;
+    uint32_t umcMsrCountArrayIdx = 0;
+    uint16_t cfgGroupCnt = 0;
+
+    DRVPRINTERROR("PmcWriteSampleData");
+
+    if (NULL != pCoreCtx)
+    {
+        PmcConfigGroup* pCfg = pCoreCtx->m_pPmcConfigGroupArray[type];
+
+        if (NULL != pCfg)
+        {
+            cfgGroupCnt = pCoreCtx->m_pmcConfigGroupCnt[type];
+
+            DRVPRINT("pPmcConfigGroup(%p) configGroupCnt(%d) type(%s) "
+                     "coreId(%d) pBuffer(%p)", pCoreCtx->m_pPmcConfigGroupArray[type],
+                     cfgGroupCnt, GetPmcTypeString(type), pCoreCtx->m_coreId, pBuffer);
+
+            pmcCnt = GetMaxPmcCount(type, &debugPmcCnt);
+            maxPmcCnt = pmcCnt + debugPmcCnt;
+
+            /* Write Sample header */
+            pSample = (PmcSample*)pBuffer;
+
+            if ((NULL != pSample) && (NULL != pCfg))
+            {
+                pSample->m_time = GetTimestamp();
+                pSample->m_coreId = pCoreCtx->m_coreId;
+                pSample->m_socketId = pCoreCtx->m_socketId;
+                pSample->m_deltaTimeEnabled = pCoreCtx->m_timeEnabled[type];
+
+                while (cfgGroupCnt--)
+                {
+                    configCnt = pCfg->m_pmcConfigCnt;
+                    pmcConfigGroupAttrs = pCfg->m_pmcConfigGroupAttrs;
+
+                    // TODO: Add configCnt and type to header? Not required?
+                    pSample->m_data[i] = (pCfg->m_pmcConfigGroupId & PMC_SAMPLE_HDR_GROUP_ID_MASK);
+                    pSample->m_data[i] |= (pCfg->m_pmcConfigGroupAttrs & PMC_SAMPLE_HDR_ATTR_MASK) << PMC_SAMPLE_HDR_ATTR_SHIFT;
+                    i++;
+
+                    if (pmcConfigGroupAttrs != 0)
+                    {
+                        /* Include timestamp in this group? */
+                        if (pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_TIMESTAMP)
+                        {
+                            pSample->m_data[i] = pCfg->m_deltaTime;
+                            i++;
+                        }
+
+                        if (pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_IRPERF)
+                        {
+                            pSample->m_data[i] = pCfg->m_irPerfDelta;
+                            i++;
+                        }
+
+                        if (pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_MPERF)
+                        {
+                            pSample->m_data[i] = pCfg->m_mPerfDelta;
+                            i++;
+                        }
+
+                        if (pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_APERF)
+                        {
+                            pSample->m_data[i] = pCfg->m_aPerfDelta;
+                            i++;
+                        }
+
+                        if (pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_FCLK)
+                        {
+                            pSample->m_data[i] = pCfg->m_dfClkDelta;
+                            i++;
+                        }
+                    }
+
+                    /* Write Sample data */
+                    for (msrIdx = 0; msrIdx < maxPmcCnt && configCnt > 0 && type != PMC_PMU_UMC; msrIdx++)
+                    {
+                        pPmcConfig = &pCfg->m_pPmcConfigArray[msrIdx];
+
+                        if (!pPmcConfig->m_controlValue)
+                        {
+                            continue;
+                        }
+
+                        pSample->m_data[i] = pPmcConfig->m_counterValue;
+                        DRVPRINT("DATA[%d]=(0x%llx)", i, pSample->m_data[i]);
+                        i++;
+                        configCnt--;
+                    }
+
+                    if (PMC_PMU_UMC == type)
+                    {
+                        uint32_t umcConfigIdx = 0;
+
+                        DRVPRINT("core(%d) cfgGroupCnt(%d) pCoreCtx->m_umcCount(%d) configCnt(%d)", GetCurrentCoreId(), cfgGroupCnt, pCoreCtx->m_umcCount, configCnt);
+
+                        for (umcIdx = 0, umcMsrCountArrayIdx = 0; umcIdx < pCoreCtx->m_umcCount; umcIdx++)
+                        {
+                            for (umcConfigIdx = 0; umcConfigIdx < configCnt; umcConfigIdx++)
+                            {
+                                if (pCfg->m_pPmcConfigArray[umcConfigIdx].m_controlValue == 0)
+                                {
+                                    continue;
+                                }
+
+                                pSample->m_data[i] = pCfg->m_pUmcMsrCountArray[umcMsrCountArrayIdx];
+                                DRVPRINT("UMC_DATA[%d]=(0x%llx)", i, pSample->m_data[i]);
+                                i++;
+                                umcMsrCountArrayIdx++;
+                            }
+                        }
+                    }
+
+                    pCfg = pCfg->m_pNext;
+                }
+
+                /* Update size of sample record (including header)
+                 * Adjust i to account for last element in PmcSample */
+                pSample->m_sampleHeader.m_header.m_sampleSize = sizeof(PmcSample) + (i - 1) * sizeof(uint64_t);
+
+                //DRVPRINT("sampleSize(%ubytes)", pSample->m_sampleHeader.m_header.m_sampleSize);
+            }
+        }
+    }
+
+    // Always return success
+    return 0;
+}
+
+int PmcSampleDataCallBack(CoreContext* pCoreCtx,
+                          PmcPmuType type,
+                          uint32_t recordSize)
+{
+    int retVal = 0;
+    void* pBuffer = NULL;
+
+    DRVPRINT("pCoreCtx(%p) type(%s) recordSize(%u)",
+             pCoreCtx, GetPmcTypeString(type), recordSize);
+
+    /* Reserve space in buffer for sample record */
+    pBuffer = PmcGetDataBuffer(pCoreCtx->m_pDataBufferContext[type],
+                               recordSize);
+
+    if (pBuffer != NULL)
+    {
+        PmcWriteSampleData(pCoreCtx,
+                           type,
+                           (char*)pBuffer);
+    }
+    else
+    {
+        /* TODO: Handle dropped sample stats here */
+        pCoreCtx->m_droppedSampleCount[type]++;
+        //retVal = ENOMEM;
+    }
+
+    if (pCoreCtx->m_pDataBufferContext[type]->m_pendingRead)
+    {
+        /* Notify consumer of data availibility and clear
+         * the pending flag */
+        NotifyPendingRead(pCoreCtx->m_pDataBufferContext[type]);
+        pCoreCtx->m_pDataBufferContext[type]->m_pendingRead = false;
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+/*
+ * TODO: How to determine if core pmcs are already occupied
+ * TODO: Watchdog will occupy one pmc if active, how do we know
+ * which pmc is occuped by watchdog or other profilers
+ * Note: PmcConfigs can be staggered
+ */
+int LoadPmcConfig(PmcConfigGroup* pPmcConfigGroup, PmcPmuType type, uint32_t umcCount, bool reset)
+{
+    int retVal = 0;
+    int msrIdx = 0;
+    int debugMsrIdx = 0;
+    PmcConfig* pPmcConfigArray = pPmcConfigGroup->m_pPmcConfigArray;
+    uint16_t pmcConfigCnt = pPmcConfigGroup->m_pmcConfigCnt;
+    uint16_t maxPmcCnt = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint64_t controlValue = 0;
+    uint64_t counterValue = 0;
+    uint32_t umcIdx = 0;
+    uint32_t umcMsrIdx = 0;
+    uint32_t umcMsrCountArrayIdx = 0;
+    uint32_t msrCountPerUmc = 0;
+
+    DRVPRINT("pPmcConfigGroup(%p) type(%d) reset(%d) pmcConfigCnt(%u) pPmcConfigArray(%p)",
+             pPmcConfigGroup, type, reset, pmcConfigCnt, pPmcConfigArray);
+
+    pmcCnt = GetMaxPmcCount(type, &debugPmcCnt);
+    maxPmcCnt = pmcCnt + debugPmcCnt;
+
+    for (msrIdx = 0; (pmcConfigCnt > 0) && (msrIdx < maxPmcCnt) && (type != PMC_PMU_UMC); msrIdx++)
+    {
+        controlValue = pPmcConfigArray[msrIdx].m_controlValue;
+
+        if (controlValue == 0)
+        {
+            continue;
+        }
+
+        --pmcConfigCnt;
+        counterValue = reset ? 0 : pPmcConfigArray[msrIdx].m_counterValue;
+
+        /* Public Pmcs*/
+        if (msrIdx < pmcCnt)
+        {
+            switch (type)
+            {
+                case PMC_PMU_CORE:
+                    // Force to counting mode only
+                    controlValue &= ~(1ULL << 20);
+                    WriteMSR(CORE_PMC_CFG_MSR(msrIdx), controlValue);
+                    WriteMSR(CORE_PMC_COUNT_MSR(msrIdx), counterValue);
+                    break;
+
+                case PMC_PMU_L3:
+                    WriteMSR(CHL3_PMC_CFG_MSR(msrIdx), controlValue);
+                    WriteMSR(CHL3_PMC_COUNT_MSR(msrIdx), counterValue);
+                    break;
+
+                case PMC_PMU_DF:
+                    WriteMSR(DF_PMC_CFG_MSR(msrIdx), controlValue);
+                    WriteMSR(DF_PMC_COUNT_MSR(msrIdx), counterValue);
+                    break;
+
+                default:
+                    break;
+            }
+        }
+        /* Debug Pmcs*/
+        else if (msrIdx < maxPmcCnt)
+        {
+            debugMsrIdx = msrIdx - pmcCnt;
+
+            switch (type)
+            {
+                case PMC_PMU_CORE:
+                    WriteMSR(CORE_PMC_DEBUG_CFG_MSR(debugMsrIdx), controlValue);
+                    WriteMSR(CORE_PMC_DEBUG_COUNT_MSR(debugMsrIdx), counterValue);
+                    break;
+
+                case PMC_PMU_DF:
+                    WriteMSR(DF_PMC_DEBUG_CFG_MSR(debugMsrIdx), controlValue);
+                    WriteMSR(DF_PMC_DEBUG_COUNT_MSR(debugMsrIdx), counterValue);
+                    break;
+
+                case PMC_PMU_L3:
+                default:
+                    break;
+            }
+        }
+        else
+        {
+            DRVPRINTERROR("Error: Invalid msrIdx(%d).", msrIdx);
+        }
+    }
+
+    /*
+     * Load Config for all UMCs set in umcMask
+     */
+    if (PMC_PMU_UMC == type)
+    {
+        msrCountPerUmc = maxPmcCnt;
+
+        for (umcIdx = 0, umcMsrCountArrayIdx = 0; umcIdx < umcCount; umcIdx++)
+        {
+            for (umcMsrIdx = 0; umcMsrIdx < msrCountPerUmc; umcMsrIdx++)
+            {
+                controlValue = pPmcConfigArray[umcMsrIdx].m_controlValue;
+
+                if (controlValue == 0)
+                {
+                    continue;
+                }
+
+                counterValue = reset ? 0 : pPmcConfigGroup->m_pUmcMsrCountArray[umcMsrCountArrayIdx];
+                WriteMSR(UMC_PMC_CFG_MSR((umcMsrIdx + (umcIdx * msrCountPerUmc))), controlValue);
+                WriteMSR(UMC_PMC_COUNT_MSR((umcMsrIdx + (umcIdx * msrCountPerUmc))), counterValue);
+                umcMsrCountArrayIdx++;
+
+            }
+        }
+    }
+
+    /* Capture pmc config group load time */
+    if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_TIMESTAMP)
+    {
+        pPmcConfigGroup->m_loadTime = ReadMSR(PMC_TSC_MSR);
+    }
+
+    /* Capture DfClk if required */
+    if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_FCLK)
+    {
+        pPmcConfigGroup->m_dfClk = GetDfClk(GetCurrentCoreId());
+    }
+
+    /* Capture IRPerf if required */
+    if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_IRPERF)
+    {
+        pPmcConfigGroup->m_irPerf = ReadMSR(PMC_IRPERF_MSR);
+    }
+
+    /* Capture MPerf if required */
+    if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_MPERF)
+    {
+        pPmcConfigGroup->m_mPerf = ReadMSR(g_PmcMperfMsr);
+    }
+
+    /* Capture APerf if required */
+    if (pPmcConfigGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_APERF)
+    {
+        pPmcConfigGroup->m_aPerf = ReadMSR(g_PmcAperfMsr);
+    }
+
+    return retVal;
+}
+
+/* TODO: Add a flag to enable/disable collecting debug pmcs */
+int ReadPmcConfigGroup(PmcConfigGroup* pPmcConfigGroup, PmcPmuType type, uint32_t umcCount)
+{
+    int retVal = 0;
+    uint32_t debugMsrIdx = 0;
+    uint32_t msrIdx = 0;
+    PmcConfig* pPmcConfigArray = pPmcConfigGroup->m_pPmcConfigArray;
+    uint16_t pmcConfigCnt = pPmcConfigGroup->m_pmcConfigCnt;
+    uint32_t maxPmcCnt = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint32_t umcIdx = 0;
+    uint32_t umcMsrIdx = 0;
+    uint32_t msrCountPerUmc = 0;
+    uint32_t umcMsrCountArrayIdx = 0;
+
+    pmcCnt = GetMaxPmcCount(type, &debugPmcCnt);
+    maxPmcCnt = pmcCnt + debugPmcCnt;
+
+    DRVPRINT("pPmcConfigGroup(%p) type(%d) pmcConfigCnt(%u) pPmcConfigArray(%p)",
+             pPmcConfigGroup, type, pmcConfigCnt, pPmcConfigArray);
+
+    for (msrIdx = 0; pmcConfigCnt > 0 && type != PMC_PMU_UMC; msrIdx++)
+    {
+        if (!pPmcConfigArray[msrIdx].m_controlValue)
+        {
+            continue;
+        }
+
+        pmcConfigCnt--;
+
+        /* Public Pmcs*/
+        if (msrIdx < pmcCnt)
+        {
+            switch (type)
+            {
+                case PMC_PMU_CORE:
+                    pPmcConfigArray[msrIdx].m_counterValue =
+                    ReadMSR(CORE_PMC_COUNT_MSR(msrIdx));
+                    break;
+
+                case PMC_PMU_L3:
+                    pPmcConfigArray[msrIdx].m_counterValue =
+                    ReadMSR(CHL3_PMC_COUNT_MSR(msrIdx));
+                    break;
+
+                /* TODO: Do we need separate reads fir HI/Lo
+                 * for DF MSR. Is that for Legacy??.
+                 * Do we need to add a memory barrier in between
+                 * do they are not executed out of order?.*/
+                case PMC_PMU_DF:
+                    pPmcConfigArray[msrIdx].m_counterValue =
+                    ReadMSR(DF_PMC_COUNT_MSR(msrIdx));
+                    break;
+
+                default:
+                    break;
+            }
+        }
+        /* Debug Pmcs*/
+        else if (msrIdx < maxPmcCnt)
+        {
+            debugMsrIdx = msrIdx - pmcCnt;
+
+            switch (type)
+            {
+                case PMC_PMU_CORE:
+                    pPmcConfigArray[msrIdx].m_counterValue =
+                        ReadMSR(CORE_PMC_COUNT_MSR(debugMsrIdx));
+                    break;
+
+                case PMC_PMU_DF:
+                    /* TODO: Do we need separate reads fir HI/Lo
+                     * for DF MSR */
+                    pPmcConfigArray[msrIdx].m_counterValue =
+                        ReadMSR(DF_PMC_COUNT_MSR(debugMsrIdx));
+                    break;
+
+                case PMC_PMU_L3:
+                default:
+                    break;
+            }
+        }
+        else
+        {
+            DRVPRINTERROR("Error: Invalid msrIdx(%d)", msrIdx);
+        }
+    }
+
+    if (PMC_PMU_UMC == type)
+    {
+        msrCountPerUmc = maxPmcCnt;
+
+        for (umcIdx = 0, umcMsrCountArrayIdx = 0; umcIdx < umcCount;  umcIdx++)
+        {
+            for (umcMsrIdx = 0; umcMsrIdx < msrCountPerUmc; umcMsrIdx++)
+            {
+                if (pPmcConfigArray[umcMsrIdx].m_controlValue == 0)
+                {
+                    continue;
+                }
+
+                pPmcConfigGroup->m_pUmcMsrCountArray[umcMsrCountArrayIdx] =
+                    ReadMSR(UMC_PMC_COUNT_MSR((umcMsrIdx + (umcIdx * msrCountPerUmc))));
+
+                umcMsrCountArrayIdx++;
+            }
+        }
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+void ClearPmcConfig(void* pCtx)
+{
+    CoreContext* pCoreCtx = (CoreContext*)pCtx;
+    int type = PMC_PMU_INVALID;
+    int msrIdx = 0;
+    int debugMsrIdx = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint16_t maxPmcCnt = 0;
+    uint32_t umcCount = 0;
+    uint32_t umcIdx = 0;
+    uint32_t umcMsrIdx = 0;
+    uint32_t msrCountPerUmc = 0;
+
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+    {
+        if (pCoreCtx->m_pPmcConfigGroupArray[type] == NULL)
+        {
+            continue;
+        }
+
+        pmcCnt = GetMaxPmcCount((PmcPmuType)type, &debugPmcCnt);
+        maxPmcCnt = pmcCnt + debugPmcCnt;
+
+        /* TODO: For now clear all MSRs, but ideally clear the
+         * ones used by config groups? How to track the msrs used
+         * with multiple config groups */
+        for (msrIdx = 0; msrIdx < maxPmcCnt && type != PMC_PMU_UMC; msrIdx++)
+        {
+#if defined(__linux__)
+
+            if ((pCoreCtx->m_availabilityMask[type] & (1UL << msrIdx)) == 0)
+            {
+                continue;
+            }
+
+#endif
+
+            if (msrIdx < pmcCnt)
+            {
+                switch (type)
+                {
+                    case PMC_PMU_CORE:
+                        WriteMSR(CORE_PMC_CFG_MSR(msrIdx), 0);
+                        WriteMSR(CORE_PMC_COUNT_MSR(msrIdx), 0);
+                        break;
+
+                    case PMC_PMU_L3:
+                        WriteMSR(CHL3_PMC_CFG_MSR(msrIdx), 0);
+                        WriteMSR(CHL3_PMC_COUNT_MSR(msrIdx), 0);
+                        break;
+
+                    case PMC_PMU_DF:
+                        WriteMSR(DF_PMC_CFG_MSR(msrIdx), 0);
+                        WriteMSR(DF_PMC_COUNT_MSR(msrIdx), 0);
+                        break;
+
+                    default:
+                        break;
+                }
+            }
+            else if (msrIdx < maxPmcCnt)
+            {
+                debugMsrIdx = msrIdx - pmcCnt;
+
+                switch (type)
+                {
+                    case PMC_PMU_CORE:
+                        WriteMSR(CORE_PMC_DEBUG_CFG_MSR(debugMsrIdx), 0);
+                        WriteMSR(CORE_PMC_DEBUG_COUNT_MSR(debugMsrIdx), 0);
+                        break;
+
+                    case PMC_PMU_DF:
+                        WriteMSR(DF_PMC_DEBUG_CFG_MSR(debugMsrIdx), 0);
+                        WriteMSR(DF_PMC_DEBUG_COUNT_MSR(debugMsrIdx), 0);
+                        break;
+
+                    case PMC_PMU_L3:
+                    default:
+                        break;
+                }
+            }
+            else
+            {
+                DRVPRINTERROR("Error: Invalid msrdIdx(%d).", msrIdx);
+            }
+        }
+
+        if (PMC_PMU_UMC == type)
+        {
+            umcCount = pCoreCtx->m_umcCount;
+            msrCountPerUmc = maxPmcCnt;
+
+            for (umcIdx = 0; umcIdx < umcCount; umcIdx++)
+            {
+                for (umcMsrIdx = 0; umcMsrIdx < msrCountPerUmc; umcMsrIdx++)
+                {
+                    WriteMSR(UMC_PMC_CFG_MSR((umcMsrIdx + (umcIdx * msrCountPerUmc))), 0);
+                    WriteMSR(UMC_PMC_COUNT_MSR((umcMsrIdx + (umcIdx * msrCountPerUmc))), 0);
+                }
+            }
+        }
+    }
+}
+
+void ResetPmcCounters(CoreContext* pCoreCtx, PmcPmuType type)
+{
+    int msrIdx = 0;
+    int debugMsrIdx = 0;
+    uint16_t pmcCnt = 0;
+    uint16_t debugPmcCnt = 0;
+    uint16_t maxPmcCnt = 0;
+    uint16_t pmcConfigCnt = 0;
+    PmcConfigGroup* pPmcConfigGroupArray = NULL;
+    uint32_t umcIdx = 0;
+    uint32_t umcMsrIdx = 0;
+    uint32_t msrCountPerUmc = 0;
+    uint32_t umcCount = 0;
+    bool isL3DfAllowed = true;
+
+    DRVPRINTERROR("ResetPmcCounters");
+    // In VM guest mode L3 and DF are disabled
+    if (IsHyperVisor() && !IsHost())
+    {
+        isL3DfAllowed = false;
+    }
+
+    pmcCnt = GetMaxPmcCount((PmcPmuType)type, &debugPmcCnt);
+    maxPmcCnt = pmcCnt + debugPmcCnt;
+
+    pPmcConfigGroupArray = pCoreCtx->m_pPmcConfigGroupArray[type];
+
+    if (NULL != pPmcConfigGroupArray)
+    {
+        pmcConfigCnt = pPmcConfigGroupArray->m_pmcConfigCnt;
+
+        for (msrIdx = 0; msrIdx < maxPmcCnt && (pmcConfigCnt != 0) && type != PMC_PMU_UMC; msrIdx++)
+        {
+            /* Skip if there is no valid control value at msrIdx */
+            if (pPmcConfigGroupArray->m_pPmcConfigArray[msrIdx].m_controlValue == 0)
+            {
+                continue;
+            }
+
+            pmcConfigCnt--;
+
+            if (msrIdx < pmcCnt)
+            {
+                switch (type)
+                {
+                    case PMC_PMU_CORE:
+                        WriteMSR(CORE_PMC_COUNT_MSR(msrIdx), 0);
+                        break;
+
+                    case PMC_PMU_L3:
+                        if (isL3DfAllowed)
+                        {
+                            WriteMSR(CHL3_PMC_COUNT_MSR(msrIdx), 0);
+                        }
+                        break;
+
+                    case PMC_PMU_DF:
+                        if (isL3DfAllowed)
+                        {
+                            WriteMSR(DF_PMC_COUNT_MSR(msrIdx), 0);
+                        }
+                        break;
+
+                    default:
+                        break;
+                }
+            }
+            else if (msrIdx < maxPmcCnt)
+            {
+                debugMsrIdx = msrIdx - pmcCnt;
+
+                switch (type)
+                {
+                    case PMC_PMU_CORE:
+                        WriteMSR(CORE_PMC_DEBUG_COUNT_MSR(debugMsrIdx), 0);
+                        break;
+
+                    case PMC_PMU_DF:
+                        WriteMSR(DF_PMC_DEBUG_COUNT_MSR(debugMsrIdx), 0);
+                        break;
+
+                    case PMC_PMU_L3:
+                    default:
+                        break;
+                }
+            }
+            else
+            {
+                DRVPRINTERROR("Error: Invalid msrdIdx(%d).", msrIdx);
+            }
+        }
+
+        if (PMC_PMU_UMC == type)
+        {
+            umcCount = pCoreCtx->m_umcCount;
+            msrCountPerUmc = maxPmcCnt;
+
+            for (umcIdx = 0; umcIdx < umcCount; umcIdx++)
+            {
+                for (umcMsrIdx = 0; umcMsrIdx < msrCountPerUmc; umcMsrIdx++)
+                {
+                    /* Skip if there is no valid control value at msrIdx */
+                    if (pPmcConfigGroupArray->m_pPmcConfigArray[umcMsrIdx].m_controlValue == 0)
+                    {
+                        continue;
+                    }
+
+                    WriteMSR(UMC_PMC_COUNT_MSR((umcMsrIdx + (umcIdx * msrCountPerUmc))), 0);
+                }
+            }
+        }
+    }
+}
+
+/*
+ * Multiplex pmc configuration group
+ */
+int MultiplexPmcConfigGroup(CoreContext* pCoreCtx, PmcPmuType type)
+{
+    int retVal = 0;
+    PmcConfigGroup* pCurrentCfgGroup = NULL;
+    bool reset = false;
+    uint64_t tsc = 0;
+    uint64_t delta = 0;
+    uint64_t irPerf = 0;
+    uint64_t mPerf = 0;
+    uint64_t aPerf = 0;
+
+    //DRVPRINT("pCoreCtx(%p)", pCoreCtx);
+
+    if (pCoreCtx == NULL)
+    {
+        retVal = EINVAL;
+    }
+
+    if (!retVal)
+    {
+        pCurrentCfgGroup = pCoreCtx->m_pPmcConfigGroupArray[type];
+
+        if (pCurrentCfgGroup == NULL)
+        {
+            retVal = ERROR_PMC_MUXPMCCFGGRP_NULL_CFGGRP;
+        }
+    }
+
+    if (!retVal)
+    {
+        /* Timestamp before multiplexing */
+        tsc = ReadMSR(PMC_TSC_MSR);
+
+        /* Capture pmc config group delta time */
+        if (pCurrentCfgGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_TIMESTAMP)
+        {
+            pCurrentCfgGroup->m_deltaTime += tsc - pCurrentCfgGroup->m_loadTime;
+        }
+
+        if (pCurrentCfgGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_FCLK)
+        {
+            /* Capture delta fclk */
+            pCurrentCfgGroup->m_dfClkDelta +=
+                GetDfClk(pCoreCtx->m_coreId) - pCurrentCfgGroup->m_dfClk;
+        }
+
+        /* Capture IRPerf delta*/
+        if (pCurrentCfgGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_IRPERF)
+        {
+            irPerf = ReadMSR(PMC_IRPERF_MSR);
+
+            // Check for irPerf rollover
+            if (irPerf < pCurrentCfgGroup->m_irPerf)
+            {
+                delta = PMC_IRPERF_MAX_VALUE - pCurrentCfgGroup->m_irPerf;
+                delta += irPerf;
+            }
+            else
+            {
+                delta = irPerf - pCurrentCfgGroup->m_irPerf;
+            }
+
+            pCurrentCfgGroup->m_irPerfDelta += delta;
+        }
+
+        /* Capture MPerf delta*/
+        if (pCurrentCfgGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_MPERF)
+        {
+            mPerf = ReadMSR(g_PmcMperfMsr);
+
+            // Check for mPerf rollover
+            if (mPerf < pCurrentCfgGroup->m_mPerf)
+            {
+                delta = PMC_MPERF_MAX_VALUE - pCurrentCfgGroup->m_mPerf;
+                delta += mPerf;
+            }
+            else
+            {
+                delta = mPerf - pCurrentCfgGroup->m_mPerf;
+            }
+
+            pCurrentCfgGroup->m_mPerfDelta += delta;
+        }
+
+        /* Capture APerf delta*/
+        if (pCurrentCfgGroup->m_pmcConfigGroupAttrs & PMC_CONFIG_GROUP_ATTR_APERF)
+        {
+            aPerf = ReadMSR(g_PmcAperfMsr);
+
+            // Check for aPerf rollover
+            if (aPerf < pCurrentCfgGroup->m_aPerf)
+            {
+                delta = PMC_APERF_MAX_VALUE - pCurrentCfgGroup->m_aPerf;
+                delta += aPerf;
+            }
+            else
+            {
+                delta = aPerf - pCurrentCfgGroup->m_aPerf;
+            }
+
+            pCurrentCfgGroup->m_aPerfDelta += delta;
+        }
+
+        /* Reset count if about to log sample. */
+        if (pCoreCtx->m_currSamplingCounter[type] == 0)
+        {
+            pCoreCtx->m_timeEnabled[type] = tsc - pCoreCtx->m_timeEnabledBegin[type];
+            reset = true;
+        }
+
+        /* Load next config group */
+        // TODO: Always returns true
+        retVal = LoadPmcConfig(pCurrentCfgGroup->m_pNext, (PmcPmuType)type, pCoreCtx->m_umcCount, reset);
+
+        if (!retVal)
+        {
+            /* Capture time enabled begin time for upcoming sample */
+            if (pCoreCtx->m_currSamplingCounter[type] == 0)
+            {
+                pCoreCtx->m_timeEnabledBegin[type] = pCurrentCfgGroup->m_pNext->m_loadTime;
+            }
+
+            pCoreCtx->m_pPmcConfigGroupArray[type] = pCurrentCfgGroup->m_pNext;
+        }
+    }
+
+    //DRVPRINT("retVal(%d)", retVal);
+    return retVal;
+}
+
+/* Write sample for all types */
+void PmcFlushDataBuffer(void* pCtx)
+{
+    CoreContext* pCoreCtx = (CoreContext*)pCtx;
+    int type = PMC_PMU_INVALID;
+
+    DRVPRINT("pCoreCtx(%p)", pCoreCtx);
+
+    if (pCoreCtx != NULL)
+    {
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            // TODO: Should this be set unconditionally?
+            pCoreCtx->m_currSamplingCounter[type] = 1;
+        }
+
+        PmcCallBack(g_pPmcClientContext, pCoreCtx);
+
+#if defined (_WIN32)
+        KeSetEvent(&pCoreCtx->m_event, 1, false);
+#endif
+    }
+}
+
+void* PmcGetDataBuffer(PmcDataBufferContext* pCtx, uint64_t recordSize)
+{
+    char* pBuffer = (char*)pCtx->m_pBuffer;
+    uint64_t offset = pCtx->m_offset;
+    uint64_t chunkMask = pCtx->m_chunkSize - 1;
+    PmcBufferMetaData* pHdr = NULL;
+    /* Adjust chunk size */
+    uint64_t chunkSize = pCtx->m_chunkSize - sizeof(PmcBufferMetaData);
+
+    /* Record too big to fit in a single chunk */
+    if (recordSize > chunkSize)
+    {
+        DRVPRINTERROR("Error: recordSize(%llu) offset(%llu)", recordSize, chunkSize);
+        return NULL;
+    }
+
+    /* Get header for current chunk */
+    // TODO: If we remove chunkMask, then chunk size would no
+    // longer need be page size multiple.
+    pHdr = (PmcBufferMetaData*)(pBuffer + (offset & ~chunkMask));
+
+    if (!pHdr->m_dirty)
+    {
+        /* Update chunk header */
+        pHdr->m_dirty = true;
+        pHdr->m_size = recordSize;
+
+        /* Adjust for buffer metadata */
+        pBuffer += (offset + sizeof(PmcBufferMetaData));
+
+        /* Calculate new offset */
+        offset += pCtx->m_chunkSize;
+
+        /* Set offset to zero if the chunk size exceeds the remaining buffer size */
+        if ((offset + pCtx->m_chunkSize) >= pCtx->m_bufferSize)
+        {
+            offset = 0;
+        }
+
+        /* Save new offset */
+        pCtx->m_offset = offset;
+    }
+    else
+    {
+        // No space available in buffer.
+        DRVPRINTERROR("Error: pHdr(%llu)", *((unsigned long long*)pBuffer));
+        pBuffer = NULL;
+    }
+
+    /* Set notification for data availability */
+    pCtx->m_pendingRead = true;
+
+    DRVPRINT("pBuffer(%p) offset(%llu)", pBuffer, offset);
+
+    return (void*)(pBuffer);
+}
+
+/* Note: Must be called after all the configurations have
+ * been processed */
+int AllocateDataBufferContext(ClientContext* pClientCtx)
+{
+    int retVal = 0;
+    CoreContext* pCoreCtx = NULL;
+    PmcDataBufferContext* pDataBufferCtx = NULL;
+    int type = PMC_PMU_INVALID;
+    int coreId = 0;
+    int numOfCores = GetCoreCount();
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && !retVal; type++)
+    {
+        for (coreId = 0; coreId < numOfCores && !retVal; coreId++)
+        {
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+            if (NULL == pCoreCtx)
+            {
+                retVal = ERROR_PMC_ALLOCATEDATABUFFERCONTEXT_NULL_CORECTX;
+                break;
+            }
+
+            /* Skip if there are no valid configs for this type */
+            if (pCoreCtx->m_pmcConfigGroupCnt[type] == 0)
+            {
+                continue;
+            }
+
+            pDataBufferCtx = (PmcDataBufferContext*)AllocateMemory(sizeof(PmcDataBufferContext));
+
+            if (pDataBufferCtx == NULL)
+            {
+                retVal = ERROR_PMC_ALLOCATEDATABUFFERCONTEXT_NULL_DATABUFFERCTX;
+                break;
+            }
+
+            pDataBufferCtx->m_coreId = coreId;
+            pDataBufferCtx->m_pBuffer = NULL;
+            pDataBufferCtx->m_bufferSize = pClientCtx->m_dataBufferSize[type];
+            pDataBufferCtx->m_offset = 0;
+            pDataBufferCtx->m_chunkSize = pClientCtx->m_dataBufferThreshold[type];
+            pDataBufferCtx->m_pendingRead = false;
+
+#if defined(__linux__)
+            atomic_set(&pDataBufferCtx->m_pollStatus, 0);
+            InitDataBufferWaitQueue(pDataBufferCtx);
+            atomic_set(&pDataBufferCtx->m_mmapCount, 0);
+#endif
+
+#if defined (_WIN32)
+            pDataBufferCtx->m_pClientContext = NULL;
+            pDataBufferCtx->m_type = (PmcPmuType)type;
+#endif
+            pCoreCtx->m_pDataBufferContext[type] = pDataBufferCtx;
+
+            DRVPRINT("type(%s) coreId(%d) pDataBufferCtx(%p)",
+                     GetPmcTypeString((PmcPmuType)type), coreId, pDataBufferCtx);
+        }
+    }
+
+    if (retVal)
+    {
+        FreeDataBufferContext(pClientCtx);
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+void FreeDataBufferContext(ClientContext* pClientCtx)
+{
+    int coreId = 0;
+    int type = PMC_PMU_INVALID;
+    CoreContext* pCoreCtx = NULL;
+    int numOfCores = GetCoreCount();
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    /* Get total number of cores */
+    for (coreId = 0; coreId < numOfCores; coreId++)
+    {
+        if (NULL != pClientCtx)
+        {
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+            if (NULL != pCoreCtx)
+            {
+                for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+                {
+                    if (pCoreCtx->m_pDataBufferContext[type] != NULL)
+                    {
+                        FreeMemory(pCoreCtx->m_pDataBufferContext[type]);
+                    }
+                }
+            }
+        }
+    }
+}
+
+int AddPmcConfigGroup(CoreContext* pCoreCtx,
+                      PmcPmuType type,
+                      PmcConfigGroup* pPmcConfigGroup)
+{
+    int retVal = 0;
+    PmcConfigGroup* pCurrentGroup = pCoreCtx->m_pPmcConfigGroupArray[type];
+
+    DRVPRINT("pCoreCtx(%p) type(%s) pPmcConfigGroup(%p) pPmcConfigArray(%p)",
+             pCoreCtx, GetPmcTypeString(type), pPmcConfigGroup, pPmcConfigGroup->m_pPmcConfigArray);
+
+    if (pCurrentGroup == NULL)
+    {
+        /* First node will point to itself
+         * in a circular linked list */
+        pCoreCtx->m_pPmcConfigGroupArray[type] = pPmcConfigGroup;
+        pPmcConfigGroup->m_pNext = pPmcConfigGroup;
+    }
+    else
+    {
+        pPmcConfigGroup->m_pNext = pCurrentGroup->m_pNext;
+        /* Should this be an atomic set? */
+        pCurrentGroup->m_pNext = pPmcConfigGroup;
+    }
+
+    pCoreCtx->m_pmcConfigGroupCnt[type]++;
+    pCoreCtx->m_totalPmcConfigGroupCnt++;
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+uint64_t SetPmcConfigAttrs(uint8_t groupAttrs)
+{
+    uint8_t pmcConfigGroupAttrs = 0;
+
+    if (groupAttrs & GROUP_ATTR_TIMESTAMP)
+    {
+        pmcConfigGroupAttrs |= PMC_CONFIG_GROUP_ATTR_TIMESTAMP;
+    }
+
+    if (groupAttrs & GROUP_ATTR_IRPERF)
+    {
+        pmcConfigGroupAttrs |= PMC_CONFIG_GROUP_ATTR_IRPERF;
+    }
+
+    if (groupAttrs & GROUP_ATTR_MPERF)
+    {
+        pmcConfigGroupAttrs |= PMC_CONFIG_GROUP_ATTR_MPERF;
+    }
+
+    if (groupAttrs & GROUP_ATTR_APERF)
+    {
+        pmcConfigGroupAttrs |= PMC_CONFIG_GROUP_ATTR_APERF;
+    }
+
+    if (groupAttrs & GROUP_ATTR_FCLK)
+    {
+        pmcConfigGroupAttrs |= PMC_CONFIG_GROUP_ATTR_FCLK;
+    }
+
+    return pmcConfigGroupAttrs;
+}
+
+int AllocatePmcConfigGroup(PmcConfigGroup** ppPmcConfigGroup,
+                           uint64_t* pPmcConfigArray,
+                           uint32_t pmcConfigCount,
+                           uint16_t maxPmcCnt,
+                           uint16_t groupAttrs,
+                           uint64_t groupId,
+                           uint32_t availabilityMask,
+                           uint32_t umcCount,
+                           PmcPmuType type)
+{
+    int retVal = 0;
+    int msrIdx = 0;
+    int j = 0;
+    PmcConfig* pConfigArray = NULL;
+    PmcConfigGroup* pPmcConfigGroup = NULL;
+    uint32_t umcMsrCount = 0;
+    uint32_t msrCountPerUmc = 0;
+
+    DRVPRINT("pPmcConfigGroup(%p) pPmcConfigArray(%p) "
+             "pmcConfigCnt(%u) maxPmcCnt(%u) pmcConfigGroupAttrs(%u) availabilityMask(%x) umcCount(%u)",
+             pPmcConfigGroup, pPmcConfigArray, pmcConfigCount,
+             maxPmcCnt, groupAttrs, availabilityMask, umcCount);
+
+    pPmcConfigGroup = (PmcConfigGroup*)AllocateMemory(sizeof(PmcConfigGroup));
+
+    if (pPmcConfigGroup == NULL)
+    {
+        retVal = ERROR_PMC_ALLOCATEPMCCFGGRP_NULL_PMCCFGGRP;
+    }
+
+    if (!retVal)
+    {
+        pPmcConfigGroup->m_pmcConfigCnt = pmcConfigCount;
+        pPmcConfigGroup->m_pNext = NULL;
+        pPmcConfigGroup->m_loadTime = 0;
+        pPmcConfigGroup->m_deltaTime = 0;
+        pPmcConfigGroup->m_dfClkDelta = 0;
+        pPmcConfigGroup->m_irPerfDelta = 0;
+        pPmcConfigGroup->m_mPerfDelta = 0;
+        pPmcConfigGroup->m_aPerfDelta = 0;
+        pPmcConfigGroup->m_pmcConfigGroupAttrs = SetPmcConfigAttrs(groupAttrs);
+        pPmcConfigGroup->m_pmcConfigGroupId = groupId;
+        pPmcConfigGroup->m_umcMsrCount = 0;
+        pPmcConfigGroup->m_pUmcMsrCountArray = NULL;
+
+        pConfigArray = (PmcConfig*)AllocateMemory(maxPmcCnt * sizeof(PmcConfig));
+
+        if (pConfigArray == NULL)
+        {
+            retVal = ERROR_PMC_ALLOCATEPMCCFGGRP_NULL_CFGARRY;
+        }
+    }
+
+    if (!retVal)
+    {
+        DRVPRINT("pConfigArray(%p) ", pConfigArray);
+
+        memset(pConfigArray, 0, maxPmcCnt * sizeof(PmcConfig));
+
+        for (msrIdx = 0, j = 0; msrIdx < maxPmcCnt && j < pmcConfigCount; msrIdx++)
+        {
+#if defined(__linux__)
+
+            // Note: Skip availability check for windows
+            if ((type != PMC_PMU_UMC) && ((availabilityMask & (1UL << msrIdx)) == 0))
+            {
+                DRVPRINTERROR("Error: PMC unavailable idx (%d) msr (0x%x) availabilityMask (%d)", msrIdx, (int)pPmcConfigArray[j], availabilityMask);
+                continue;
+            }
+
+#endif
+
+            pConfigArray[msrIdx].m_controlValue = pPmcConfigArray[j];
+            pConfigArray[msrIdx].m_counterValue = 0;
+            j++;
+
+            DRVPRINT("pConfigArray[%d](%llx) ", msrIdx, pConfigArray[msrIdx].m_controlValue);
+        }
+
+        // Set error code if all the configs were not consumned
+        // This happens when watchdog takes up a counter on linux
+        if (j < pmcConfigCount)
+        {
+            // TODO: Replace this with appropriate error code
+            DRVPRINTERROR("Error: Unable to config all PMCs. maxPmcCnt(%d) umcCount(%d) used(%d) pmcConfigCount(%d)",maxPmcCnt, umcCount, j, pmcConfigCount);
+            retVal = ERROR_PMC_ALLOCATEPMCCFGGRP_PMCNOTCONFIGURED;
+        }
+
+        pPmcConfigGroup->m_pPmcConfigArray = pConfigArray;
+
+        if (PMC_PMU_UMC == type)
+        {
+            msrCountPerUmc = maxPmcCnt;
+            umcMsrCount = umcCount * msrCountPerUmc;
+            pPmcConfigGroup->m_umcMsrCount = umcMsrCount;
+
+            pPmcConfigGroup->m_pUmcMsrCountArray = (uint64_t*)AllocateMemory(umcMsrCount * sizeof(uint64_t));
+
+            if (pPmcConfigGroup->m_pUmcMsrCountArray == NULL)
+            {
+                DRVPRINTERROR("Error: pPmcConfigGroup->m_pUmcMsrCountArray == NULL");
+                retVal = ERROR_PMC_ALLOCATEPMCCFGGRP_NULL_UMCCOUNTARRYA;
+            }
+
+            if (!retVal)
+            {
+                memset(pPmcConfigGroup->m_pUmcMsrCountArray, 0, sizeof(uint64_t) * umcMsrCount);
+            }
+        }
+    }
+
+    if (!retVal)
+    {
+        *ppPmcConfigGroup = pPmcConfigGroup;
+    }
+
+    if (retVal)
+    {
+        if (pPmcConfigGroup != NULL)
+        {
+            if (pPmcConfigGroup->m_pPmcConfigArray != NULL)
+            {
+                FreeMemory(pPmcConfigGroup->m_pPmcConfigArray);
+                pPmcConfigGroup->m_pPmcConfigArray = NULL;
+            }
+
+            if (pPmcConfigGroup->m_pUmcMsrCountArray != NULL)
+            {
+                FreeMemory(pPmcConfigGroup->m_pUmcMsrCountArray);
+                pPmcConfigGroup->m_pUmcMsrCountArray = NULL;
+            }
+
+            FreeMemory(pPmcConfigGroup);
+            pPmcConfigGroup = NULL;
+        }
+    }
+
+    if(retVal)
+    {
+        DRVPRINTERROR("Error: retVal(0x%x)", retVal);
+    }
+
+    return retVal;
+}
+
+void FreePmcConfigGroup(ClientContext* pClientCtx)
+{
+    int coreId = 0;
+    CoreContext* pCoreCtx = NULL;
+    PmcConfigGroup* pPmcCfgGroup = NULL;
+    int type = PMC_PMU_INVALID;
+    int numOfCores = GetCoreCount();
+
+    DRVPRINTERROR("pClientCtx(%p)", pClientCtx);
+    // Config groups memories are allocated only for the cores which are active
+    // pCoreCtx context is allocated for all cores as below
+    // pCoreCtxArray = (CoreContext*)AllocateMemory(numOfCores * sizeof(CoreContext)); // in AllocateCoreContext
+
+    if (pClientCtx != NULL)
+    {
+        for (coreId = 0; coreId < numOfCores; coreId++)
+        {
+            pCoreCtx = NULL;
+
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+            if (pCoreCtx != NULL)
+            {
+                for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+                {
+                    pPmcCfgGroup = NULL;
+
+                    if (pCoreCtx->m_pPmcConfigGroupArray[type] != NULL)
+                    {
+                        pPmcCfgGroup = pCoreCtx->m_pPmcConfigGroupArray[type];
+                    }
+
+                    if (pPmcCfgGroup != NULL)
+                    {
+                        if (pPmcCfgGroup->m_pUmcMsrCountArray != NULL)
+                        {
+                            FreeMemory(pPmcCfgGroup->m_pUmcMsrCountArray);
+                            pPmcCfgGroup->m_pUmcMsrCountArray = NULL;
+                        }
+
+                        if (pPmcCfgGroup->m_pPmcConfigArray != NULL)
+                        {
+                            FreeMemory(pPmcCfgGroup->m_pPmcConfigArray);
+                            pPmcCfgGroup->m_pPmcConfigArray = NULL;
+                        }
+
+                        FreeMemory(pPmcCfgGroup);
+                        pPmcCfgGroup = NULL;
+                        pCoreCtx->m_pPmcConfigGroupArray[type] = NULL;
+                    }
+                }
+            }
+        }
+    }
+}
+
+/* Initialize sampling counters for all configured cores. */
+static void InitSamplingCounter(ClientContext* pClientCtx)
+{
+    int type = PMC_PMU_INVALID;
+    int coreId = 0;
+    CoreContext* pCoreCtx = NULL;
+    uint32_t numOfCores = GetCoreCount();
+
+    DRVPRINT("pClientCtx(%p) numOfCores(%d)", pClientCtx, numOfCores);
+
+    for (coreId = 0; coreId < numOfCores; coreId++)
+    {
+        pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            /* Is this part of any core masks? */
+            pCoreCtx->m_currSamplingCounter[type] =
+                pClientCtx->m_samplingCount[type];
+        }
+    }
+}
+
+// Allocate and initialize core context
+int AllocateCoreContext(ClientContext* pClientCtx)
+{
+    bool retVal = 0;
+    int i = 0;
+    CoreContext* pCoreCtxArray = NULL;
+    int numOfCores = GetCoreCount();
+    int type = PMC_PMU_INVALID;
+
+    DRVPRINT("pClientCtx(%p) numOfCores(%d)", pClientCtx, numOfCores);
+
+    /* Note: Allocate memory for all available cores
+     * even if not included in core mask */
+    pCoreCtxArray = (CoreContext*)AllocateMemory(numOfCores * sizeof(CoreContext));
+
+    if (pCoreCtxArray == NULL)
+    {
+        DRVPRINTERROR("Error: pCoreCtxArray == NULL");
+        retVal = ERROR_PMC_ALLOCATECORECONTEXT_NULL_CORECTXARRAY;
+    }
+
+    if (!retVal)
+    {
+        for (i = 0; i < numOfCores; i++)
+        {
+            pCoreCtxArray[i].m_coreId = i;
+            pCoreCtxArray[i].m_socketId = 0;
+            pCoreCtxArray[i].m_pTimerConfig = NULL;
+
+            for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+            {
+                pCoreCtxArray[i].m_pPmcConfigGroupArray[type] = NULL;
+                pCoreCtxArray[i].m_pDataBufferContext[type] = NULL;
+                pCoreCtxArray[i].m_currSamplingCounter[type] = 0;
+                pCoreCtxArray[i].m_pmcConfigGroupCnt[type] = 0;
+                pCoreCtxArray[i].m_timeEnabled[type] = 0;
+                pCoreCtxArray[i].m_timeEnabledBegin[type] = 0;
+                pCoreCtxArray[i].m_droppedSampleCount[type] = 0;
+                pCoreCtxArray[i].m_availabilityMask[type] = 0;
+            }
+
+            pCoreCtxArray[i].m_umcSampleRecordSize = 0;
+            pCoreCtxArray[i].m_umcCount = 0;
+            pCoreCtxArray[i].m_totalPmcConfigGroupCnt = 0;
+        }
+
+        pClientCtx->m_pCoreContext = pCoreCtxArray;
+    }
+
+    if (retVal)
+    {
+        FreeCoreContext(pClientCtx);
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+void FreeCoreContext(ClientContext* pClientCtx)
+{
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    if ((pClientCtx != NULL) && (pClientCtx->m_pCoreContext != NULL))
+    {
+        FreeMemory(pClientCtx->m_pCoreContext);
+        pClientCtx = NULL;
+    }
+}
+
+static void SetSamplingFactor(ClientContext* pClientCtx)
+{
+    uint64_t timerInterval = pClientCtx->m_timerInterval;
+    uint64_t logInterval = pClientCtx->m_logInterval;
+    uint16_t configGroupCnt = 0;
+    uint64_t samplingFactor = 0;
+    int type = PMC_PMU_INVALID;
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    if (pClientCtx != NULL)
+    {
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            configGroupCnt = pClientCtx->m_pmcConfigGroupCnt[type];
+
+            /* Skip if there are no valid configurations for pmc type
+             * and prevent divide by zero.*/
+            if (configGroupCnt == 0)
+            {
+                continue;
+            }
+
+            /* Sampling Factor =
+             * LogInterval / (MuxInterval * Number of Event Groups) */
+            samplingFactor = logInterval / timerInterval;
+            samplingFactor /= configGroupCnt;
+
+            /* TODO: Should we round up instead of down? But how? */
+            /* Cannot be zero */
+            if (!samplingFactor)
+            {
+                samplingFactor++;
+            }
+
+            /* If new interval is not equal to log interval */
+            if (logInterval != (samplingFactor * timerInterval * configGroupCnt))
+            {
+                /* TODO: Print log interval changed to xxx for pmc type yyy */
+            }
+
+            pClientCtx->m_samplingCount[type] = (uint16_t)samplingFactor * configGroupCnt;
+
+            DRVPRINT("samplingCount[%d](%u)", type, pClientCtx->m_samplingCount[type]);
+        }
+    }
+}
+
+static void SetTimerInterval(ClientContext* pClientCtx)
+{
+    bool multiplex = false;
+    int type = PMC_PMU_INVALID;
+
+    if (pClientCtx != NULL)
+    {
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            if (pClientCtx->m_pmcConfigGroupCnt[type] > 1)
+            {
+                multiplex = true;
+                break;
+            }
+        }
+
+        if (multiplex)
+        {
+            pClientCtx->m_timerInterval = pClientCtx->m_muxInterval;
+        }
+        else
+        {
+            pClientCtx->m_timerInterval = pClientCtx->m_logInterval;
+        }
+
+        SetSamplingFactor(pClientCtx);
+
+        /* Initialize current sampling counter for each core and other
+         * initializations */
+        InitSamplingCounter(pClientCtx);
+
+        pClientCtx->m_multiplex = multiplex;
+    }
+}
+
+static int GetCoreMaskArrayCount(uint64_t* pCoreMaskArrary)
+{
+    int count = 0;
+    uint64_t coreMask = 0;
+    int i = 0;
+    int j = 0;
+
+    for (i = 0; i < PMC_CORE_MASK_ARRAY_SIZE; i++)
+    {
+        coreMask = pCoreMaskArrary[i];
+
+        for (j = 0; j < PMC_CORE_MASK_BIT_WIDTH; j++)
+        {
+            if (coreMask & (1ULL << j))
+            {
+                count++;
+            }
+        }
+    }
+
+    return count;
+}
+
+
+
+void FreeUmcMaskArray(ClientContext* pClientCtx)
+{
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+    if (pClientCtx != NULL)
+    {
+        pClientCtx->m_umcMaskArraySize = 0;
+        memset(pClientCtx->m_umcMaskArray, 0, sizeof(uint32) * PMC_MAX_SOCKET_COUNT);
+    }
+}
+
+int AllocateCoreMaskArray(ClientContext* pClientCtx)
+{
+    int type = PMC_PMU_INVALID;
+    int retVal = 0;
+    uint64_t* pCoreMask = NULL;
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+    {
+        pCoreMask = (uint64_t*)AllocateMemory(PMC_CORE_MASK_ARRAY_SIZE * sizeof(uint64_t));
+
+        if (pCoreMask != NULL)
+        {
+            memset(pCoreMask, 0 , PMC_CORE_MASK_ARRAY_SIZE * sizeof(uint64_t));
+            pClientCtx->m_pPmcCoreMaskArray[type] = pCoreMask;
+        }
+        else
+        {
+            DRVPRINTERROR("Error: Failed AllocateMemory");
+            retVal = ERROR_PMC_ALLOCATECOREMASKARRY_NULLCOREMASK;
+            break;
+        }
+    }
+
+    if (retVal)
+    {
+        FreeCoreMaskArray(pClientCtx);
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+void FreeCoreMaskArray(ClientContext* pClientCtx)
+{
+    int type = PMC_PMU_INVALID;
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    if (pClientCtx != NULL)
+    {
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            if (pClientCtx->m_pPmcCoreMaskArray[type] != NULL)
+            {
+                FreeMemory(pClientCtx->m_pPmcCoreMaskArray[type]);
+                pClientCtx->m_pPmcCoreMaskArray[type] = NULL;
+            }
+        }
+    }
+}
+
+/* Process configuration */
+int ProcessCountModeProfileConfig(ClientContext* pClientCtx,
+                                  CountModeProfileConfig* pConfig)
+{
+
+    int retVal = 0;
+    int type = PMC_PMU_INVALID;
+    uint32_t grpIdx = 0;
+    uint16_t coreId = 0;
+    uint64_t coreMask = 0;
+    GroupType groupType = GROUP_TYPE_INVALID;
+    uint16_t groupConfigCnt = 0;
+    uint16_t maxPmcCnt = 0;
+    uint16_t groupAttrs = 0;
+    uint64_t groupId = 0;
+    uint32_t numOfConfigGroups = 0;
+    bool enableIRPerf = false;
+    int numOfCores = GetCoreCount();
+    uint16_t debugPmcCnt = 0;
+    uint32_t socketId = 0;
+    uint32_t umcCount = 0;
+    uint64_t* pCoreMaskArray = NULL;
+    CoreContext* pCoreCtx = NULL;
+    uint64_t* pPmcConfigArray = NULL;
+    CountModeGroupConfig* pGroupConfig = NULL;
+    PTARGET_SYSTEM_INFO pTargetSystemInfo = NULL;
+    PmcConfigGroup* pPmcConfigGroup = NULL;
+
+
+    DRVPRINT("pClientCtx(%p) pConfig(%p)", pClientCtx, pConfig);
+
+    GetTargetSystemInfo(&pTargetSystemInfo, false);
+
+    if (pClientCtx == NULL || pConfig == NULL || pTargetSystemInfo == NULL || g_pPmcClientContext == NULL)
+    {
+        DRVPRINTERROR("Error: pClientCtx == NULL || pConfig == NULL || pTargetSystemInfo == NULL || g_pPmcClientContext == NULL");
+        retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_INVALIDPARAMS;
+    }
+
+    if(!retVal)
+    {
+        if (g_pPmcClientContext->m_clientState != PMC_CLIENT_STATE_INIT)
+        {
+            DRVPRINTERROR("Error: Client state is not in PMC_CLIENT_STATE_INIT, current state(%d)\n", g_pPmcClientContext->m_clientState);
+            retVal = ERROR_PMC_INVALID_STATE;
+        }
+    }
+
+    if (!retVal)
+    {
+        /* Allocate space for Core mask array */
+        retVal = AllocateCoreMaskArray(pClientCtx);
+    }
+    else
+    {
+        DRVPRINTERROR("Error: AllocateCoreMaskArray failed\n");
+    }
+
+    if (!retVal)
+    {
+        /* Save a copy of core mask */
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            pCoreMaskArray = GetCoreMaskArray(pConfig, (PmcPmuType)type);
+
+            if (NULL != pCoreMaskArray)
+            {
+                memcpy(pClientCtx->m_pPmcCoreMaskArray[type],
+                       pCoreMaskArray,
+                       PMC_CORE_MASK_ARRAY_SIZE * sizeof(uint64_t));
+            }
+            else
+            {
+                DRVPRINTERROR("Error: Failed to get GetCoreMaskArray for PMU type %d\n", type);
+                retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_NULL_COREMASKARRAY;
+            }
+        }
+
+        if (!retVal)
+        {
+            /* Set default mux interval if not provided */
+            pClientCtx->m_muxInterval = (pConfig->m_muxInterval) ?
+                                        pConfig->m_muxInterval : MUX_INTERVAL_DEFAULT;
+
+            /* Save log interval, set to default if not provided */
+            pClientCtx->m_logInterval = (pConfig->m_logInterval) ?
+                                        pConfig->m_logInterval : LOG_INTERVAL_DEFAULT;
+
+            memset(pClientCtx->m_umcMaskArray, 0, PMC_MAX_SOCKET_COUNT * sizeof(uint32));
+
+        }
+    }
+
+    if (!retVal)
+    {
+        /* Save umc mask provided by the user */
+        memcpy(pClientCtx->m_umcMaskArray, pConfig->m_umcMask, PMC_MAX_SOCKET_COUNT * sizeof(uint32_t));
+
+        /* umcMaskArraySize is number of bits set in umcPmcCoreMask*/
+        pClientCtx->m_umcMaskArraySize = GetCoreMaskArrayCount(pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_UMC]);
+
+        memcpy(pClientCtx->m_firstCore, pTargetSystemInfo->m_zen.m_firstCore, PMC_MAX_SOCKET_COUNT * sizeof(uint32_t));
+
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            /* Save data buffer size and threshold */
+            pClientCtx->m_dataBufferSize[type] = pConfig->m_dataBufferSize[type];
+            pClientCtx->m_dataBufferThreshold[type] = pConfig->m_dataBufferThreshold[type];
+            pClientCtx->m_bufferMaxFillCount[type] = GetCoreMaskArrayCount(pClientCtx->m_pPmcCoreMaskArray[type]);
+        }
+
+        /* TODO: Should we do this on client registration for each client
+         * instead of doing it here? */
+        retVal = AllocateCoreContext(pClientCtx);
+
+        if (retVal)
+        {
+            DRVPRINTERROR("Error: AllocateCoreContext\n");
+        }
+    }
+
+    if (!retVal)
+    {
+        numOfConfigGroups = pConfig->m_groupCount;
+    }
+
+#if defined(__linux__)
+
+    if (!retVal)
+    {
+        // Get availability mask for each core with valid core mask
+        for (coreId = 0; coreId < numOfCores; coreId++)
+        {
+            if (!cpu_online(coreId))
+            {
+                continue;
+            }
+
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+            pCoreCtx->m_resetPmc = pConfig->m_resetPmc;
+
+            if (NULL != pCoreCtx)
+            {
+                ExecuteOnCore(coreId, (void*)GetPmcAvailabilityMask, (void*)pCoreCtx);
+            }
+            else
+            {
+                DRVPRINTERROR("Error: NULL == pCoreCtx cpu id (%d)\n", coreId);
+                retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_NULL_CORECONTEXT;
+            }
+        }
+    }
+
+#endif
+
+    /* Process each config group */
+    for (grpIdx = 0; grpIdx < numOfConfigGroups && !retVal; grpIdx++)
+    {
+        uint32_t maskIdx = 0;
+
+        pGroupConfig = (CountModeGroupConfig*)pConfig->m_pConfigArray + grpIdx;
+
+        if (NULL == pGroupConfig)
+        {
+            DRVPRINTERROR("Error: NULL == pGroupConfig group id (%d)\n", grpIdx);
+            retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_NULL_GRPCFG;
+            break;
+        }
+
+        groupType = (GroupType)pGroupConfig->m_configHeader.m_header.m_groupType;
+        groupConfigCnt = pGroupConfig->m_configHeader.m_header.m_groupConfigCount;
+        groupAttrs = pGroupConfig->m_configHeader.m_header.m_groupAttributes;
+        groupId = pGroupConfig->m_configHeader.m_header.m_groupId;
+
+        if (groupAttrs & GROUP_ATTR_IRPERF && !enableIRPerf)
+        {
+            enableIRPerf = IsIrPerfAvailable();
+        }
+
+        type = GetPmcType(groupType);
+
+        /* End of valid configurations */
+        if (groupType == GROUP_TYPE_INVALID)
+        {
+            DRVPRINTERROR("Error: Invalid group type (%d)\n", groupType);
+            break;
+        }
+
+        pCoreMaskArray = pClientCtx->m_pPmcCoreMaskArray[type];
+        pPmcConfigArray = GetPmcConfigArray(pGroupConfig);
+
+        if ((NULL != pCoreMaskArray) && (NULL != pPmcConfigArray))
+        {
+            maxPmcCnt = (uint16_t)GetMaxPmcCount((PmcPmuType)type, &debugPmcCnt);
+
+            pClientCtx->m_pmcConfigGroupCnt[type]++;
+
+            for (maskIdx = 0, coreId = 0; maskIdx < PMC_CORE_MASK_ARRAY_SIZE && !retVal; maskIdx++)
+            {
+                uint32_t bit = 0;
+                coreMask = pCoreMaskArray[maskIdx];
+
+                for (bit = 0; bit < PMC_CORE_MASK_BIT_WIDTH && !retVal; bit++, coreId++)
+                {
+                    pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+                    if (coreMask & (1ULL << bit))
+                    {
+                        if (PMC_PMU_UMC == type)
+                        {
+                            socketId = GetSocketIdForCore(coreId);
+
+                            /* Throw an error if socket Id exceeds array size
+                             * Will happen in case of incorrect topology deduction */
+                            if (socketId < pClientCtx->m_umcMaskArraySize)
+                            {
+                                umcCount = POPCNT(pClientCtx->m_umcMaskArray[socketId]);
+                            }
+                            else
+                            {
+                                DRVPRINTERROR("Error: pClientCtx->m_umcMaskArraySize(%d) <= socketId(%d)\n", pClientCtx->m_umcMaskArraySize, socketId);
+                                retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_INVALIDSOCKETID;
+                            }
+                        }
+
+                        if (!retVal)
+                        {
+                            pPmcConfigGroup = NULL;
+
+                            retVal = AllocatePmcConfigGroup(&pPmcConfigGroup,
+                                                            pPmcConfigArray,
+                                                            groupConfigCnt,
+                                                            maxPmcCnt,
+                                                            groupAttrs,
+                                                            groupId,
+                                                            pCoreCtx->m_availabilityMask[type],
+                                                            umcCount,
+                                                            (PmcPmuType)type);
+                        }
+
+                        if (retVal || (NULL == pPmcConfigGroup))
+                        {
+                            if (NULL == pPmcConfigGroup)
+                            {
+                                DRVPRINTERROR("Error: AllocatePmcConfigGroup retVal (0x%x)\n", retVal);
+                            }
+                            break;
+                        }
+
+                        retVal = AddPmcConfigGroup(pCoreCtx,
+                                                   (PmcPmuType)type,
+                                                   pPmcConfigGroup);
+
+                        if (retVal)
+                        {
+                            DRVPRINTERROR("Error: AddPmcConfigGroup, retVal (0x%x)\n", retVal);
+                        }
+
+                        /* TODO: Free already allocated memory and
+                         * return appropriate error code */
+
+                        /* TODO: Should we load Pmc Config once we have added it?
+                         * To avoid waiting for all Pmc configs to be added before we start
+                         * monitoring. But we need timer to be configured in order to
+                         * collect sample data. Time configuration requires sampling
+                         * factor determination which in turn requires a config group cnt
+                         * for each pmc type. Circular dependency. Can be avoided if
+                         * total pmc config group count is provided by backend */
+                    }
+                }
+            }
+
+            pClientCtx->m_totalPmcAttrCnt[type] += (uint16_t)GetGroupAttrCount((uint8_t)groupAttrs);
+            pClientCtx->m_totalPmcConfigCnt[type] += groupConfigCnt;
+        }
+        else
+        {
+            DRVPRINTERROR("Error: Invalid pointer pCoreMaskArray or pPmcConfigArray");
+            retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_ALLOCPMCCFGGRP_NULL_COREMASK_OR_PMCCFG_ARRAY;
+        }
+    }
+
+    if (!retVal)
+    {
+        if (enableIRPerf)
+        {
+            if (!EnableIRPerf(pTargetSystemInfo))
+            {
+                DRVPRINTERROR("Error: EnableIRPerf");
+                retVal = ERROR_PMC_PROCESSCOUNTMODEPROFILECFG_ENABLEIRPERF;
+            }
+        }
+
+        /* Calculate size of sample record
+         * Note: Must be called after adding Pmc Configurations */
+        SetSampleRecordSize(pClientCtx);
+
+        retVal = AllocateDataBufferContext(pClientCtx);
+    }
+
+#if defined(__linux__)
+
+    if (!retVal)
+    {
+        /* File descriptors to be returned as output */
+        /* TODO: This is Linux specific.*/
+        retVal = CreatePmcFileDescriptors(pConfig, pClientCtx);
+    }
+
+#endif
+
+    if (!retVal)
+    {
+        /* Note: Requires pmc config group count for each pmc type and
+         * hence can only be set once config groups have been added. */
+        SetTimerInterval(pClientCtx);
+
+        /* Setup timer */
+        retVal = PmcSetupTimer(pClientCtx);
+
+        /* TODO: Load first PMC config groups for all cores?
+         * or shoud it be done before starting the timer */
+         g_pPmcClientContext->m_clientState = PMC_CLIENT_STATE_CONFIGURED;
+    }
+
+    // Clean the memory if Timer setup failed
+    if (retVal)
+    {
+        FreeDataBufferContext(pClientCtx);
+        FreePmcConfigGroup(pClientCtx);
+        FreeCoreContext(pClientCtx);
+        FreeUmcMaskArray(pClientCtx);
+        FreeCoreMaskArray(pClientCtx);
+    }
+
+    DRVPRINT("retVal(0x%x)", retVal);
+
+    return retVal;
+}
+
+int AllocateClientContext(uint32_t clientId)
+{
+
+    int type = PMC_PMU_INVALID;
+    int retVal = 0;
+    ClientContext* pClientContext = NULL;
+
+    DRVPRINT("clientId(%lu)", (unsigned long int)clientId);
+
+    if (NULL != g_pPmcClientContext)
+    {
+        DRVPRINTERROR("Error: Previous session is still in progress or not cleanedup properly");
+        retVal = ERROR_PMC_ALLOCCLIENTCONTEXT_NULL;
+    }
+    else
+    {
+        pClientContext = (ClientContext*)AllocateMemory((sizeof(ClientContext)));
+    }
+
+    if (!retVal && (pClientContext != NULL))
+    {
+        pClientContext->m_clientId = clientId;
+        pClientContext->m_clientState = PMC_CLIENT_STATE_UNKNOWN;
+
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX; type++)
+        {
+            pClientContext->m_pPmcCoreMaskArray[type] = NULL;
+            pClientContext->m_sampleRecordSize[type] = 0;
+            pClientContext->m_totalPmcConfigCnt[type] = 0;
+            pClientContext->m_totalPmcAttrCnt[type] = 0;
+            pClientContext->m_pmcConfigGroupCnt[type] = 0;
+            pClientContext->m_samplingCount[type] = 0;
+            pClientContext->m_dataBufferSize[type] = 0;
+            pClientContext->m_dataBufferThreshold[type] = 0;
+            pClientContext->m_bufferFillCount[type] = 0;
+            pClientContext->m_bufferMaxFillCount[type] = 0;
+        }
+
+        pClientContext->m_muxInterval = 0;
+        pClientContext->m_logInterval = 0;
+        pClientContext->m_timerInterval = 0;
+        pClientContext->m_pCoreContext = NULL;
+        pClientContext->m_multiplex = false;
+        pClientContext->m_umcMaskArraySize = 0;
+        pClientContext->m_clientState = PMC_CLIENT_STATE_INIT;
+
+#if defined(_WIN32)
+        pClientContext->m_pDevExt = NULL;
+#endif
+        /* Save reference to client context */
+        if (NULL != pClientContext)
+        {
+            g_pPmcClientContext = pClientContext;
+            retVal = 0;
+        }
+        else
+        {
+            DRVPRINTERROR("Error: NULL == pClientContext");
+            retVal = ERROR_PMC_ALLOCCLIENTCONTEXT_NULL;
+        }
+    }
+
+    DRVPRINT("pClientCtx(%p) retVal(%d)", g_pPmcClientContext, retVal);
+
+    return retVal;
+}
+
+void FreeClientContext(uint32_t clientId)
+{
+    DRVPRINT("clientId(%lu)", (unsigned long int)clientId);
+
+    if (g_pPmcClientContext != NULL)
+    {
+        if (g_pPmcClientContext->m_clientId == clientId)
+        {
+            FreeMemory(g_pPmcClientContext);
+            g_pPmcClientContext = NULL;
+        }
+    }
+
+    DRVPRINT("pClientCtx(%p)", g_pPmcClientContext);
+}
+
+#if defined (_WIN32)
+typedef struct
+{
+    PmcPmuType m_type;
+    PmcConfigGroup* m_pConfigGroup;
+    uint32_t m_umcCount;
+    KEVENT m_event;
+} DpcLoadConfig;
+
+void _LoadPmcConfig(void* pContext)
+{
+    DpcLoadConfig* pCtx = (DpcLoadConfig*)pContext;
+
+    if (pCtx != NULL)
+    {
+        LoadPmcConfig(pCtx->m_pConfigGroup, pCtx->m_type, pCtx->m_umcCount, false);
+
+        KeSetEvent(&pCtx->m_event, 1, FALSE);
+    }
+}
+#endif
+
+/* TODO: This is linux specific since the type of
+ * this function will be same as smp_call_func_t */
+static void _PmcStartProfiler(void* pInfo)
+{
+    CoreContext* pCoreCtx = (CoreContext*)pInfo;
+    int type = PMC_PMU_INVALID;
+    int retVal = 0;
+#if defined (_WIN32)
+    DpcLoadConfig dpcCtx;
+
+    KeInitializeEvent(&dpcCtx.m_event, SynchronizationEvent, false);
+#endif
+
+    DRVPRINT("pCoreCtx(%p)", pCoreCtx);
+
+    if (pCoreCtx != NULL)
+    {
+        // Load PMC config core
+        for (type = PMC_PMU_CORE; type < PMC_PMU_MAX && !retVal; type++)
+        {
+            // If there is a valid PMC config group for this type
+            if (pCoreCtx->m_pPmcConfigGroupArray[type] != NULL)
+            {
+#if defined (_WIN32)
+                dpcCtx.m_pConfigGroup = pCoreCtx->m_pPmcConfigGroupArray[type];
+                dpcCtx.m_type = (PmcPmuType)type;
+                dpcCtx.m_umcCount = pCoreCtx->m_umcCount;
+
+                DeferedCoreExecution(pCoreCtx->m_coreId, (void*)_LoadPmcConfig, (void*)&dpcCtx);
+#else
+                retVal = LoadPmcConfig(pCoreCtx->m_pPmcConfigGroupArray[type],
+                                       (PmcPmuType)type, pCoreCtx->m_umcCount, false);
+
+#endif
+                /* Capture time enabled */
+                pCoreCtx->m_timeEnabledBegin[type] = pCoreCtx->m_pPmcConfigGroupArray[type]->m_loadTime;
+
+                if (retVal)
+                {
+                    DRVPRINTERROR("Error: loading pmc config group. pPmcConfigGroup(%p) type(%d)",
+                             pCoreCtx->m_pPmcConfigGroupArray[type], type);
+                }
+
+#if defined (_WIN32)
+                KeWaitForSingleObject((void*)&dpcCtx.m_event, Executive, KernelMode, false, NULL);
+#endif
+            }
+        }
+
+        // Start timer for this core
+        // Note: On windows this registers a DPC
+        // TODO: This should return based on failure and success
+        PmcStartTimerOnCore(pCoreCtx);
+    }
+}
+
+static void SetEffFreqMsr(void)
+{
+    bool isCefROSupported = IsROCefAvailable();
+    if (isCefROSupported)
+    {
+        g_PmcAperfMsr = PMC_RO_APERF_MSR;
+        g_PmcMperfMsr = PMC_RO_MPERF_MSR;
+    }
+    else
+    {
+        g_PmcAperfMsr = PMC_APERF_MSR;
+        g_PmcMperfMsr = PMC_MPERF_MSR;
+    }
+}
+
+// This function needs to block until timer starts
+/* Load configurations for all cores and start timer */
+int PmcStartProfiler()
+{
+    int retVal = STATUS_SUCCESS;
+    int coreId = 0;
+    int numOfCores = GetCoreCount();
+    CoreContext* pCoreCtx = NULL;
+    DRVPRINT("pClientCtx(%p)", g_pPmcClientContext);
+    SetEffFreqMsr();
+
+    /* TODO: Check profiler state to confirm
+     * if profiler has already been configured. */
+    if ((g_pPmcClientContext != NULL) && (g_pPmcClientContext->m_clientState != PMC_CLIENT_STATE_CONFIGURED))
+    {
+        DRVPRINTERROR("Error: g_pPmcClientContext == NULL, or state not in PMC_CLIENT_STATE_CONFIGURED");
+        retVal = ERROR_PMC_INVALID_STATE;
+    }
+
+    // HalAllocateHardwareCounters fails when number of cores are more than 256
+    // To avoid this issue this is a workaround to by pass HalAllocateHardwareCounters
+    // TODO: Need to check with MS
+    if (numOfCores < 256)
+    {
+        if (!g_halPmcAcquired)
+        {
+            g_halPmcAcquired = AcquirePCMCountersLock();
+
+            if (!g_halPmcAcquired)
+            {
+                DRVPRINTERROR("Error: Power HAL Arbitration failed!");
+                retVal = STATUS_ACCESS_DENIED;
+            }
+            else
+            {
+                DRVPRINTERROR("INFO: Power HAL Arbitration success!");
+            }
+        }
+    }
+
+    if (retVal == STATUS_SUCCESS)
+    {
+        for (coreId = 0; coreId < numOfCores && !retVal; coreId++)
+        {
+            if (g_pPmcClientContext->m_pCoreContext != NULL)
+            {
+                pCoreCtx = &g_pPmcClientContext->m_pCoreContext[coreId];
+
+                /* If the core has atleast one valid PMC config group */
+                if (pCoreCtx != NULL && pCoreCtx->m_totalPmcConfigGroupCnt)
+                {
+#if defined (__linux__)
+                    retVal = ExecuteOnCore(coreId, (void*)_PmcStartProfiler,
+                                           (void*)pCoreCtx);
+#endif
+
+#if defined (_WIN32)
+                    _PmcStartProfiler(pCoreCtx);
+#endif
+                }
+            }
+        }
+
+        if (!retVal)
+        {
+            g_pPmcClientContext->m_clientState = PMC_CLIENT_STATE_RUNNING;
+        }
+    }
+
+    DRVPRINT("retval(%d)", retVal);
+
+    return retVal;
+}
+
+/* TODO: This is linux specific since the type of
+ * this function will be same as smp_call_func_t */
+static void _PmcStopProfiler(void* pInfo)
+{
+    CoreContext* pCoreCtx = (CoreContext*)pInfo;
+
+    if (pCoreCtx != NULL)
+    {
+        /* Stop Timer */
+        PmcStopTimerOnCore(pCoreCtx);
+
+        if (g_halPmcAcquired)
+        {
+            // Free the HAL Arbitration
+            ReleasePCMCountersLock();
+            g_halPmcAcquired = false;
+        }
+    }
+}
+
+int PmcStopProfiler()
+{
+    int retVal = 0;
+    int coreId = 0;
+    int numOfCores = GetCoreCount();
+    CoreContext* pCoreCtx = NULL;
+    ClientContext* pClientCtx = g_pPmcClientContext;
+
+    DRVPRINT("PmcStopProfiler pClientCtx(%p) g_pPmcClientContext(%p)", pClientCtx, g_pPmcClientContext);
+
+    if ((pClientCtx == NULL)
+        || (pClientCtx->m_pCoreContext == NULL)
+        || (g_pPmcClientContext == NULL)
+        || (g_pPmcClientContext->m_clientState != PMC_CLIENT_STATE_RUNNING))
+    {
+        DRVPRINTERROR("Error: pClientCtx, g_pPmcClientContext, g_pPmcClientContext is NULL, or state not in PMC_CLIENT_STATE_RUNNING");
+        retVal = ERROR_PMC_INVALID_STATE;
+    }
+
+    if (!retVal && (g_pPmcClientContext->m_clientState == PMC_CLIENT_STATE_RUNNING))
+    {
+        DRVPRINTERROR("PmcStopProfiler stop initiated\n");
+        g_pPmcClientContext->m_clientState = PMC_CLIENT_STATE_STOP_INITIATED;
+    }
+
+    // Stop timers on all cores
+    for (coreId = 0; coreId < numOfCores && !retVal; coreId++)
+    {
+        pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+        if (pCoreCtx != NULL && pCoreCtx->m_totalPmcConfigGroupCnt)
+        {
+#if defined(__linux__)
+            int success = 0;
+            DRVPRINTERROR("Info: initiate stop for cpu (%d)\n", coreId);
+            success = ExecuteOnCore(coreId, (void*)_PmcStopProfiler,
+                                   (void*)pCoreCtx);
+            if (success)
+            {
+                DRVPRINTERROR("Info: complete stop for cpu (%d)\n", coreId);
+            }
+#endif
+
+#if defined (_WIN32)
+            // Note: Ideally, we should wait for the timers to stop
+            // on windows but unfortunately Pcore doesn't have
+            // a blocking version of PcoreRemoveConfiguration
+            PmcStopTimerOnCore(pCoreCtx);
+#endif
+        }
+    }
+
+    /* Flush data buffers */
+    for (coreId = 0; coreId < numOfCores && !retVal; coreId++)
+    {
+        pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+        // Skip if there are no valid configs for this core
+        if (pCoreCtx == NULL || pCoreCtx->m_totalPmcConfigGroupCnt == 0)
+        {
+            continue;
+        }
+
+#if defined (_WIN32)
+        KeInitializeEvent(&pCoreCtx->m_event, SynchronizationEvent, false);
+#endif
+        /* Flush data buffer */
+        ExecuteOnCore(coreId, (void*)PmcFlushDataBuffer, (void*)pCoreCtx);
+
+#if defined (_WIN32)
+        KeWaitForSingleObject((void*)&pCoreCtx->m_event, Executive, KernelMode, false, NULL);
+#endif
+    }
+
+    /* Clear config on occupied cores */
+    for (coreId = 0; coreId < numOfCores && !retVal; coreId++)
+    {
+        pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+        // Skip if there are no valid configs for this core
+        if (pCoreCtx == NULL || pCoreCtx->m_totalPmcConfigGroupCnt == 0)
+        {
+            continue;
+        }
+
+        ExecuteOnCore(coreId, (void*)ClearPmcConfig, (void*)pCoreCtx);
+    }
+
+    if (!retVal)
+    {
+        PmcDestroyTimer(pClientCtx);
+
+        if (g_pPmcClientContext->m_clientState == PMC_CLIENT_STATE_STOP_INITIATED)
+        {
+            DRVPRINTERROR("PmcStopProfiler stopped\n");
+            g_pPmcClientContext->m_clientState = PMC_CLIENT_STATE_STOPPED;
+        }
+    }
+
+    DRVPRINTERROR("retval(%d)", retVal);
+
+    return retVal;
+}
+
+void PmcClearProfiler()
+{
+    if (NULL != g_pPmcClientContext)
+    {
+        /* Free Configurations */
+        FreePmcConfigGroup(g_pPmcClientContext);
+        FreeCoreMaskArray(g_pPmcClientContext);
+        FreeUmcMaskArray(g_pPmcClientContext);
+        FreeDataBufferContext(g_pPmcClientContext);
+        FreeCoreContext(g_pPmcClientContext);
+    }
+
+    if (g_halPmcAcquired)
+    {
+        // Free the HAL Arbitration
+        ReleasePCMCountersLock();
+        g_halPmcAcquired = false;
+    }
+}
+
+/* TODO: Disable MSR configs and Stop timer
+ * Flush data buffer? */
+int PmcPauseProfiler()
+{
+    /* TODO: Add implementation */
+    return 0;
+}
+
+/* TODO: Enable MSR configs and stop timer */
+int PmcResumeProfiler()
+{
+    /* TODO: Add implementation */
+    return 0;
+}
diff --git a/drivers/powerprofiler/src/PmcTimerConfig.c b/drivers/powerprofiler/src/PmcTimerConfig.c
new file mode 100644
index 000000000000..b4601c9a58c8
--- /dev/null
+++ b/drivers/powerprofiler/src/PmcTimerConfig.c
@@ -0,0 +1,342 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcTimerConfig.c
+///
+//==================================================================================
+
+#include <PmcOsTypes.h>
+#include <PmcTimerConfig.h>
+#include <PwrOsPrimitives.h>
+#include <PmcInterface.h>
+#include <PmcProcessConfig.h>
+#include <PwrCommonDataTypes.h>
+
+#include <linux/smp.h>
+#include <linux/slab.h>
+
+extern ClientContext* g_pPmcClientContext;
+
+static enum hrtimer_restart PmcTimerCallback(struct hrtimer* pHrTimer)
+{
+    enum hrtimer_restart ret = HRTIMER_NORESTART;
+    int err = 0;
+    int coreId = 0;
+    CoreContext* pCoreCtx = NULL;
+    PmcTimerConfig* pTimerConfig = NULL;
+
+    DRVPRINT("pHrTimer(%p) g_pPmcClientContext(%p)", pHrTimer, g_pPmcClientContext);
+
+    /* Note: For multiple clients we can iterate through list of clients here */
+    if (g_pPmcClientContext == NULL)
+    {
+        DRVPRINTERROR("Error: g_pPmcClientContext == NULL");
+        err = ERROR_PMC_TIMERCFG_NULL_CLIENTCTX;
+    }
+
+    if (PMC_CLIENT_STATE_RUNNING != g_pPmcClientContext->m_clientState)
+    {
+        coreId = GetCoreId();
+        DRVPRINTERROR("Warning: Not in running state, current state(%d) coreId(%d)\n", g_pPmcClientContext->m_clientState, coreId);
+        return HRTIMER_NORESTART;
+    }
+
+    if (!err)
+    {
+        /* Note: We can also use multiple container_ofs
+         * to get clientContext reference and avoid using a
+         * global reference here. */
+        coreId = GetCoreId();
+        pCoreCtx = &g_pPmcClientContext->m_pCoreContext[coreId];
+
+        if (pCoreCtx == NULL)
+        {
+            DRVPRINTERROR("pCoreCtx == NULL");
+            err = EINVAL;
+        }
+
+        DRVPRINT("coreId(%d)", coreId);
+    }
+
+    if (!err)
+    {
+        err = PmcCallBack(g_pPmcClientContext, pCoreCtx);
+    }
+
+    if (!err)
+    {
+        pTimerConfig = pCoreCtx->m_pTimerConfig;
+
+        hrtimer_forward_now(pHrTimer, pTimerConfig->m_time);
+        ret = HRTIMER_RESTART;
+    }
+
+    DRVPRINT("ret(%d) err(%d)", ret, err);
+
+    return ret;
+}
+
+static void PmcInitTimer(void* pInfo)
+{
+    PmcTimerConfig* pTimerConfig = (PmcTimerConfig*)pInfo;
+
+    DRVPRINT("pTimerConfig(%p)", pTimerConfig);
+
+    hrtimer_init(&pTimerConfig->m_hrTimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
+}
+
+int PmcSetupTimer(ClientContext* pClientCtx)
+{
+    int retVal = 0;
+    int i = 0;
+    int j = 0;
+    int coreId = 0;
+    uint64_t corePmcCoreMask = 0;
+    uint64_t l3PmcCoreMask = 0;
+    uint64_t dfPmcCoreMask = 0;
+    uint64_t umcPmcCoreMask = 0;
+
+    PmcTimerConfig* pTimerConfig = NULL;
+    uint64_t interval = pClientCtx->m_timerInterval;
+
+    DRVPRINT("pClientCtx(%p)", pClientCtx);
+
+    if (pClientCtx == NULL)
+    {
+        retVal = EINVAL;
+    }
+
+    /* ToDo: Add a check here to limit the mux interval */
+    /* ToDo: Instead of checking core masks for all types
+     * check if there is a valid config? */
+    for (i = 0; i < PMC_CORE_MASK_ARRAY_SIZE && !retVal; i++)
+    {
+        corePmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_CORE][i];
+        l3PmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_L3][i];
+        dfPmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_DF][i];
+        umcPmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_UMC][i];
+
+
+        for (j = 0; j < PMC_CORE_MASK_BIT_WIDTH && !retVal; j++, coreId++)
+        {
+            if  ((corePmcCoreMask & 1ULL << j)
+                || (l3PmcCoreMask & 1ULL << j)
+                || (dfPmcCoreMask & 1ULL << j)
+                || (umcPmcCoreMask & 1ULL << j))
+            {
+                pTimerConfig = (PmcTimerConfig*)kzalloc(sizeof(PmcTimerConfig), GFP_KERNEL);
+
+                if (pTimerConfig == NULL)
+                {
+                    retVal = -ENOMEM;
+                }
+
+                pClientCtx->m_pCoreContext[coreId].m_pTimerConfig = pTimerConfig;
+
+                retVal = smp_call_function_single(coreId, PmcInitTimer,
+                                                  pTimerConfig, true);
+
+                if (!retVal)
+                {
+                    /* Interval in ms */
+                    pTimerConfig->m_time = ktime_set(interval / 1000, interval * 1000000);
+                    pTimerConfig->m_hrTimer.function = PmcTimerCallback;
+
+                    DRVPRINT("retVal(%d) m_time(%lld)", retVal, (long long int) pTimerConfig->m_time);
+                }
+
+                DRVPRINT("coreId(%d) pTimerConfig(%p)", coreId, pTimerConfig);
+            }
+        }
+    }
+
+    if (retVal)
+    {
+        PmcDestroyTimer(pClientCtx);
+    }
+
+    DRVPRINT("retVal(%d)", retVal);
+
+    return retVal;
+}
+
+void PmcDestroyTimer(ClientContext* pClientCtx)
+{
+    int i = 0;
+    CoreContext* pCoreCtx = NULL;
+    int numOfCores = GetCoreCount();
+
+    for (i = 0; i < numOfCores; i++)
+    {
+        pCoreCtx = &pClientCtx->m_pCoreContext[i];
+
+        if (pCoreCtx != NULL)
+        {
+            if (pCoreCtx->m_pTimerConfig != NULL)
+            {
+                kfree(pCoreCtx->m_pTimerConfig);
+            }
+        }
+    }
+}
+
+void PmcStartTimerOnCore(CoreContext* pCoreCtx)
+{
+    if (pCoreCtx != NULL)
+    {
+        PmcTimerConfig* pTimerConfig = pCoreCtx->m_pTimerConfig;
+
+        DRVPRINT("pTimerConfig(%p)", pTimerConfig);
+
+        if (pTimerConfig != NULL)
+        {
+            hrtimer_start(&pTimerConfig->m_hrTimer,
+                          pTimerConfig->m_time,
+                          HRTIMER_MODE_REL_PINNED);
+        }
+    }
+}
+
+static void _PmcStartTimer(void* pInfo)
+{
+    if (pInfo != NULL)
+    {
+        CoreContext* pCoreCtx = (CoreContext*)pInfo;
+
+        PmcTimerConfig* pTimerConfig = pCoreCtx->m_pTimerConfig;
+
+        if (pTimerConfig != NULL)
+        {
+            hrtimer_start(&pTimerConfig->m_hrTimer,
+                          pTimerConfig->m_time,
+                          HRTIMER_MODE_REL_PINNED);
+        }
+    }
+}
+
+
+/* ToDo: Remove this if not being used anywhere */
+int PmcStartTimer(ClientContext* pClientCtx)
+{
+    int retVal = 0;
+    int i = 0;
+    int j = 0;
+    uint64_t corePmcCoreMask = 0;
+    uint64_t l3PmcCoreMask = 0;
+    uint64_t dfPmcCoreMask = 0;
+    uint32_t coreId = 0;
+    CoreContext* pCoreCtx = NULL;
+
+    for (i = 0; i < PMC_CORE_MASK_ARRAY_SIZE; i++)
+    {
+        corePmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_CORE][i];
+        l3PmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_L3][i];
+        dfPmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_DF][i];
+
+        for (j = 0; j < PMC_CORE_MASK_BIT_WIDTH; j++, coreId++)
+        {
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+            if ((corePmcCoreMask & 1 << j) ||
+                (l3PmcCoreMask & 1 << j)   ||
+                (dfPmcCoreMask & 1 << j))
+            {
+                retVal = smp_call_function_single(coreId,
+                                                  (smp_call_func_t)_PmcStartTimer,
+                                                  (void*)pCoreCtx, true);
+            }
+        }
+    }
+
+    if (retVal != HRTIMER_RESTART)
+    {
+        // ToDo: Return appropriate error code and message
+        // Failed to start timer
+    }
+
+    return retVal;
+}
+
+void PmcStopTimerOnCore(CoreContext* pCoreCtx)
+{
+    int retVal = 0;
+
+    if (pCoreCtx != NULL)
+    {
+        PmcTimerConfig* pTimerConfig = pCoreCtx->m_pTimerConfig;
+
+        if (pTimerConfig != NULL)
+        {
+            retVal = hrtimer_cancel(&pTimerConfig->m_hrTimer);
+
+            if (!retVal)
+            {
+                /* ToDo: Timer was already cancelled */
+            }
+        }
+    }
+}
+
+static void _PmcStopTimer(void* pInfo)
+{
+    int retVal = 0;
+
+    if (pInfo != NULL)
+    {
+        CoreContext* pCoreCtx = (CoreContext*)pInfo;
+
+        PmcTimerConfig* pTimerConfig = pCoreCtx->m_pTimerConfig;
+
+        if (pTimerConfig != NULL)
+        {
+            retVal = hrtimer_cancel(&pTimerConfig->m_hrTimer);
+
+            if (!retVal)
+            {
+                /* ToDo: Timer was already cancelled */
+            }
+        }
+    }
+}
+
+/* ToDo: Remove if unused */
+int PmcStopTimer(ClientContext* pClientCtx)
+{
+    int retVal = 0;
+    int i = 0;
+    int j = 0;
+    uint64_t corePmcCoreMask = 0;
+    uint64_t l3PmcCoreMask = 0;
+    uint64_t dfPmcCoreMask = 0;
+    uint32_t coreId = 0;
+    CoreContext* pCoreCtx = NULL;
+
+    if (pClientCtx == NULL)
+    {
+        retVal = EINVAL;
+    }
+
+    for (i = 0; i < PMC_CORE_MASK_ARRAY_SIZE && !retVal; i++)
+    {
+        corePmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_CORE][i];
+        l3PmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_L3][i];
+        dfPmcCoreMask = pClientCtx->m_pPmcCoreMaskArray[PMC_PMU_DF][i];
+
+        for (j = 0; j < PMC_CORE_MASK_BIT_WIDTH; j++, coreId++)
+        {
+            pCoreCtx = &pClientCtx->m_pCoreContext[coreId];
+
+            if ((corePmcCoreMask & 1 << j) ||
+                (l3PmcCoreMask & 1 << j)   ||
+                (dfPmcCoreMask & 1 << j))
+            {
+                retVal = smp_call_function_single(coreId,
+                                                  (smp_call_func_t)_PmcStopTimer,
+                                                  (void*)pCoreCtx, true);
+            }
+        }
+    }
+
+    return retVal;
+}
diff --git a/drivers/powerprofiler/src/PmcUtils.c b/drivers/powerprofiler/src/PmcUtils.c
new file mode 100644
index 000000000000..a5490b3eb512
--- /dev/null
+++ b/drivers/powerprofiler/src/PmcUtils.c
@@ -0,0 +1,97 @@
+//==================================================================================
+// Copyright (c) 2021 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PmcUtils.c
+///
+//==================================================================================
+
+#if !(__KERNEL__)
+    #include <stddef.h>
+#endif
+
+#include <PmcUtils.h>
+
+const char* GetPmcTypeString(PmcPmuType type)
+{
+    switch (type)
+    {
+        case PMC_PMU_CORE:
+            return "core";
+
+        case PMC_PMU_L3:
+            return "l3";
+
+        case PMC_PMU_DF:
+            return "df";
+
+        case PMC_PMU_UMC:
+            return "umc";
+
+        default:
+            return NULL;
+    }
+}
+
+uint64_t* GetCoreMaskArray(CountModeProfileConfig* pConfig, PmcPmuType type)
+{
+    switch (type)
+    {
+        case PMC_PMU_CORE:
+            return pConfig->m_corePmcCoreMaskArray;
+
+        case PMC_PMU_L3:
+            return pConfig->m_l3PmcCoreMaskArray;
+
+        case PMC_PMU_DF:
+            return pConfig->m_dfPmcCoreMaskArray;
+
+        case PMC_PMU_UMC:
+            return pConfig->m_umcPmcCoreMaskArray;
+
+        default:
+            return NULL;
+    }
+}
+
+uint64_t* GetPmcConfigArray(CountModeGroupConfig* pConfig)
+{
+    switch (pConfig->m_configHeader.m_header.m_groupType)
+    {
+        case GROUP_TYPE_CORE_PMC:
+            return  pConfig->m_cfgArray.m_corePmcConfigArray;
+
+        case GROUP_TYPE_L3_PMC:
+            return pConfig->m_cfgArray.m_l3PmcConfigArray;
+
+        case GROUP_TYPE_DF_PMC:
+            return  pConfig->m_cfgArray.m_dfPmcConfigArray;
+
+        case GROUP_TYPE_UMC_PMC:
+            return  pConfig->m_cfgArray.m_umcPmcConfigArray;
+
+        default:
+            return NULL;
+    }
+}
+
+PmcPmuType GetPmcType(GroupType groupType)
+{
+    switch (groupType)
+    {
+        case GROUP_TYPE_CORE_PMC:
+            return PMC_PMU_CORE;
+
+        case GROUP_TYPE_L3_PMC:
+            return PMC_PMU_L3;
+
+        case GROUP_TYPE_DF_PMC:
+            return PMC_PMU_DF;
+
+        case GROUP_TYPE_UMC_PMC:
+            return PMC_PMU_UMC;
+
+        default:
+            return PMC_PMU_INVALID;
+    }
+}
diff --git a/drivers/powerprofiler/src/PwrAccessPmcData.c b/drivers/powerprofiler/src/PwrAccessPmcData.c
new file mode 100644
index 000000000000..1f9f18d59844
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrAccessPmcData.c
@@ -0,0 +1,176 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrAccessPmcData.h
+///
+//==================================================================================
+#include <PwrOsPrimitives.h>
+#include <PwrDriverUtils.h>
+#include <PwrAccessPmcData.h>
+
+uint16 EventId[] = {0x76, 0xC0};
+
+#define LEGACY_COREPERFCONTROL_BASE 0xC0010000U
+#define LEGACY_COREPERFCONTROL_OFFSET 4U
+#define LEGACY_COREPMC_STRIDE 1U
+#define EXT_COREPERFCONTROL_BASE 0xC0010200U
+#define EXT_COREPERFCONTROL_OFFSET 1U
+#define EXT_COREPMC_STRIDE 2U
+// Attempt to get the HAL Arbitration for the counter availability
+static bool g_halAcquired = false;
+
+// ResetPMCCounters: Reset PCM counter values
+bool ResetPMCCounters(PmcCounters* pPmc)
+{
+    bool retVal = true;
+    uint32 index = 0;
+
+    for (index = 0; index < PMC_EVENT_MAX_CNT; index++)
+    {
+        // Initialize the counter value to 0;
+        WriteMSR(pPmc[index].m_dataMSR, 0ULL);
+    }
+
+    return retVal;
+}
+
+// EncodePMCEvent: Encode PMC event as per bit field
+uint32 EncodePMCEvent(uint16 eventSelect, uint8 unitMask)
+{
+    typedef union
+    {
+        struct
+        {
+            uint8 ucEventSelect : 8;
+            uint8 ucUnitMask : 8;
+            uint8 bitUsrEvents : 1;
+            uint8 bitOsEvents : 1;
+            uint8 bitEdgeEvents : 1;
+            uint8 bitPinControl : 1;
+            uint8 bitSampleEvents : 1;
+            uint8 bitReserved : 1;
+            uint8 bitEnabled : 1;
+            uint8 bitInvert : 1;
+            uint8 ucCounterMask : 8;
+            uint8 ucEventSelectHigh : 4;
+            uint8 Reserved1 : 4;
+            uint8 guestOnly : 1;
+            uint8 hostOnly : 1;
+            uint32 Reserved : 22;
+        };
+        uint32 perf_ctl;
+    } PERF_CTL;
+
+    PERF_CTL perfControl;
+    perfControl.perf_ctl = 0;
+
+    perfControl.ucEventSelect = eventSelect & 0xFFU;
+    perfControl.ucEventSelectHigh = (eventSelect >> 8) & 0xFU;
+    perfControl.ucUnitMask = (uint8)unitMask;
+    perfControl.bitOsEvents = 1U;
+    perfControl.bitUsrEvents = 1U;
+    perfControl.bitSampleEvents = 0U; // Count Mode
+    perfControl.bitEnabled = 1U; // Enable the Performance event counter
+
+    return perfControl.perf_ctl;
+}
+
+// InitializePMCCounters
+bool InitializePMCCounters(PmcCounters* pPmc)
+{
+    bool retVal = false;
+    uint32 msrBaseAddress = 0;
+    uint32 counterOffset = 0;
+    uint32 stride = 0;
+    uint32 index = 0;
+    bool isPmcAvailable = IsPMCCounterAvailable();
+
+    if (true == isPmcAvailable)
+    {
+        if (!g_halAcquired)
+        {
+            g_halAcquired = AcquirePCMCountersLock();
+
+            if (!g_halAcquired)
+            {
+                DRVPRINT("Power HAL Arbitration failed!");
+            }
+        }
+
+        if (g_halAcquired)
+        {
+            msrBaseAddress = isPmcAvailable ? EXT_COREPERFCONTROL_BASE : LEGACY_COREPERFCONTROL_BASE;
+            counterOffset = isPmcAvailable ? EXT_COREPERFCONTROL_OFFSET : LEGACY_COREPERFCONTROL_OFFSET;
+            stride = isPmcAvailable ? EXT_COREPMC_STRIDE : LEGACY_COREPMC_STRIDE;
+            index = 0;
+
+            for (index = 0; index < PMC_EVENT_MAX_CNT; index++)
+            {
+                // initialize the MSR for CPU Cycles Unhalted
+                // Initialize the MSR for Retired Instructions
+                pPmc[index].m_controlMSR = msrBaseAddress + (index * stride);
+                pPmc[index].m_dataMSR = msrBaseAddress + (index * stride) + counterOffset;
+                WriteMSR(pPmc[index].m_controlMSR, (uint64)EncodePMCEvent(EventId[index], 0));
+            }
+
+            // Reset PMC Counter values
+            ResetPMCCounters(pPmc);
+        }
+
+        retVal = true;
+    }
+
+    return retVal;
+}
+
+// ReadPmcCounterData: Read PMC counter values
+uint32 ReadPmcCounterData(PmcCounters* pPmc, uint64* pData)
+{
+    uint32 index = 0;
+    uint32 retSize = 0;
+
+    if (g_halAcquired)
+    {
+        for (index = 0; index < PMC_EVENT_MAX_CNT; index++)
+        {
+            pData[index] = ReadMSR(pPmc[index].m_dataMSR);
+        }
+    }
+    else
+    {
+        DRVPRINT("PMC counters are not accessible");
+
+        for (index = 0; index < PMC_EVENT_MAX_CNT; index++)
+        {
+            pData[index] = 1;
+        }
+    }
+
+    retSize = PMC_EVENT_MAX_CNT * sizeof(uint32);
+
+    return retSize;
+}
+
+// ResetPMCControl: Reset PMC counter control data
+bool ResetPMCControl(PmcCounters* pPmc)
+{
+    bool retVal = true;
+    uint32 index = 0;
+
+    if (g_halAcquired)
+    {
+        for (index = 0; index < PMC_EVENT_MAX_CNT; index++)
+        {
+            // Restet the control value to 0;
+            WriteMSR(pPmc[index].m_controlMSR, 0ULL);
+        }
+
+        // Free the HAL Arbitration
+        ReleasePCMCountersLock();
+        g_halAcquired = false;
+    }
+
+    return retVal;
+}
+
diff --git a/drivers/powerprofiler/src/PwrCommonConfig.c b/drivers/powerprofiler/src/PwrCommonConfig.c
new file mode 100644
index 000000000000..bc876edb6fd2
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrCommonConfig.c
@@ -0,0 +1,70 @@
+//==================================================================================
+// Copyright (c) 2016 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrCommonConfig.c
+///
+//==================================================================================
+#include <PwrOsPrimitives.h>
+#include <PwrProfInternal.h>
+#include <PwrCommonDataTypes.h>
+#include <PwrDriverUtils.h>
+#include <PwrAccessPmcData.h>
+#include <PwrCommonConfig.h>
+
+#define RETIRED_PERFORMACE_CNT 0xC00000E9
+#define ACTUAL_PERFORMANCE_FREQ_CLOCK_CNT 0xC00000E8
+
+// ConfigureSourceProfiling: Configuration for source code profiling
+void ConfigureSourceProfiling(CoreData* pCoreCfg)
+{
+    if (pCoreCfg
+        && pCoreCfg->m_pSysInfo
+        && !pCoreCfg->m_pSysInfo->m_isZen)
+    {
+        InitializePMCCounters(pCoreCfg->m_pmc);
+    }
+}
+
+// CloseSourceProfiling: Close the configuration for source code profiling
+void CloseSourceProfiling(CoreData* pCoreCfg)
+{
+    if (pCoreCfg
+        && pCoreCfg->m_pSysInfo
+        && !pCoreCfg->m_pSysInfo->m_isZen)
+    {
+        ResetPMCControl(pCoreCfg->m_pmc);
+    }
+}
+
+// PwrReadZpIpcData: Get MSR based Zepplin IPC data
+void PwrReadZpIpcData(uint64* pData)
+{
+    pData[PMC_EVENT_RETIRED_MICRO_OPS] = ReadMSR(RETIRED_PERFORMACE_CNT);
+    pData[PMC_EVENT_CPU_CYCLE_NOT_HALTED] = ReadMSR(ACTUAL_PERFORMANCE_FREQ_CLOCK_CNT);
+}
+
+// PwrGetIpcData: Get IPC data for process and module profiling
+void PwrGetIpcData(PmcCounters* pSrc, uint64* pData)
+{
+    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+    GetTargetSystemInfo(&pTargetInfo, false);
+
+    if (NULL != pTargetInfo)
+    {
+        if (pTargetInfo->m_isZen)
+        {
+            PwrReadZpIpcData(pData);
+        }
+        else
+        {
+            ReadPmcCounterData(pSrc, pData);
+            ResetPMCCounters(pSrc);
+        }
+    }
+    else
+    {
+        DRVPRINT("NULL != pTargetInfo");
+    }
+}
+
diff --git a/drivers/powerprofiler/src/PwrCommonHelper.c b/drivers/powerprofiler/src/PwrCommonHelper.c
new file mode 100644
index 000000000000..2bd2974b89e5
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrCommonHelper.c
@@ -0,0 +1,622 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrCommonHelper.c
+///
+//==================================================================================
+#include <PwrDriverTypedefs.h>
+#include <PwrOsPrimitives.h>
+#include <PwrDriverUtils.h>
+#include <PwrCommonDataTypes.h>
+#include <PmcInterface.h>
+
+#define RAPL_PWR_UNIT_ADDR 0xC0010299
+#define HWCR_REG_ADDR 0xC0010015
+#define HWCR_ENABLE_MASK 0x40000000
+#define HWCR_DISABLE_MASK 0xBFFFFFFF
+#define PWR_INVALID_PLATFORM 0xFFFFFFFF
+
+static bool g_perfEnable = false;
+static PTARGET_SYSTEM_INFO g_pSystemInfo = NULL;
+static TARGET_SYSTEM_INFO g_systemInfo;
+
+// PwrIsIGPUAvailable: Check if iGPU is available with B0D1F0x18 register
+// refer to the BKDG for this register. Available only in family 15 & 16
+bool PwrIsIGPUAvailable()
+{
+    uint32 data = ReadPCIDev(0x0U, 0x1U, 0x0U, 0x18U);
+    return (data < PWR_INVALID_PLATFORM ? true : false);
+}
+
+// PwrEnablePerf: Enable perf bit
+void PwrEnablePerf(bool enable)
+{
+    if (g_systemInfo.m_isZen && IsIrPerfAvailable())
+    {
+        uint64 data;
+        data = ReadMSR(HWCR_REG_ADDR);
+
+        if (true == enable)
+        {
+            if (!(data & HWCR_ENABLE_MASK))
+            {
+                data |= HWCR_ENABLE_MASK;
+                WriteMSR(HWCR_REG_ADDR, data);
+                g_perfEnable = true;
+            }
+        }
+        else
+        {
+            if (g_perfEnable)
+            {
+                data = data & HWCR_DISABLE_MASK;
+                WriteMSR(HWCR_REG_ADDR, data);
+                g_perfEnable = false;
+            }
+        }
+    }
+}
+
+// PwrGetSocketType: Get socket type
+static uint32 PwrGetSocketType(void)
+{
+    uint32 brandId = 0;
+
+    if (g_systemInfo.m_isZen)
+    {
+        uint32 ebxOffset = PwrReadCpuId(PWR_EBX_OFFSET, CPUID_FnBrandIdIdentifier);
+        brandId = ebxOffset >> 28;
+    }
+
+    return brandId;
+}
+
+// GetThreadsPerCore : Return number of threads per core
+static uint32 GetThreadsPerCore(void)
+{
+    uint32 threadsPerCore = 0;
+
+    if (g_systemInfo.m_isZen)
+    {
+        uint32 ebxOffset = PwrReadCpuId(PWR_EBX_OFFSET, CPUID_FnIdentifiers);
+        threadsPerCore = ((ebxOffset >> 8) & 0xFF) + 1;
+    }
+
+    DRVPRINT("Threads per core :%d\n", threadsPerCore);
+    return threadsPerCore;
+}
+
+// GetThreadsPerSocket : Get Threads per socket
+static uint32 GetThreadsPerSocket(void)
+{
+    uint32 threadsPerSocket = 0;
+
+#if defined(_WIN64)
+    // On Windows VM, CPUId returns incorrect socket count (1 socket for each core)
+    // Assume single socket for windows VMs
+
+    // TODO: For two socket system, below code is not correct. We cannot assume there will be only one socket
+    // This is work around for Bergamo. It may need in other platforms as well
+
+    const bool isFlag = (g_systemInfo.m_family == 0x19) &&
+                           (((g_systemInfo.m_model >> 4) == 0xa)
+                           || ((g_systemInfo.m_model >> 4) == 0x1));
+
+    if ((g_systemInfo.m_isGuest) && !isFlag)
+    {
+        return GetTargetCoreCount();
+    }
+
+#endif
+
+    if (g_systemInfo.m_isZen)
+    {
+        uint32 ecxOffset = PwrReadCpuId(PWR_ECX_OFFSET, CPUID_FnSizeID);
+
+        if (g_systemInfo.m_family < 0x1A)
+        {
+            ecxOffset = ecxOffset & 0xFF;
+        }
+
+        threadsPerSocket = (ecxOffset & 0xFFF) + 1;
+    }
+
+    DRVPRINT("Threads per socket :%d\n", threadsPerSocket);
+    return threadsPerSocket;
+}
+
+// GetNumberOfSockets : Get number of sockets per system
+static uint32 GetNumberOfSockets(void)
+{
+    uint32 socketCnt = 0;
+
+    if (g_systemInfo.m_isZen)
+    {
+        uint32 tgtThreadCount = GetCoreCount();
+        uint32 threadsPerSocket = GetThreadsPerSocket();
+        socketCnt = tgtThreadCount / threadsPerSocket;
+
+        if (socketCnt > PWR_MAX_SOCKET_COUNT)
+        {
+            socketCnt = PWR_MAX_SOCKET_COUNT;
+        }
+    }
+
+    DRVPRINT("Socket Cnt : %d \n", socketCnt);
+    return socketCnt;
+}
+
+// GetPhyCoresPerSocket : Get cores per socket
+static uint32 GetPhyCoresPerSocket(void)
+{
+    DRVPRINT("GetPhyCoresPerSocket : %d \n", GetThreadsPerSocket() / GetThreadsPerCore());
+    return GetThreadsPerSocket() / GetThreadsPerCore();
+}
+
+// GetTargetPhyCoreCnt : Get physical core count
+static uint32 GetTargetPhyCoreCnt(void)
+{
+    DRVPRINT("GetTargetPhyCoreCnt : %d \n", GetTargetCoreCount() / GetThreadsPerCore());
+    return GetPhyCoresPerSocket() * GetNumberOfSockets();
+}
+
+// GetEnergyUnit
+static uint32 GetEnergyUnit(void)
+{
+    uint64 data = 0;
+    uint32 result = 0;
+
+    if (IsRAPLAvailable())
+    {
+        data = ReadMSR(RAPL_PWR_UNIT_ADDR);
+        result = (uint8)((data & 0x1F00) >> 8) ? (uint8)((data & 0x1F00) >> 8) : 0x10;
+    }
+
+    return result;
+}
+
+//GetZenSystemInfo()
+static void GetZenSystemInfo(void)
+{
+    uint32 cnt = 0;
+    uint32 socketId = 0;
+    bool isEpyc = false;
+    bool isZen2 = false;
+    bool isZen3 = false;
+    bool isZen4AndAbove = false;
+    uint32 maskWidth = 0;
+    uint32 coresPerCcx = 0;
+    uint32 threadsPerCcx = 0;
+    uint32 ccxPerSocket = 0;
+    uint32 socketCnt = 0;
+    bool isExtTopoAvailable = false;
+    bool useHwTopo = (g_systemInfo.m_family >= 0x17) && IsExtApicIsAvailable() && IsHost();
+    DRVPRINTERROR("ExtAPIC(%d) Host(%d)", IsExtApicIsAvailable(), IsHost());
+
+    // By default first core of socke 0 is core 0
+    g_systemInfo.m_zen.m_firstCore[0] = 0UL;
+
+    for (cnt = 1; cnt < PWR_MAX_SOCKET_COUNT; cnt++)
+    {
+        g_systemInfo.m_zen.m_firstCore[cnt] = 0xFFFFFFFFUL;
+    }
+
+    g_systemInfo.m_zen.m_energyUnit = GetEnergyUnit();
+    g_systemInfo.m_zen.m_totalThreads = GetTargetCoreCount();
+    g_systemInfo.m_zen.m_isSmtEnabled = PwrIsSmtEnabled();
+
+    PwrSetExtendedApicId(&g_systemInfo);
+
+    // DRVPRINTERROR("useHwTopo(%d) IsExtApicIsAvailable(%d) IsIrPerfAvailable(%d) IsHyperV(%d) IsHost(%d) cpu(%d)",
+    // useHwTopo, IsExtApicIsAvailable(), IsIrPerfAvailable(), IsHyperVisor(), IsHost(), GetTargetCoreCount());
+
+    // In VM without Extended topology, guest VM can not detect different socket, ccx, and SMT
+    // Socket must be 1
+    if (useHwTopo)
+    {
+        g_systemInfo.m_zen.m_threadsPerSocket              = GetThreadsPerSocket();
+        g_systemInfo.m_socketCount                         = GetNumberOfSockets();
+        g_systemInfo.m_zen.m_totalPhysicalCores            = GetTargetPhyCoreCnt();
+        g_systemInfo.m_zen.m_physicalCoresPerSocket        = GetPhyCoresPerSocket();
+    }
+    else
+    {
+        g_systemInfo.m_zen.m_threadsPerSocket              = GetTargetCoreCount();
+        g_systemInfo.m_socketCount                         = 1;
+        g_systemInfo.m_zen.m_totalPhysicalCores            = GetTargetCoreCount();
+        g_systemInfo.m_zen.m_physicalCoresPerSocket        = GetTargetCoreCount();
+    }
+
+    g_systemInfo.m_zen.m_isRaplAvailable               = IsRAPLAvailable();
+
+    isEpyc = (g_systemInfo.m_family == 0x17) && (g_systemInfo.m_model <= 0x2f);
+
+    if (!isEpyc && g_systemInfo.m_family == 0x17)
+    {
+        isZen2 = ((0x30 <= g_systemInfo.m_model) && (g_systemInfo.m_model <= 0x3f))
+                 || ((0x60 <= g_systemInfo.m_model) && (g_systemInfo.m_model <= 0x7f));
+    }
+
+    if (!isEpyc && ! isZen2 && (0x19 == g_systemInfo.m_family))
+    {
+        isZen3 = (g_systemInfo.m_model <= 0xf)
+                 || ((0x20 <= g_systemInfo.m_model) && (g_systemInfo.m_model <= 0x5f));
+    }
+
+    if (!isEpyc && (0x19 <= g_systemInfo.m_family))
+    {
+        isZen4AndAbove = (0x19 == g_systemInfo.m_family &&
+                          ((g_systemInfo.m_model >= 0x10 && g_systemInfo.m_model <= 0x1f) || // RS
+                           (g_systemInfo.m_model >= 0xa0 && g_systemInfo.m_model <= 0xaf) || // RSDN
+                           (g_systemInfo.m_model >= 0x60 && g_systemInfo.m_model <= 0x6f) || // RPL
+                           (g_systemInfo.m_model >= 0x70 && g_systemInfo.m_model <= 0x7f) || // PHX & PHX2
+                           (g_systemInfo.m_model >= 0x80 && g_systemInfo.m_model <= 0x8f) || // MI300C
+                           (g_systemInfo.m_model >= 0x90 && g_systemInfo.m_model <= 0x9f))) || // MI300A
+                         (g_systemInfo.m_family > 0x19); // Zen5
+    }
+
+    g_systemInfo.m_zen.m_isZen2 = isZen2;
+    g_systemInfo.m_zen.m_isZen3 = isZen3;
+    g_systemInfo.m_zen.m_isZen4AndAbove = isZen4AndAbove;
+
+    if (isZen2 || isZen3 || isZen4AndAbove)
+    {
+        // Check if extended topology information is available
+        isExtTopoAvailable = IsExtnTopology();
+
+        if (isExtTopoAvailable)
+        {
+            maskWidth = CoreMaskWidth();
+            DRVPRINT("Mask Width %d\n", maskWidth);
+        }
+
+    }
+
+    g_systemInfo.m_zen.m_socketMaskWidth = 1;
+    g_systemInfo.m_zen.m_socketShiftWidth = isExtTopoAvailable ? maskWidth : 0;
+    g_systemInfo.m_zen.m_coreShiftWidth = g_systemInfo.m_zen.m_isSmtEnabled ? 1 : 0;
+
+    if (isZen2)
+    {
+        // TODO: Will this work for downcored Zen 2?
+        g_systemInfo.m_zen.m_coreMaskWidth = 2;
+
+        g_systemInfo.m_zen.m_ccxMaskWidth = 0x1;
+        g_systemInfo.m_zen.m_ccxShiftWidth = g_systemInfo.m_zen.m_coreMaskWidth + g_systemInfo.m_zen.m_coreShiftWidth;
+
+        g_systemInfo.m_zen.m_ccdShiftWidth = g_systemInfo.m_zen.m_ccxMaskWidth + g_systemInfo.m_zen.m_ccxShiftWidth;
+        g_systemInfo.m_zen.m_ccdMaskWidth = 3;
+
+        if (!isExtTopoAvailable)
+        {
+            g_systemInfo.m_zen.m_socketShiftWidth = g_systemInfo.m_zen.m_ccdShiftWidth + g_systemInfo.m_zen.m_ccdMaskWidth;
+        }
+    }
+    else if (isZen3 || isZen4AndAbove)
+    {
+        threadsPerCcx = ThreadsPerCcx();
+        coresPerCcx = g_systemInfo.m_zen.m_isSmtEnabled ? threadsPerCcx / 2 : threadsPerCcx;
+        g_systemInfo.m_zen.m_coreMaskWidth = 0;
+
+        socketCnt = g_systemInfo.m_zen.m_totalThreads/g_systemInfo.m_zen.m_threadsPerSocket;
+
+        DRVPRINT("SocketCnt: %d\n", socketCnt);
+
+        while(socketCnt)
+        {
+            g_systemInfo.m_zen.m_socketMaskWidth++;
+            socketCnt >>=1;
+        }
+
+        DRVPRINT("Threads per ccx: %u", threadsPerCcx);
+        DRVPRINT("Cores per ccx: %u", coresPerCcx);
+
+        coresPerCcx--;
+
+        if (coresPerCcx == 0)
+        {
+            coresPerCcx++;
+        }
+
+        while (coresPerCcx)
+        {
+            g_systemInfo.m_zen.m_coreMaskWidth++;
+            coresPerCcx >>= 1;
+        }
+
+        g_systemInfo.m_zen.m_ccxMaskWidth = 0;
+        g_systemInfo.m_zen.m_ccxShiftWidth = 0;
+
+        g_systemInfo.m_zen.m_ccdMaskWidth = 0;
+        ccxPerSocket = (g_systemInfo.m_zen.m_threadsPerSocket / threadsPerCcx) - 1;
+
+        if (ccxPerSocket == 0)
+        {
+            ccxPerSocket++;
+        }
+
+        while (ccxPerSocket)
+        {
+            g_systemInfo.m_zen.m_ccdMaskWidth++;
+            ccxPerSocket >>= 1;
+        }
+
+        if (isExtTopoAvailable)
+        {
+            g_systemInfo.m_zen.m_ccdShiftWidth = maskWidth - g_systemInfo.m_zen.m_ccdMaskWidth;
+        }
+        else
+        {
+            g_systemInfo.m_zen.m_ccdShiftWidth = g_systemInfo.m_zen.m_coreMaskWidth + g_systemInfo.m_zen.m_coreShiftWidth;
+        }
+
+        if (!isExtTopoAvailable)
+        {
+            g_systemInfo.m_zen.m_socketShiftWidth = g_systemInfo.m_zen.m_ccdShiftWidth + g_systemInfo.m_zen.m_ccdMaskWidth;
+        }
+    }
+
+    DRVPRINT("coreMaskWidth(%u) coreShiftWidth(%u) ccxMaskWidth(%u) ccxShiftWidth(%u) ccdMaskWidth(%u) ccdShiftWidth(%u) socketMaskWidth(%u) socketShiftWidth(%u)",
+             g_systemInfo.m_zen.m_coreMaskWidth, g_systemInfo.m_zen.m_coreShiftWidth,
+             g_systemInfo.m_zen.m_ccxMaskWidth, g_systemInfo.m_zen.m_ccxShiftWidth,
+             g_systemInfo.m_zen.m_ccdMaskWidth, g_systemInfo.m_zen.m_ccdShiftWidth,
+             g_systemInfo.m_zen.m_socketMaskWidth, g_systemInfo.m_zen.m_socketShiftWidth);
+
+    if (!IsHyperVisor())
+    {
+        g_systemInfo.m_zen.m_pstateReg = ReadMSR(AMDT_PSTATE_BASE_REGISTER);
+    }
+
+    PwrSetExtPerfMonAndDbgInfo(&g_systemInfo);
+
+    if (g_systemInfo.m_socketCount > 0)
+    {
+        for (cnt = 0; cnt < g_systemInfo.m_zen.m_totalThreads; cnt++)
+        {
+            if (isEpyc)
+            {
+                // TODO: This will fail for downcored/virtual instances on zen2
+                socketId = (g_systemInfo.m_zen.m_apic[cnt].m_extdApic >> 6);
+            }
+            else if (isZen2 || isZen3 || isZen4AndAbove)
+            {
+                uint32 socketMask = 0;
+                uint32 socketMaskWidth = g_systemInfo.m_zen.m_socketMaskWidth;
+
+                while (socketMaskWidth)
+                {
+                    socketMask |= (1 << (socketMaskWidth - 1));
+                    socketMaskWidth--;
+                }
+
+                socketId = (g_systemInfo.m_zen.m_apic[cnt].m_extdApic >> g_systemInfo.m_zen.m_socketShiftWidth) & socketMask;
+            }
+
+            if (g_systemInfo.m_zen.m_firstCore[socketId] == 0xFFFFFFFFUL)
+            {
+                g_systemInfo.m_zen.m_firstCore[socketId] = cnt;
+                DRVPRINT("SOCKET CORE %d\n", cnt);
+            }
+        }
+    }
+}
+
+static void SetFirstBusIds(PTARGET_SYSTEM_INFO pTargetInfo)
+{
+    if (NULL != pTargetInfo)
+    {
+        uint32 cnt = 0;
+
+        for (cnt = 0; cnt < pTargetInfo->m_socketCount; cnt++)
+        {
+            if (cnt < PWR_MAX_SOCKET_COUNT)
+            {
+                uint32 firstCoreOfSocket = pTargetInfo->m_zen.m_firstCore[cnt];
+
+                if (firstCoreOfSocket < MAX_CORE_CNT)
+                {
+                    uint32 nodeId = pTargetInfo->m_zen.m_apic[firstCoreOfSocket].m_nodeId;
+                    uint32 dev = 0x18U + nodeId;
+                    uint32 func = 0x0U;
+                    uint32 offset = pTargetInfo->m_zen.m_isZen4AndAbove ? 0xC04 : 0x84U;
+                    pTargetInfo->m_zen.m_mmio[cnt].m_bus = ReadPCIDev(0x0U, dev, func, offset);
+                    pTargetInfo->m_zen.m_mmio[cnt].m_threadId = pTargetInfo->m_zen.m_firstCore[cnt];
+                    DRVPRINT("Info: core %d busId 0x%x \n", pTargetInfo->m_zen.m_mmio[cnt].m_threadId, pTargetInfo->m_zen.m_mmio[cnt].m_bus);
+                }
+                else
+                {
+                    DRVPRINT("Invalid CoreId(%d)) for Socket(%d)).", firstCoreOfSocket, cnt);
+                }
+            }
+            else
+            {
+                DRVPRINT("Invalid socketId(%d))", cnt);
+            }
+        }
+    }
+}
+
+// GetTargetSystemInfo: Get the target system info
+void GetTargetSystemInfo(PTARGET_SYSTEM_INFO* pTargetInfo, bool reset)
+{
+    if (NULL == g_pSystemInfo || reset)
+    {
+        memset(&g_systemInfo, 0, sizeof(TARGET_SYSTEM_INFO));
+        g_systemInfo.m_isAmd = IsAMDPlatform();
+        GetCpuModelFamily(&g_systemInfo.m_family, &g_systemInfo.m_model);
+        g_systemInfo.m_isZen = (0x17 <= g_systemInfo.m_family);
+        g_systemInfo.m_socketCount = 1;
+
+        if (1 == g_systemInfo.m_isAmd)
+        {
+            g_systemInfo.m_socketType = PwrGetSocketType();
+            g_systemInfo.m_isCefAvailable = IsCefSupported();
+            g_systemInfo.m_isGuest = IsHyperVisor();
+        }
+
+        if (g_systemInfo.m_isZen)
+        {
+            GetZenSystemInfo();
+
+            if (!g_systemInfo.m_isGuest)
+            {
+                SetFirstBusIds(&g_systemInfo);
+            }
+        }
+        else
+        {
+            // For non amd processors
+            g_systemInfo.m_nonAmd.m_cores = GetTargetCoreCount();
+        }
+
+        g_pSystemInfo = &g_systemInfo;
+    }
+
+    *pTargetInfo = g_pSystemInfo;
+}
+
+// PwrGetSetBitIndex: Get the index of nth set set
+uint32 PwrGetSetBitIndex(uint32 setBitId, uint32 bitMask)
+{
+    uint32 cnt = 0;
+    uint32 setBitInstance = 0;
+    uint32 pos = 0;
+
+    for (cnt = 0; cnt < 32; cnt++)
+    {
+        if (bitMask & (1 << cnt))
+        {
+            setBitInstance++;
+        }
+
+        if (setBitInstance == setBitId)
+        {
+            pos = cnt;
+            break;
+        }
+    }
+
+    return pos;
+}
+
+// Note: Return accurate values for Zen 2 and Zen 3
+uint32_t GetCcxCount()
+{
+    uint32_t ccxCnt = 0;
+    uint32_t i = 0;
+    uint32_t j = 0;
+    PTARGET_SYSTEM_INFO pInfo = NULL;
+    uint32_t ccxShiftWidth = 0;
+
+    GetTargetSystemInfo(&pInfo, false);
+
+    // Count the number of distinct apic ids at ccx level
+    if (pInfo->m_zen.m_isZen2)
+    {
+        ccxShiftWidth = pInfo->m_zen.m_ccxShiftWidth;
+    }
+    // ccd = ccx for Zen3
+    else if (pInfo->m_zen.m_isZen3 || pInfo->m_zen.m_isZen4AndAbove)
+    {
+        ccxShiftWidth = pInfo->m_zen.m_ccdShiftWidth;
+    }
+
+    // There will be atlest one distinct element
+    ccxCnt = 1;
+
+    for (i = 1; i < MAX_CORE_CNT; i++)
+    {
+        for (j = 0; j < i; j++)
+        {
+            if (pInfo->m_zen.m_apic[i].m_extdApic >> ccxShiftWidth ==
+                pInfo->m_zen.m_apic[j].m_extdApic >> ccxShiftWidth)
+            {
+                break;
+            }
+        }
+
+        if (i == j)
+        {
+            ccxCnt++;
+        }
+    }
+
+    return ccxCnt;
+}
+
+uint32 GetSocketCount()
+{
+    PTARGET_SYSTEM_INFO pInfo = NULL;
+
+    GetTargetSystemInfo(&pInfo, false);
+
+    return pInfo->m_socketCount;
+}
+
+uint32_t GetZenVersion()
+{
+    uint32_t zenVer = 0;
+    PTARGET_SYSTEM_INFO pInfo = NULL;
+
+    GetTargetSystemInfo(&pInfo, false);
+
+    if (pInfo->m_zen.m_isZen2)
+    {
+        zenVer = (uint32_t)PWR_ZEN2;
+    }
+    else if (pInfo->m_zen.m_isZen3)
+    {
+        zenVer = (uint32_t)PWR_ZEN3;
+    }
+    else if (pInfo->m_zen.m_isZen4AndAbove)
+    {
+        zenVer = (uint32_t)PWR_ZEN4;
+    }
+
+    return zenVer;
+}
+
+uint32_t GetNodeIdForCore(uint32_t coreId)
+{
+    uint32_t nodeId = 0;
+    PTARGET_SYSTEM_INFO pInfo = NULL;
+
+    GetTargetSystemInfo(&pInfo, false);
+
+    if (coreId < MAX_CORE_CNT)
+    {
+        nodeId = pInfo->m_zen.m_apic[coreId].m_nodeId;
+    }
+
+    return nodeId;
+}
+
+uint32_t GetSocketIdForCore(uint32_t coreId)
+{
+    uint32_t socketId = 0;
+    PTARGET_SYSTEM_INFO pInfo = NULL;
+
+    GetTargetSystemInfo(&pInfo, false);
+
+    if (coreId < MAX_CORE_CNT)
+    {
+        if (!IsHyperVisor())
+        {
+            socketId = pInfo->m_zen.m_apic[coreId].m_extdApic >> pInfo->m_zen.m_socketShiftWidth &
+                   ~(0xFFFFFFFFU << pInfo->m_zen.m_socketMaskWidth);
+        }
+        else
+        {
+            // As per PPR it is one node per processor CPUID_Fn8000001E_ECX
+            // However, using this only for hyper-V case to avoid testing all scenarios
+            socketId = pInfo->m_zen.m_apic[coreId].m_nodeId;
+        }
+    }
+    else
+    {
+        DRVPRINT("Invalid core id(%d)", coreId);
+    }
+
+    return socketId;
+}
diff --git a/drivers/powerprofiler/src/PwrCounterAccessInterface.c b/drivers/powerprofiler/src/PwrCounterAccessInterface.c
new file mode 100644
index 000000000000..b405c39cfb3f
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrCounterAccessInterface.c
@@ -0,0 +1,520 @@
+//==================================================================================
+// Copyright (c) 2016 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrCounterAccessInterface.c
+///
+//==================================================================================
+#include <PwrOsPrimitives.h>
+#include <PwrDriverUtils.h>
+#include <PwrCounterAccessInterface.h>
+#include <PwrCommonConfig.h>
+
+static uint32 g_boostedPstateCnt = INVALID_UINT32_VALUE;
+static bool g_cefSupported = false;
+static bool g_cefROSupported = false;
+
+// PreviousData: Holds previous counter data
+uint32 prevCoreEnergy[MAX_CORE_CNT];
+uint32 prevPkgEnergy[PWR_MAX_SOCKET_COUNT];
+static PwrCefInfo g_prevROCefData[MAX_CORE_CNT];
+
+#define CORE_ENERGY_STAT_ADDR 0xC001029A
+#define PKG_ENERGY_STAT_ADDR 0xC001029B
+#define AMDUPROF_THM_TCTL_REGISTER      0x00059800
+
+// ReadBoostedPstate:
+static uint32 ReadBoostedPstate(void)
+{
+    uint32 boostedPstate = 0;
+    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+    GetTargetSystemInfo(&pTargetInfo, false);
+
+    if ((NULL != pTargetInfo) && (1 != pTargetInfo->m_isZen))
+    {
+        // Get the number of boosted P-States from D18F4x15C Core Performance Boost Control
+        uint32 data = ReadPCIDev(0, 0x18, 0x4, 0x15C);
+
+        // bits 4:2 are NumBoostStates
+        boostedPstate = ((data & 0x1C) >> 2);
+    }
+
+    return boostedPstate;
+}
+
+// ResetCoreEffectiveFreqCounters:
+static void ResetCoreEffectiveFreqCounters(void)
+{
+    if ((true != g_cefROSupported) && (true == g_cefSupported))
+    {
+        WriteMSR(MPERF_MSR_ADDRESS, 0);
+        WriteMSR(APERF_MSR_ADDRESS, 0);
+    }
+}
+
+// ReadCoreEffectiveFreqCounters:
+static void ReadCoreEffectiveFreqCounters(PwrCefInfo* pCef)
+{
+    if (true == g_cefSupported)
+    {
+        pCef->m_mperf = ReadMSR(MPERF_MSR_ADDRESS);
+        pCef->m_aperf = ReadMSR(APERF_MSR_ADDRESS);
+        pCef->m_p0State = ReadMSR(P0STATE_MSR_ADDRESS + g_boostedPstateCnt);
+        pCef->m_tsc = ReadMSR(TSC_MSR_ADDRESS);
+
+        // Reset the counter value adter reading the registers
+        ResetCoreEffectiveFreqCounters();
+    }
+    else
+    {
+        memset(pCef, 0, sizeof(PwrCefInfo));
+    }
+}
+
+// InitailizePrevROCefData: Init DS to store prev data for CEF
+void PwrInitailizePrevROCefData(int core)
+{
+    g_prevROCefData[core].m_mperf = ReadMSR(MPERF_RO_MSR_ADDRESS);
+    g_prevROCefData[core].m_aperf = ReadMSR(APERF_RO_MSR_ADDRESS);
+    g_prevROCefData[core].m_tsc = ReadMSR(TSC_MSR_ADDRESS);
+}
+
+// ReadCefROCounters : Read CEF data
+void PwrReadCefROCounters(uint32 core, PwrCefInfo* pCef, bool isCefROSupported, uint32 boostedPstateCnt)
+{
+    uint64 mperf = 0;
+    uint64 aperf = 0;
+    uint64 tsc = 0;
+
+    if (isCefROSupported)
+    {
+        mperf = ReadMSR(MPERF_RO_MSR_ADDRESS);
+        aperf = ReadMSR(APERF_RO_MSR_ADDRESS);
+        tsc = ReadMSR(TSC_MSR_ADDRESS);
+
+        if (g_prevROCefData[core].m_mperf < mperf)
+        {
+            pCef->m_mperf = mperf - g_prevROCefData[core].m_mperf;
+        }
+        else
+        {
+            pCef->m_mperf = mperf + ~g_prevROCefData[core].m_mperf;
+        }
+
+
+        if (g_prevROCefData[core].m_aperf < aperf)
+        {
+            pCef->m_aperf = aperf - g_prevROCefData[core].m_aperf;
+        }
+        else
+        {
+            pCef->m_aperf = aperf + ~g_prevROCefData[core].m_aperf;
+        }
+
+        if (g_prevROCefData[core].m_tsc < tsc)
+        {
+            pCef->m_tsc = tsc - g_prevROCefData[core].m_tsc;
+        }
+        else
+        {
+            pCef->m_tsc = tsc + ~g_prevROCefData[core].m_tsc;
+        }
+
+        // Store the data
+        g_prevROCefData[core].m_mperf = mperf;
+        g_prevROCefData[core].m_aperf = aperf;
+        g_prevROCefData[core].m_tsc = tsc;
+
+        // Read P-State-0 Frequency
+        pCef->m_p0State = ReadMSR(P0STATE_MSR_ADDRESS + boostedPstateCnt);
+    }
+    else
+    {
+        memset(pCef, 0, sizeof(PwrCefInfo));
+    }
+}
+
+// CollectPerCoreCounters:
+bool CollectNodeCounters(CoreData* pCoreCfg, uint32* pLength)
+{
+    bool result = true;
+    uint32 idx = 0;
+    uint32 offset = 0;
+    uint32* value = NULL;
+    uint64* value64 = NULL;
+    uint8* pData = NULL;
+
+    if ((NULL == pCoreCfg)
+        || (NULL == pCoreCfg->m_pCoreBuffer)
+        || (NULL == pCoreCfg->m_pCoreBuffer->m_pBuffer))
+    {
+        DRVPRINT("InvalidpCoreCfg or pCoreCfg->m_pCoreBuffer->m_pBuffer");
+        result = false;
+    }
+
+    if (true == result)
+    {
+        pData = pCoreCfg->m_pCoreBuffer->m_pBuffer;
+        offset = *pLength;
+
+        for (idx = COUNTERID_PID; idx <= COUNTERID_NODE_MAX_CNT; idx++)
+        {
+            if (false == ((pCoreCfg->m_counterMask >> idx) & 0x01))
+            {
+                continue;
+            }
+
+            switch (idx)
+            {
+                case COUNTERID_PID:
+                {
+                    //Get PID
+                    value64 = (uint64*)&pData[offset];
+                    *value64 = (uint64)pCoreCfg->m_contextData.m_processId;
+                    offset += sizeof(uint64);
+                    break;
+                }
+
+                case COUNTERID_TID:
+                {
+                    //Get TID
+                    value64 = (uint64*)&pData[offset];
+                    *value64 = (uint64)pCoreCfg->m_contextData.m_threadId;
+                    offset += sizeof(uint64);
+                    break;
+                }
+
+                case COUNTERID_CEF:
+                {
+                    PwrCefInfo* pCef = (PwrCefInfo*)&pData[offset];
+
+                    if (g_cefROSupported)
+                    {
+                        PwrReadCefROCounters(pCoreCfg->m_coreId,
+                                             pCef,
+                                             g_cefROSupported,
+                                             g_boostedPstateCnt);
+                    }
+                    else
+                    {
+                        ReadCoreEffectiveFreqCounters(pCef);
+                    }
+
+                    offset += sizeof(PwrCefInfo);
+                    break;
+
+                }
+
+                case COUNTERID_SOFTWARE_PSTATE:
+                {
+#define SOFTWARE_PSTATE_MSR_ADDR 0xC0010063
+                    value = (uint32*)&pData[offset];
+                    *value = (uint32)ReadMSR(SOFTWARE_PSTATE_MSR_ADDR);
+                    offset += sizeof(uint32);
+                    break;
+                }
+
+
+                case COUNTERID_PSTATE:
+                {
+#define PSTATE_MSR_ADDR 0xC0010071
+                    uint64 data = 0;
+                    data = ReadMSR(PSTATE_MSR_ADDR);
+                    value = (uint32*)&pData[offset];
+                    *value = (data >> 16) & 0x03;
+                    offset += sizeof(uint32);
+                    break;
+                }
+
+                case COUNTERID_CORE_POWER:
+                {
+                    uint32 data = 0;
+                    data = (uint32)ReadMSR(CORE_ENERGY_STAT_ADDR);
+                    value = (uint32*)&pData[offset];
+
+                    // When system is in idle counter reads 0 instead of prev or incremented value.
+                    // To avoid such cases, following fix is required
+                    *value = ((data == 0) ||  (prevCoreEnergy[pCoreCfg->m_coreId] == 0 )) ? 0 : data - prevCoreEnergy[pCoreCfg->m_coreId];
+                    prevCoreEnergy[pCoreCfg->m_coreId] = data;
+                    prevCoreEnergy[pCoreCfg->m_coreId] = data;
+                    offset += sizeof(uint32);
+                    break;
+                }
+
+                case COUNTERID_PKG_POWER:
+                {
+                    uint32 data = 0;
+                    uint32 socketId = 0;
+
+                    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+                    GetTargetSystemInfo(&pTargetInfo, false);
+
+                    if ((NULL != pTargetInfo)
+                        && (pTargetInfo->m_socketCount > 1))
+                    {
+                        if (pCoreCfg->m_coreId > 0)
+                        {
+                            uint32 socketCnt = 0;
+                            for (socketCnt = 0; socketCnt < PWR_MAX_SOCKET_COUNT; socketCnt++)
+                            {
+                                if (pTargetInfo->m_zen.m_firstCore[socketCnt] == pCoreCfg->m_coreId)
+                                {
+                                    socketId = socketCnt;
+                                    break;
+                                }
+                            }
+                        }
+                    }
+
+                    value = (uint32*)&pData[offset];
+                    data = (uint32)ReadMSR(PKG_ENERGY_STAT_ADDR);
+                    *value = data - prevPkgEnergy[socketId];
+                    prevPkgEnergy[socketId] = data;
+                    offset += sizeof(uint32);
+                    break;
+                }
+
+                case COUNTERID_PKG_TEMPERATURE:
+                {
+                    uint32 addr = AMDUPROF_THM_TCTL_REGISTER;
+                    uint32 data = 0;
+                    uint32 busId = 0;
+                    uint32 coreId = GetCurrentCoreId();
+                    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+                    GetTargetSystemInfo(&pTargetInfo, false);
+
+                    if (NULL != pTargetInfo)
+                    {
+                        uint32 cnt = 0;
+
+                        for (cnt = 0; cnt < PWR_MAX_SOCKET_COUNT; cnt++)
+                        {
+                            if (pTargetInfo->m_zen.m_mmio[cnt].m_threadId == coreId)
+                            {
+                                busId = pTargetInfo->m_zen.m_mmio[cnt].m_bus;
+                                break;
+                            }
+                        }
+                    }
+
+                    SmnRead(busId, addr, &data);
+                    // DRVPRINT("COUNTERID_PKG_TEMPERATURE coreId %d busId %d\n", coreId, busId);
+
+                    value = (uint32*)&pData[offset];
+                    *value = data;
+                    offset += sizeof(uint32);
+
+                    break;
+                }
+
+                default:
+                    break;
+            }
+        }
+    }
+
+    *pLength = offset;
+
+    return result;
+}
+
+// CollectBasicCounters:
+bool CollectBasicCounters(CoreData* pCoreCfg, uint32* pLength)
+{
+    bool result = true;
+    uint32 idx = 0;
+    uint32 offset = 0;
+    uint64* value64 = NULL;
+    uint16* value16 = NULL;
+    uint8* pData = NULL;
+
+    if ((NULL == pCoreCfg)
+        || (NULL == pCoreCfg->m_pCoreBuffer)
+        || (NULL == pCoreCfg->m_pCoreBuffer->m_pBuffer))
+    {
+        DRVPRINT("InvalidpCoreCfg or pCoreCfg->m_pCoreBuffer->m_pBuffer");
+        result = false;
+    }
+
+    if (true == result)
+    {
+        pData = pCoreCfg->m_pCoreBuffer->m_pBuffer;
+        offset = *pLength;
+
+        for (idx = 0; idx <= COUNTERID_BASIC_CNT ; idx++)
+        {
+            switch (idx)
+            {
+                case COUNTERID_SAMPLE_ID:
+                {
+                    value16 = (uint16*) &pData[offset];
+                    *value16 = (uint16)pCoreCfg->m_sampleId;
+                    offset += sizeof(uint16);
+                    break;
+                }
+
+                case COUNTERID_RECORD_ID:
+                {
+                    value64 = (uint64*) &pData[offset];
+                    *value64 = pCoreCfg->m_pCoreBuffer->m_recCnt;
+                    offset += sizeof(uint64);
+                    break;
+                }
+
+                case COUNTERID_SAMPLE_TIME:
+                {
+                    value64 = (uint64*) &pData[offset];
+                    *value64 = pCoreCfg->m_contextData.m_timeStamp;
+                    offset += sizeof(uint64);
+                    break;
+                }
+
+                default:
+                    break;
+            }
+        }
+
+        *pLength = offset;
+    }
+
+    return result;
+}
+void PwrReadInitialValues(uint32 threadId)
+{
+    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+    GetTargetSystemInfo(&pTargetInfo, false);
+
+    if ((NULL != pTargetInfo) && pTargetInfo->m_isZen)
+    {
+        bool initialValue = false;
+
+        if (NULL != pTargetInfo)
+        {
+            if (threadId == pTargetInfo->m_zen.m_apic[threadId].m_physicalId)
+            {
+                initialValue = true;
+            }
+
+            if (1 == pTargetInfo->m_zen.m_isRaplAvailable)
+            {
+                uint32 socketCnt = 0;
+                uint32 data = (uint32)ReadMSR(PKG_ENERGY_STAT_ADDR);
+
+                if (initialValue)
+                {
+                    prevCoreEnergy[threadId] = (uint32)ReadMSR(CORE_ENERGY_STAT_ADDR);
+                }
+
+
+
+                for (socketCnt = 0; socketCnt < pTargetInfo->m_socketCount; socketCnt++)
+                {
+                    if (threadId == pTargetInfo->m_zen.m_firstCore[socketCnt])
+                    {
+                        prevPkgEnergy[socketCnt] = data;
+                        break;
+                    }
+                }
+            }
+        }
+    }
+}
+
+// PwrInitializeBoostedPstate: Read and store boosted pstate
+void PwrInitializeBoostedPstate(void)
+{
+    // Read boosted p-state
+    if (INVALID_UINT32_VALUE == g_boostedPstateCnt)
+    {
+        g_boostedPstateCnt = ReadBoostedPstate();
+    }
+}
+
+// PwrInitializeEffectiveFrequency: Initialize effective frequency data
+void PwrInitializeEffectiveFrequency(uint32 core)
+{
+    g_cefSupported = IsCefSupported();
+    g_cefROSupported = IsROCefAvailable();
+
+    if (g_cefROSupported)
+    {
+        PwrInitailizePrevROCefData(core);
+    }
+    else if (g_cefSupported)
+    {
+        ResetCoreEffectiveFreqCounters();
+    }
+}
+// InitializeGenericCounterAccess:
+void InitializeGenericCounterAccess(uint32 core)
+{
+    DRVPRINT("DPC thread id %d", core);
+    PwrInitializeBoostedPstate();
+    PwrInitializeEffectiveFrequency(core);
+    PwrReadInitialValues(core);
+    PwrEnablePerf(true);
+}
+
+// CloseGenericCounterAccess:
+void CloseGenericCounterAccess(void)
+{
+    g_boostedPstateCnt = INVALID_UINT32_VALUE;
+    ResetCoreEffectiveFreqCounters();
+    memset(prevPkgEnergy, 0, sizeof(uint32) * PWR_MAX_SOCKET_COUNT);
+    memset(prevCoreEnergy, 0, sizeof(uint32) * MAX_CORE_CNT);
+    PwrEnablePerf(false);
+}
+
+// GetBasicCounterSize
+uint32 GetBasicCounterSize(void)
+{
+    uint32 bufferLen = 0;
+    //COUNTERID_SAMPLE_ID:
+    bufferLen += sizeof(uint16);
+    //COUNTERID_RECORD_ID:
+    bufferLen += sizeof(uint64);
+    //COUNTERID_SAMPLE_TIME:
+    bufferLen += sizeof(uint64);
+    return bufferLen;
+}
+
+// GetNodeCounterSize
+uint32 GetNodeCounterSize(uint32 counterId)
+{
+    uint32 bufferLen = 0;
+
+    switch (counterId)
+    {
+        // 8 byte counters
+        case COUNTERID_PID:
+        case COUNTERID_TID:
+        {
+            bufferLen += sizeof(uint64);
+            break;
+        }
+
+        // 4 byte counters
+        case COUNTERID_PSTATE:
+        case COUNTERID_SOFTWARE_PSTATE:
+        case COUNTERID_PKG_POWER:
+        case COUNTERID_PKG_TEMPERATURE:
+        case COUNTERID_CORE_POWER:
+        {
+            bufferLen += sizeof(uint32);
+            break;
+        }
+
+        // 24 bytes counter
+        case COUNTERID_CEF:
+        {
+            bufferLen += sizeof(PwrCefInfo);
+            break;
+        }
+
+        default:
+            break;
+    }
+
+    return bufferLen;
+}
+
diff --git a/drivers/powerprofiler/src/PwrDriverUtils.c b/drivers/powerprofiler/src/PwrDriverUtils.c
new file mode 100644
index 000000000000..db062e589f1c
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrDriverUtils.c
@@ -0,0 +1,935 @@
+//==================================================================================
+// Copyright (c) 2020 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrDriverUtils.cpp
+///
+//==================================================================================
+// LOCAL INCLUDES
+
+#include <PwrOsPrimitives.h>
+#include <PwrCounterAccessInterface.h>
+#include <PwrDriverUtils.h>
+#include <PwrProfCpuid.h>
+#if defined (_WIN32)
+    #include <PwrDriverInternal.h>
+#endif
+
+#if defined (__linux__)
+    #include <linux/slab.h>
+    #include <PwrProfInternal.h>
+    #include <PwrProfCpuid.h>
+    #include <PwrDriverIoctls.h>
+    #include <PmcInterface.h>
+#endif
+
+#define PCI_ADDR_PORT       0xCF8
+#define PCI_DATA_PORT       0xCFC
+
+#define HWCF    0xC0010015
+
+// Bit 30: IRPerfEn: enable instructions retired counter
+#define HwCfgIRPerfEn   1ULL << 30
+
+// GetTargetCoreCount: Get the total number of core in the cpu
+uint32 GetTargetCoreCount(void)
+{
+    return GetOnlineCpus();
+}
+
+// GetCpuModelFamily: Get family and model number of the cpu
+void GetCpuModelFamily(uint32* family, uint32* model)
+{
+    CpuInfo info;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUID(aCPUInfo, CPUID_FnFeatureId);
+
+    info.eax = aCPUInfo[0];
+    *family = info.info.family;
+    *model = info.info.model;
+
+    if (FAMILY_EXTENDED_VALUE == *family)
+    {
+        *family += info.info.extFamily;
+    }
+
+    *model += (info.info.extModel << 4);
+}
+
+// IsCefSupported: Check if core effective frequency feature is available
+bool IsCefSupported()
+{
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, CPUID_FnThermalAndPowerManagement);
+
+    // Effective Frequency is supported
+    result = (aCPUInfo[PWR_ECX_OFFSET] & CPUID_FnThermalAndPowerManagement_ECX_EffFreq) != 0;
+    return result;
+}
+
+// IsROCefAvailable
+bool IsROCefAvailable()
+{
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, CPUID_FnAdvancePowerManagementInformation);
+
+    // Effective Frequency is supported
+    result = (aCPUInfo[PWR_EDX_OFFSET] & CPUID_FnAdvancePowerManagementInformation_EDX_EffFreqRO) != 0;
+    return result;
+}
+
+// IsPMCCounterAvailable
+bool IsPMCCounterAvailable(void)
+{
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, CPUID_FnBrandIdIdentifier);
+
+    // Effective Frequency is supported
+    result = (aCPUInfo[PWR_ECX_OFFSET] & CPUID_FnAmdExtendedFeatures_ECX_PerfCtrExtCore) != 0;
+    return result;
+}
+
+// Get Address for extended configuration address space.
+static uint32 GetExtendedConfigurationSpaceAddress(unsigned int bus, unsigned int device, unsigned  func, unsigned int reg)
+{
+    PciExtendedConfigurationSpaceAddress pciAddr;
+    pciAddr.m_address = 0U;
+    pciAddr.element.m_configEn = 1U;
+    pciAddr.element.m_extReg = (reg >> 8) & 0xFU;
+    pciAddr.element.m_reg = reg & 0x00FCU;
+    pciAddr.element.m_bus = bus;
+    pciAddr.element.m_device = device;
+    pciAddr.element.m_function = func;
+    return pciAddr.m_address;
+}
+
+// Read data from specified PCI32 configuration address.
+uint32 ReadPCIDev(uint32 bus, uint32 device, uint32 func, uint32 reg)
+{
+    uint32 data = 0;
+    uint32 address = GetExtendedConfigurationSpaceAddress(bus, device, func, reg);
+    data = ReadPCI(address);
+    DRVPRINT("bus %u , device %u , func %u , reg %u , address %u, data %u\n", bus, device, func, reg, address, data);
+    return data;
+}
+
+void WritePCIDev(uint32 bus, uint32 device, uint32 func, uint32 reg, uint32 data)
+{
+    uint32 address = GetExtendedConfigurationSpaceAddress(bus, device, func, reg);
+    WritePCI(address, data);
+    DRVPRINT("bus %u , device %u , func %u , reg %u , address %u, data %u\n", bus, device, func, reg, address, data);
+}
+
+// Access PCIe Address space for read/write
+void AccessPci(PACCESS_PCI pData)
+{
+    if (NULL != pData)
+    {
+        if (1 == pData->m_isReadAccess)
+        {
+            pData->m_data = (uint32)ReadPCI(pData->m_address);
+        }
+        else if (0 == pData->m_isReadAccess)
+        {
+            WritePCI(pData->m_address, pData->m_data);
+        }
+    }
+}
+
+// Access MSR Address space fore read/write
+void AccessMSR(PACCESS_MSR pData)
+{
+    if (NULL != pData)
+    {
+        if (1 == pData->m_isReadAccess)
+        {
+            pData->m_data = ReadMSR(pData->m_regId);
+        }
+        else if (0 == pData->m_isReadAccess)
+        {
+            WriteMSR(pData->m_regId, pData->m_data);
+        }
+    }
+}
+
+// AccessMMIO: Read/Write to the MMIO address space.
+// This method is used to called from user space
+bool AccessMMIO(ACCESS_MMIO* pMMIO)
+{
+    bool ret = false;
+    uint64 res = 0;
+    uint64 map = 0;
+
+    DRVPRINT("R/W: %d, addr:0x%llx data:0x%x\n", pMMIO->m_isReadAccess, pMMIO->m_addr, pMMIO->m_data);
+
+    // Memory map for the address.
+    ret = MapMMIOSpace(pMMIO->m_addr,
+                       sizeof(uint32),
+                       &map,
+                       &res);
+
+    if (true == ret)
+    {
+        if (1 == pMMIO->m_isReadAccess)
+        {
+            pMMIO->m_data = READ_DWORD(map);
+        }
+        else if (0 == pMMIO->m_isReadAccess)
+        {
+             WRITE_DWORD(map, pMMIO->m_data);
+        }
+
+        UnmapMMIOSpace(map, sizeof(uint32));
+    }
+
+    return ret;
+}
+
+void SmnRead(uint32 bus, uint32 address, uint32* pData)
+{
+    WritePCIDev(bus, 0, 0, 0xE0, address);
+    *pData = ReadPCIDev(bus, 0, 0, 0xE4);
+}
+
+void SmnWrite(uint32 bus, uint32 address, uint32 data)
+{
+    WritePCIDev(bus, 0, 0, 0xE0, address);
+    WritePCIDev(bus, 0, 0, 0xE4, data);
+}
+
+bool AccessSMN(TARGET_SYSTEM_INFO* pTargetInfo, ACCESS_SMN* pSmn)
+{
+    bool ret = false;
+
+    if ((NULL != pTargetInfo) && (NULL != pSmn))
+    {
+        if (pSmn->m_isBus == true)
+        {
+            if (1 == pSmn->m_isReadAccess)
+            {
+                SmnRead(pSmn->m_busId, pSmn->m_address, &pSmn->m_data);
+            }
+            else if (0 == pSmn->m_isReadAccess)
+            {
+                SmnWrite(pSmn->m_busId, pSmn->m_address, pSmn->m_data);
+            }
+
+            ret = true;
+        }
+        else
+        {
+            // Get the bus for SMN
+            if (pSmn->m_socket < pTargetInfo->m_socketCount)
+            {
+                // Make sure, SMN is access through only Pre-populated bus numbers.
+                uint32 bus = pTargetInfo->m_zen.m_mmio[pSmn->m_socket].m_bus;
+
+                if (1 == pSmn->m_isReadAccess)
+                {
+                    SmnRead(bus, pSmn->m_address, &pSmn->m_data);
+                }
+                else if (0 == pSmn->m_isReadAccess)
+                {
+                    SmnWrite(bus, pSmn->m_address, pSmn->m_data);
+                }
+
+                ret = true;
+            }
+            else
+            {
+                DRVPRINT("Error:Invalid socketIdx(%d) Socket count(%d)", pSmn->m_socket, pTargetInfo->m_socketCount);
+            }
+        }
+    }
+
+    return ret;
+}
+
+// Return the number of bits set.
+void GetBitsCount(uint64 mask, uint32* pCount)
+{
+    uint32 count = 0;
+    uint32 loop = 8 * sizeof(uint64);
+
+    while (loop--)
+    {
+        if (mask & (1ULL << loop))
+        {
+            count++;
+        }
+    }
+
+    *pCount = count;
+}
+
+// Get GPU base address
+uint64 GmmxGetBaseAddress(uint32 gpuAddr)
+{
+    uint32 baseGPUAddressLow = ReadPCI(gpuAddr);;
+
+    // set bits 0:3 to 0
+    baseGPUAddressLow = baseGPUAddressLow & 0xFFFFFFF0;
+    return baseGPUAddressLow;
+}
+
+// PwrGetLogicalProcessCount:  Get the number of logical cores
+uint32 PwrGetLogicalProcessCount(void)
+{
+    uint32 numOfThreads = 0;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUID(aCPUInfo, CPUID_FnFeatureId);
+
+    numOfThreads = (aCPUInfo[PWR_EBX_OFFSET] & CPUID_FeatureId_EBX_LogicalProcessorCount) >> 16;
+    return numOfThreads;
+}
+
+// PwrIsSmtEnabled: Check if thread per core is more than 1
+bool PwrIsSmtEnabled()
+{
+    uint32 numOfThreads = 0;
+
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUID(aCPUInfo, CPUID_FnIdentifiers);
+
+    numOfThreads = (aCPUInfo[PWR_EBX_OFFSET] & CPUID_NodeIdentifiers_EBX_ThreadsPerCore) + 1;
+
+    result = (numOfThreads > 1) ? true : false;
+    return result;
+}
+
+// PwrReadCpuId: Get the CPUID instruction
+uint32 PwrReadCpuId(RegisterOffset regId, uint32 functionId)
+{
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, functionId);
+    return aCPUInfo[regId];
+}
+
+static void PwrCoreDpc(void* pContext)
+{
+    PwrApicInfo* pApic = (PwrApicInfo*) pContext;
+    uint32 osCoreId = GetCurrentCoreId();
+
+    if (NULL != pApic)
+    {
+        DRVPRINT("Executed DPC %d", osCoreId);
+        pApic[osCoreId].m_extdApic = PwrReadCpuId(PWR_EAX_OFFSET, CPUID_FnIdentifiers);
+        pApic[osCoreId].m_nodeId = 0xFF & PwrReadCpuId(PWR_ECX_OFFSET, CPUID_FnIdentifiers);
+        DRVPRINT("thread %d extended apic 0x%x node %d", osCoreId, pApic[osCoreId].m_extdApic, pApic[osCoreId].m_nodeId);
+    }
+}
+
+static void PwrExtPerfMonAndDbgInfoDpc(void* pContext)
+{
+    PwrExtPerfMonAndDbgInfo* pInfo = (PwrExtPerfMonAndDbgInfo*)pContext;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    uint32_t largestExtdFuncNum = 0;
+
+    if (NULL != pInfo)
+    {
+        largestExtdFuncNum = PwrReadCpuId(PWR_EAX_OFFSET, CPUID_FnLargFuncExtNum);
+
+        if (largestExtdFuncNum >= CPUID_FnExtdPerfmonAndDebug)
+        {
+            ReadCPUID(aCPUInfo, CPUID_FnExtdPerfmonAndDebug);
+            pInfo->m_isPerfMonV2 = aCPUInfo[PWR_EAX_OFFSET] & 0x1;
+            pInfo->m_isLbrExtV2 = (aCPUInfo[PWR_EAX_OFFSET] >> 1) & 0x1;
+            pInfo->m_numOfUmcPmc = (aCPUInfo[PWR_EBX_OFFSET] >> 16) & 0x3F;
+            pInfo->m_numOfDfPmc = (aCPUInfo[PWR_EBX_OFFSET] >> 10) & 0x3F;
+            pInfo->m_lbrV2StackSize = (aCPUInfo[PWR_EBX_OFFSET] >> 4) & 0x3F;
+            pInfo->m_numOfCorePmc = (aCPUInfo[PWR_EBX_OFFSET] & 0xF);
+            pInfo->m_activeUmcMask = (aCPUInfo[PWR_ECX_OFFSET] & 0xFFFFFFFF);
+        }
+
+        // Note: On some family/models CPUID_FnExtdPerfmonAndDebug
+        // will return 0, in which case use default values
+        pInfo->m_numOfCorePmc = (pInfo->m_numOfCorePmc == 0) ? CORE_PMC_COUNT : pInfo->m_numOfCorePmc;
+        pInfo->m_numOfDfPmc = (pInfo->m_numOfDfPmc == 0) ? DF_PMC_COUNT : pInfo->m_numOfDfPmc;
+        pInfo->m_numOfL3Pmc = CHL3_PMC_COUNT;
+
+        DRVPRINT("isPerfMonV2(%d) isLbrExtV2(%d) numOfUmcPmc(%u) numOfDfPmc(%u) lbrV2StackSize(%u) numOfCorePmc(%u) activeUmcMask(%u)",
+                 pInfo->m_isPerfMonV2, pInfo->m_isLbrExtV2,
+                 pInfo->m_numOfUmcPmc, pInfo->m_numOfDfPmc,
+                 pInfo->m_lbrV2StackSize, pInfo->m_numOfCorePmc,
+                 pInfo->m_activeUmcMask);
+    }
+}
+
+uint32 GetFirstBitSet(uint64 num)
+{
+    uint32 cnt = 0;
+
+    while ((num & 1) == 0)
+    {
+        cnt++;
+        num >>= 1;
+    }
+
+    return cnt;
+}
+
+
+uint32 GetBitCount(uint64 val)
+{
+    uint32 cnt;
+
+    for (cnt = 0; val; cnt++)
+    {
+        val &= val - 1;
+    }
+
+    return cnt;
+}
+
+uint32 GetBitCountExt(uint64* pVal)
+{
+    uint32 idx = 0;
+    uint32 bitCount = 0;
+
+    for (idx = 0; idx < PWR_CORE_MASK_SIZE; idx++)
+    {
+        if (0 == pVal[idx])
+        {
+            continue;
+        }
+
+        bitCount += GetBitCount(pVal[idx]);
+    }
+
+    return bitCount;
+}
+
+// AccessPciAddress: Read/Write PCI address space
+bool AccessPciAddress(PACCESS_PCI pData)
+{
+    bool ret = false;
+
+    if (NULL != pData)
+    {
+        AccessPci(pData);
+        ret = true;
+    }
+
+    return ret;
+}
+
+static void MsrDpc(void* pContext)
+{
+    PACCESS_MSR pData = (PACCESS_MSR) pContext;
+
+    if (NULL != pData)
+    {
+        AccessMSR(pData);
+    }
+}
+
+// AccessMSRAddress: Read/Write MSR in a core context
+bool AccessMSRAddress(PACCESS_MSR pData)
+{
+    bool ret = false;
+
+    if (NULL != pData)
+    {
+        if ((PWR_CURRENT_CORE == pData->m_core) || (GetCurrentCoreId() == pData->m_core))
+        {
+            AccessMSR(pData);
+        }
+        else
+        {
+            DeferedCoreExecution(pData->m_core, MsrDpc, pData);
+        }
+
+        ret = true;
+    }
+
+    return ret;
+}
+
+static void PrepareApicList(PTARGET_SYSTEM_INFO pTargetInfo)
+{
+    uint32 count = 0;
+
+    if (NULL != pTargetInfo)
+    {
+        for (count = 0; count < pTargetInfo->m_zen.m_totalThreads; count++)
+        {
+            if (pTargetInfo->m_zen.m_isSmtEnabled)
+            {
+                uint32 idx = 0;
+                uint32 apicId = pTargetInfo->m_zen.m_apic[count].m_extdApic;
+                apicId = apicId & (~0UL << 1);
+
+                for (idx = 0; idx < pTargetInfo->m_zen.m_totalThreads; idx++)
+                {
+                    if (pTargetInfo->m_zen.m_apic[idx].m_extdApic == apicId)
+                    {
+                        pTargetInfo->m_zen.m_apic[count].m_physicalId = idx;
+                        DRVPRINT("thread %d phy %d", count, idx);
+                        break;
+                    }
+                }
+            }
+            else
+            {
+                pTargetInfo->m_zen.m_apic[count].m_physicalId = count;
+            }
+        }
+    }
+}
+
+#if defined(_WIN32)
+void PwrSetExtendedApicId(TARGET_SYSTEM_INFO* pTargetInfo)
+{
+    DRVPRINT(" PwrSetExtendedApicId");
+
+    if ((nullptr != pTargetInfo)
+        && (1 == pTargetInfo->m_isZen))
+    {
+        uint32 count = 0;
+
+        for (count = 0; count < pTargetInfo->m_zen.m_totalThreads; count++)
+        {
+            DeferedCoreExecution(static_cast<uint32>(count), PwrCoreDpc, pTargetInfo->m_zen.m_apic);
+        }
+
+        PrepareApicList(pTargetInfo);
+    }
+}
+
+#endif
+
+// Linux functions
+#if defined (__linux__)
+static bool IsCpuSigRead = false;
+
+// struct for cpu signature
+static CpuSignature cpu_sig =
+{
+    .m_value = 0,
+    .m_isHypervisor = false,
+};
+
+// LOCAL FUNCTIONS
+//
+// Read CPU Signature.
+void ReadCpuSignature(CpuSignature* cpu)
+{
+    int32 data[PWR_NUM_CPUID_OFFSETS] = {0,};
+    char vendorId[13];
+
+    memset(data, 0, sizeof(uint32)*PWR_NUM_CPUID_OFFSETS);
+    ReadCPUID(data, 0);
+
+    DRVPRINT("cpuid1 eax=%u, ebx=%u, ecx=%u, edx=%u \n", data[PWR_EAX_OFFSET], data[PWR_EBX_OFFSET], data[PWR_ECX_OFFSET], data[PWR_EDX_OFFSET]);
+    memcpy(vendorId, &data[PWR_EBX_OFFSET], 4);
+    memcpy(vendorId + 4, &data[PWR_EDX_OFFSET], 4);
+    memcpy(vendorId + 8, &data[PWR_ECX_OFFSET], 4);
+    vendorId[12] = '\0';
+
+    if (0 != strcmp(vendorId, "AuthenticAMD"))
+    {
+        printk(KERN_WARNING "pcore: NON AMD CPU found \n");
+        cpu->m_value = 0;
+        return;
+    }
+
+    memset(data, 0, sizeof(uint32)*PWR_NUM_CPUID_OFFSETS);
+    ReadCPUID(data, CPUID_FnBasicFeatures);
+    cpu->m_value = data[PWR_EAX_OFFSET];
+    cpu->m_isHypervisor = false;
+
+    if ((data[PWR_ECX_OFFSET] & CPUID_FnBasicFeatures_ECX_Hypervisor) != 0)
+    {
+        cpu->m_isHypervisor = true;
+        printk(KERN_WARNING "pcore: Hypervisor Detected\n");
+    }
+}
+
+// Get CPU signature.
+CpuSignature* GetCpuSignature(void)
+{
+
+    if (!IsCpuSigRead)
+    {
+        ReadCpuSignature(&cpu_sig);
+        IsCpuSigRead = true;
+    }
+
+    return &cpu_sig;
+}
+
+// Check for Amd platform
+bool IsAmd(CpuSignature* cpu)
+{
+    return cpu->m_value != 0U;
+}
+
+// Get Cpu family
+uint GetFamilyValue(CpuSignature* cpu)
+{
+    return ((cpu->m_value & CpuBaseFamily_MASK) >> 8) + ((cpu->m_value & CpuExtFamily_MASK) >> 20);
+}
+
+// Get Cpu model
+uint GetModelValue(CpuSignature* cpu)
+{
+    return ((cpu->m_value & CpuBaseModel_MASK) >> 4) | ((cpu->m_value & CpuExtModel_MASK) >> (16 - 4));
+}
+
+// Check if hardware is supported.
+long CheckHwSupport(void)
+{
+    uint family;
+    uint model;
+
+    CpuSignature* sig = GetCpuSignature();
+
+    /* Following are not supported:
+    1. Non AMD Platforms
+    2. Hypervisors
+    */
+    if (!IsAmd(sig))
+    {
+        DRVPRINT(KERN_WARNING "pcore:Non AMD Platform detected. pcore only supports AMD platforms\n");
+        return -EACCES;
+    }
+
+    if (sig->m_isHypervisor)
+    {
+        DRVPRINT(KERN_WARNING "pcore:Hypervisor detected. pcore does not support Hypervisor platforms\n");
+        return -EACCES;
+    }
+
+    /*Supported AMD platforms
+        Kaveri  :  0x15 30 to 3F
+        Carrizo :  0x15 60 to 6F
+        Mullins :  0x16 30 to 3F
+    */
+    family = GetFamilyValue(sig);
+    model  = GetModelValue(sig);
+    DRVPRINT(" family %x , model %x \n", family, model);
+
+    if ((family < 0x15) || (family > 0x16))
+    {
+        printk(KERN_WARNING "pcore: Unsupported family 0x%x \n", family);
+        return -EACCES;
+    }
+
+    if (0x15 == family)
+    {
+        if (!((model >= 0x30 && model <= 0x3F)
+              || (model >= 0x60 && model <= 0x6F)))
+        {
+            printk(KERN_WARNING "pcore: Unsupported model 0x%x for family 0x%x \n", model, family);
+            return -EACCES;
+        }
+    }
+
+    if (0x16 == family)
+    {
+        if (!(model >= 0x30 && model <= 0x3F))
+        {
+            printk(KERN_WARNING "pcore: Unsupported model 0x%x for family 0x%x \n", model, family);
+            return -EACCES;
+        }
+    }
+
+    /*
+    4. TODO: AMD dGPU on a non AMD platforms SHOULD be supported.
+    5. If SMU is not avaliabe support only Core Counters/ MSR's.
+    6. If BAPM is disabled - Enable/ Disable through BIOS messages.
+    7. If iGPU is disabled same as #5.
+    */
+
+    return 0;
+}
+
+// Get the current core id
+uint32 GetCurrentCoreId(void)
+{
+    int cpu = get_cpu();
+    put_cpu();
+    return (uint32)cpu;
+}
+
+// Get number of control unit present in a node.
+uint32 GetCuCountPerNode(void)
+{
+    // D18F5x80 gives the CU count
+    uint bus = 0U;
+    uint device = 0x18U;
+    uint function = 0x5U;
+    uint reg = 0x80U;
+
+    uint cuStatus = 0U;
+
+    cuStatus = ReadPCIDev(bus, device, function, reg);
+
+    return (cuStatus & 0x1U) + ((cuStatus >> 1) & 0x1U);
+}
+
+void PwrSetExtendedApicId(TARGET_SYSTEM_INFO* pTargetInfo)
+{
+    cpumask_t* pMask = NULL;
+
+    pMask = kmalloc(sizeof(cpumask_t), GFP_KERNEL);
+
+    if ((NULL != pMask) && (1 == pTargetInfo->m_isZen))
+    {
+        uint32 cores = 0;
+        uint32 cpu = 0;
+        uint64 mask[PWR_CORE_MASK_SIZE];
+
+        memset(mask, 0, sizeof(uint64) * PWR_CORE_MASK_SIZE);
+        cores = GetTargetCoreCount();
+
+        if (cores < PWR_CORE_MASK_BITS_COUNT)
+        {
+            mask[0] = ~0ULL ^ (~0ULL << cores);
+        }
+        else
+        {
+            uint32 maxArrSize = 0;
+            uint64 resetBits = 0;
+            uint32 idx = 0;
+
+            // Find the mask array size
+            for (maxArrSize = 2; maxArrSize < PWR_CORE_MASK_SIZE; maxArrSize++)
+            {
+                if (cores <= (PWR_CORE_MASK_BITS_COUNT * maxArrSize))
+                {
+                    break;
+                }
+            }
+
+            for (idx = 0; idx < (maxArrSize - 1); idx++)
+            {
+                mask[idx] = ~0ULL;
+            }
+
+            resetBits = (maxArrSize * PWR_CORE_MASK_BITS_COUNT) - cores;
+            mask[maxArrSize - 1] = ~0ULL >> resetBits;
+        }
+        // Prepare cpu m_affinity mask structure for the configured core mask
+        cpumask_clear(pMask);
+        PrepareAffinityMask(pMask, mask);
+
+        cpu = get_cpu();
+        put_cpu();
+
+        if (cpumask_test_cpu(cpu, pMask))
+        {
+            PwrCoreDpc(pTargetInfo->m_zen.m_apic);
+        }
+
+        preempt_disable();
+        smp_call_function_many(pMask,
+                               (void*)PwrCoreDpc,
+                               (void*)pTargetInfo->m_zen.m_apic,
+                               true); // blocking call
+        preempt_enable();
+        PrepareApicList(pTargetInfo);
+    }
+}
+#endif
+
+void IRPerfDpc(void* info)
+{
+    uint32 msr = HWCF;
+    uint64 value = 0;
+    bool irPerfEn = false;
+
+    value = ReadMSR(msr);
+
+    irPerfEn = (0ULL != (value & HwCfgIRPerfEn)) ? true : false;
+
+    if (!irPerfEn)
+    {
+        value |= HwCfgIRPerfEn;
+        WriteMSR(msr, value);
+    }
+}
+
+bool EnableIRPerf(PTARGET_SYSTEM_INFO pTargetInfo)
+{
+    bool ret = false;
+    bool isIRPerfAvailable = false;
+    uint32 ebxOffset = PwrReadCpuId(PWR_ECX_OFFSET, CPUID_FnSizeID);
+    uint32 coreId = 0;
+
+    isIRPerfAvailable = (0 != ((ebxOffset >> 1) & 0x1));
+
+    if ((NULL != pTargetInfo) && isIRPerfAvailable)
+    {
+        for (coreId = 0; coreId < pTargetInfo->m_zen.m_totalThreads; coreId++)
+        {
+#if defined(_WIN32)
+            DeferedCoreExecution(coreId, (void*)IRPerfDpc, NULL);
+#endif
+
+#if defined (__linux__)
+            smp_call_function_single((int)coreId,
+                                     (smp_call_func_t)IRPerfDpc, NULL, true); // blocking call
+#endif
+        }
+
+        ret = true;
+    }
+
+    return ret;
+}
+
+// Note: Call this function once APIC IDs have been populated
+void PwrSetExtPerfMonAndDbgInfo(TARGET_SYSTEM_INFO* pTargetInfo)
+{
+    DRVPRINT("PwrSetExtPerfMonAndDbgInfo");
+
+    if ((NULL != pTargetInfo)
+        && (1 == pTargetInfo->m_isZen))
+    {
+        uint32 coreId = 0;
+        uint32 socketId = 0;
+        int32_t socketCoreArray[PWR_MAX_SOCKET_COUNT];
+
+        memset(socketCoreArray, -1, PWR_MAX_SOCKET_COUNT * sizeof(int32_t));
+
+        for (coreId = 0; coreId < pTargetInfo->m_zen.m_totalThreads; coreId++)
+        {
+            socketId = pTargetInfo->m_zen.m_apic[coreId].m_nodeId;
+
+            if ((socketId < PWR_MAX_SOCKET_COUNT) && (socketCoreArray[socketId] < 0))
+            {
+                socketCoreArray[socketId] = (int32_t)coreId;
+            }
+        }
+
+        for (socketId = 0; socketId < PWR_MAX_SOCKET_COUNT; socketId++)
+        {
+            if (socketCoreArray[socketId] >= 0)
+            {
+#if defined(_WIN32)
+                DeferedCoreExecution(static_cast<uint32>(socketCoreArray[socketId]),
+                                     PwrExtPerfMonAndDbgInfoDpc, &(pTargetInfo->m_zen.m_perfMonInfo[socketId]));
+#endif
+#if defined (__linux__)
+                smp_call_function_single(socketCoreArray[socketId], (smp_call_func_t)PwrExtPerfMonAndDbgInfoDpc,
+                                         (void*) & (pTargetInfo->m_zen.m_perfMonInfo[socketId]), true);
+#endif
+            }
+        }
+    }
+}
+
+void InitStatus(void)
+{
+    SetMsrStatus();
+}
+
+bool IsExtApicIsAvailable(void)
+{
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, CPUID_FnAmdExtendedFeatures);
+    result = (0 != (aCPUInfo[PWR_ECX_OFFSET] & CPUID_MASK_TOPO_EXTN));
+
+    return result;
+}
+
+bool IsExtnTopology(void)
+{
+    int32 aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUIDEx(aCPUInfo, CPUID_FnExtendedTopology, 0);
+
+    return (aCPUInfo[PWR_EBX_OFFSET] != 0);
+}
+
+uint32 CoreMaskWidth(void)
+{
+    int32 aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUIDEx(aCPUInfo, CPUID_FnExtendedTopology, 1);
+    return (aCPUInfo[PWR_EAX_OFFSET] & 0x1f);
+}
+
+uint32 ThreadsPerCcx(void)
+{
+    int32 aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUIDEx(aCPUInfo, CPUID_FnCacheProperties, 3);
+    return (((aCPUInfo[PWR_EAX_OFFSET] >> 14) & 0xFFF) + 1);
+}
+
+bool IsIrPerfAvailable(void)
+{
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, CPUID_FnSizeIdentifiers);
+    result = (0 != ((aCPUInfo[PWR_EBX_OFFSET] >> 1) & 0x1));
+
+    return result;
+}
+
+bool IsRootPartition(void)
+{
+    bool result = false;
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+
+    ReadCPUID(aCPUInfo, CPUID_FnHyperVFeature);
+    result = (aCPUInfo[PWR_EBX_OFFSET] & 1) ? true : false;
+
+    return result;
+}
+
+// IsAMDPlatform
+bool IsAMDPlatform(void)
+{
+    char vendorId[20];
+    bool result = false;
+    uint32 data = PwrReadCpuId(PWR_EBX_OFFSET, 0);
+    memcpy(vendorId, &data, 4);
+    data = PwrReadCpuId(PWR_EDX_OFFSET, 0);
+    memcpy(vendorId + 4, &data, 4);
+    data = PwrReadCpuId(PWR_ECX_OFFSET, 0);
+    memcpy(vendorId + 8, &data, 4);
+    vendorId[12] = '\0';
+
+    if (0 == strcmp(vendorId, "AuthenticAMD"))
+    {
+        result = true;
+    }
+
+    return result;
+}
+
+// IsRAPLAvailable: Check is RAPL counters are available
+// Available only on family17
+bool IsRAPLAvailable()
+{
+    bool result = false;
+    uint32 data = PwrReadCpuId(PWR_EDX_OFFSET, CPUID_FnAdvancePowerManagementInfo);
+    result = (data & CPUID_FnFeatureRapl) != 0;
+    return result;
+}
+
+// PwrIsHyperVisor: check if hypervisor is enabled
+bool IsHyperVisor()
+{
+    bool result = false;
+    uint32 data = PwrReadCpuId(PWR_ECX_OFFSET, CPUID_FnBasicFeatures);
+    result = (0 != (data & CPUID_HypervisorMask));
+    return result;
+}
+
+bool IsHost(void)
+{
+    return !IsHyperVisor() || IsRootPartition();
+}
+
diff --git a/drivers/powerprofiler/src/PwrOsPrimitives.c b/drivers/powerprofiler/src/PwrOsPrimitives.c
new file mode 100644
index 000000000000..ac09c5235898
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrOsPrimitives.c
@@ -0,0 +1,597 @@
+//==================================================================================
+// Copyright (c) 2020 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrOsPrimitives.c
+///
+//==================================================================================
+// SYSTEM INCLUDES
+#include <asm/io.h>
+#include <linux/delay.h>
+#include <linux/fs.h>
+#include <linux/interrupt.h>
+#include <linux/list.h>
+#include <linux/smp.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/version.h>
+#include <linux/ktime.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 17, 0)
+    #include <linux/timekeeping.h>
+#endif
+
+// PROJECT INCLUDES
+#include <PwrOsPrimitives.h>
+#include <PwrDriverTypedefs.h>
+#include <PwrDriverUtils.h>
+#include <PwrProfAsm.h>
+#include <PwrProfCpuid.h>
+
+// LOCAL DEFINES
+#define PCI_ADDR_PORT       0xCF8
+#define PCI_DATA_PORT       0xCFC
+MemoryPool g_sessionPool;
+static MsrStatus g_msrStatus;
+
+typedef struct CoreContextInfo
+{
+    void*  m_pContext;
+    void*  m_pCallback;
+    uint32 m_core;
+} CoreContextInfo;
+
+void SetMsrStatus(void)
+{
+    int aCPUInfo[PWR_NUM_CPUID_OFFSETS] = { -1 };
+    ReadCPUID(aCPUInfo, CPUID_FnSizeID);
+    g_msrStatus.m_isIrperf = (0 != ((aCPUInfo[1] >> 1) & 0x1));
+    ReadCPUID(aCPUInfo, CPUID_FnAdvancePowerManagementInformation);
+    g_msrStatus.m_isRapl= (0 != ((aCPUInfo[3] >> 14) & 0x1));
+
+    if (IsROCefAvailable() || IsCefSupported())
+    {
+        g_msrStatus.m_isMperf = g_msrStatus.m_isAperf = 1;
+    }
+}
+
+bool static IsValidMsr(uint32 reg)
+{
+    bool ret = false;
+
+    switch(reg)
+    {
+        // IRPERF
+        case 0xC00000E9:
+            ret = g_msrStatus.m_isIrperf;
+            break;
+
+        // MPERF
+        case 0x000000E7:
+            ret = g_msrStatus.m_isMperf;
+            break;
+        // read-only MPERF
+        case 0xC00000E7:
+            ret = g_msrStatus.m_isMperf;
+            break;
+
+        // APERF
+        case 0x000000E8:
+            ret = g_msrStatus.m_isAperf;
+            break;
+        // read-only APERF
+        case 0xC00000E8:
+            ret = g_msrStatus.m_isAperf;
+            break;
+
+
+        case 0xC001029A:
+        case 0xC001029B:
+            ret = g_msrStatus.m_isRapl;
+            break;
+
+        default:
+            // TODO: Need to check other MSRs from the list
+            ret = true;
+            break;
+    }
+
+    return ret;
+}
+
+// Memory pull functions is not done common as the way memory is allocated in
+// Windows and linux are different
+// Create memory pool
+bool CreateMemoryPool(MemoryPool* pPool, uint32 size)
+{
+    bool ret = false;
+
+    if (NULL != pPool)
+    {
+        pPool->m_pBase = (uint8*)kmalloc(size, GFP_KERNEL);
+
+        if (NULL != pPool->m_pBase)
+        {
+            pPool->m_offset = 0;
+            pPool->m_size = size;
+            ret = true;
+        }
+    }
+
+    return ret;
+}
+
+// Get buffer from the memory pool
+uint8* GetMemoryPoolBuffer(MemoryPool* pPool, uint32 size)
+{
+    uint8* pBuffer = NULL;
+
+    if ((NULL == pPool) || ((pPool->m_offset + size) > pPool->m_size))
+    {
+        pBuffer = NULL;
+    }
+    else
+    {
+        pBuffer = pPool->m_pBase + pPool->m_offset;
+        pPool->m_offset += size;
+    }
+
+    return pBuffer;
+}
+
+// Delete the memory pool
+bool ReleaseMemoryPool(MemoryPool* pPool)
+{
+    bool ret = false;
+
+    if (NULL != pPool)
+    {
+        if (NULL != pPool->m_pBase)
+        {
+            kfree(pPool->m_pBase);
+            pPool->m_pBase = NULL;
+            ret = true;
+        }
+    }
+
+    return ret;
+}
+
+void* AllocateMemory(uint32_t size)
+{
+    // ToDo: Add flags to arguemnt?
+    return kmalloc((size_t)size, GFP_KERNEL);
+}
+
+void FreeMemory(void* obj)
+{
+    kfree(obj);
+}
+
+// Read CPU id.
+void readCPUID(uint32 index, uint32 index2, uint32* peax, uint32* pebx, uint32* pecx, uint32* pedx)
+{
+    uint32 a = 0;
+    uint32 b = 0;
+    uint32 c = 0;
+    uint32 d = 0;
+    asm(
+        "cpuid\n\t"
+        :"=b"(b),
+        "=d"(d),
+        "=c"(c),
+        "=a"(a)
+        :"a"(index), "c"(index2)
+    );
+    /*asm
+      ("cpuid" : "=a" (a), "=b" (b), "=c" (c), "=d" (d)
+       : "a" (index), "c" (index2));*/
+    DRVPRINT("cpuid a=%u, b=%u, c=%u,d =%u \n", a, b, c, d);
+
+    if ((NULL != peax) || (NULL != pebx) || (NULL != pecx) || (NULL != pedx))
+    {
+        *peax = a;
+        *pebx = b;
+        *pecx = c;
+        *pedx = d;
+    }
+    else
+    {
+        DRVPRINT("NULL POINTER");
+    }
+}
+
+// Read CPU id.
+void ReadCPUID(int32* pInfo, uint32 indentifier)
+{
+    if (NULL != pInfo)
+    {
+        readCPUID(indentifier, 0, &pInfo[PWR_EAX_OFFSET], &pInfo[PWR_EBX_OFFSET], &pInfo[PWR_ECX_OFFSET], &pInfo[PWR_EDX_OFFSET]);
+    }
+}
+
+// Read extended CPU id.
+void ReadCPUIDEx(int32* pInfo, uint32 indentifier, uint32 sub)
+{
+    if (NULL != pInfo)
+    {
+        readCPUID(indentifier, sub, &pInfo[PWR_EAX_OFFSET], &pInfo[PWR_EBX_OFFSET], &pInfo[PWR_ECX_OFFSET], &pInfo[PWR_EDX_OFFSET]);
+    }
+}
+
+// Map MMIO space
+bool MapMMIOSpace(
+    uint64  address,         // IN
+    size_t  size,            // IN
+    uint64* mappedAddress,   // OUT
+    uint64* mappedSize)      // OUT
+{
+    bool result = true;
+    *mappedAddress = (uint64)ioremap(address, size);
+    *mappedSize = size;
+    return result;
+}
+
+// Unmapping MMIO space
+bool UnmapMMIOSpace(uint64 mappedAddress, uint64 mappedSize)
+{
+    bool result = true;
+    iounmap((void*)mappedAddress);
+    return result;
+}
+
+// Read from MSR
+uint64 ReadMSR(uint32 index)
+{
+    uint64 result = 0;
+    uint64_t password = 0;
+    uint32 value[2];
+    uint32* pPwHalfs = (uint32*)(&password);
+
+    if(IsValidMsr(index))
+    {
+        rdmsrpw(index, value[0], value[1], pPwHalfs[0], pPwHalfs[1]);
+        result = value[1];
+        result = (result << 32) | value[0];
+        //DRVPRINT("Thread %d addr 0x%x , value %llx \n", GetCurrentCoreId(), index, result);
+    }
+    else
+    {
+        DRVPRINT("Error: Msr not available 0x%x\n", index);
+    }
+
+    return result;
+}
+
+// Write to MSR
+void WriteMSR(uint32 index, uint64 value)
+{
+    uint64_t password = 0;
+    uint32* pHalfs = (uint32*)(&value);
+    uint32* pPwHalfs = (uint32*)(&password);
+    //DRVPRINT("Thread %d addr 0x%x , value %llu \n", GetCurrentCoreId(), index, value);
+    wrmsrpw(index, pHalfs[0], pHalfs[1], pPwHalfs[0], pPwHalfs[1]);
+}
+
+// Read data from the specified MMIO address
+uint32 ReadMMIO(uint32 addr, uint64_t* val, bool map)
+{
+    uint32 byteCount ;
+    void __iomem* virtualAddress;
+    uint32* p;
+    byteCount = 4;
+    DRVPRINT(" READMMIO addr 0x%x \n ", addr);
+
+    if (map)
+    {
+        if ((virtualAddress = ioremap(addr, byteCount)) == NULL)
+        {
+            DRVPRINT(" ioremap failed \n");
+            return STATUS_INVALID_PARAMETER;
+        }
+    }
+    else
+    {
+        p = &addr;
+        virtualAddress = (void*)p;
+    }
+
+    DRVPRINT(" READMMIO virtual address %p \n", virtualAddress);
+
+    if (virtualAddress)
+    {
+        *(uint32*)val = read_dword(virtualAddress);
+
+        if (map)
+        {
+            iounmap(virtualAddress);
+        }
+
+        return STATUS_SUCCESS;
+    }
+
+    printk(" WARNING , Invalid MMOIO Address \n");
+    return STATUS_INVALID_PARAMETER;
+}
+
+// Write data to the specified MMIO address
+uint32 WriteMMIO(uint32 addr, uint32 data, bool map)
+{
+    uint32 byteCount;
+    void* virtualAddress ;
+    uint32* p;
+    DRVPRINT(" WRITEMMIO addr %x, data %u \n ", addr, data);
+    byteCount = 4;
+
+    if (map)
+    {
+        virtualAddress = ioremap(addr, byteCount);
+    }
+    else
+    {
+        p = &addr;
+        virtualAddress = (void*)p;
+    }
+
+    DRVPRINT(" WRITEMMIO virtual address %p \n ", virtualAddress);
+
+    if (virtualAddress != NULL)
+    {
+        //write_dword( virtualAddress, *(uint32 *)pData );
+        iowrite32(data, virtualAddress);
+
+        if (map)
+        {
+            iounmap(virtualAddress);
+        }
+
+        return STATUS_SUCCESS;
+    }
+
+    return STATUS_INVALID_PARAMETER;
+}
+
+void AccessPciExt(uint32 addr, uint32* pData, bool isRead)
+{
+    bool testRes = true;
+    unsigned long value = 0;
+    unsigned long iosize = 4;
+    unsigned long baseAddr = 0;
+    uint64 readAddr = 0;
+    uint64 offset = 0;
+    void __iomem* virtualAddress = NULL;
+    baseAddr = ReadMSR(MCFG_BASE_ADDRESS);
+    baseAddr = baseAddr & 0xffffffff00000;
+
+    // Device(5)|Function(3)|Register(11)
+    offset = (addr & 0xFF) | ((addr & 0xF000000) >> 16) // Register(12)
+                | ((addr & 0x700ULL) << 8) // Function(3)
+                | ((addr & 0xF800ULL) << 4); // Device(5)
+
+    readAddr = baseAddr + offset;
+    //DRVPRINTERROR("INFO: offset(0x%llx) MMIO base(0x%llx) readAddr(0x%llx)", offset, baseAddr, readAddr);
+
+    virtualAddress = ioremap(readAddr, iosize);
+
+    if (isRead)
+    {
+        if (!(void*)(virtualAddress))
+        {
+            DRVPRINT("Error: failed to map MMIO range\n");
+            testRes = false;
+        }
+
+        if (testRes == true)
+        {
+            DRVPRINT("Info: map_ioaddr: 0x%lx\n", (unsigned long) virtualAddress);
+            value = read_dword(virtualAddress);
+            DRVPRINT("Info: data readb=%lx\n", value);
+            *pData = value;
+        }
+        else
+        {
+            testRes = false;
+            DRVPRINT("Error: request_mem_region failed 0x%lx", value);
+        }
+    }
+    else
+    {
+        DRVPRINT("Error: Extended PCIe read not implemented");
+    }
+}
+
+// Read data from the specified PCI configuration address
+uint32 ReadPCI(uint32 addr)
+{
+    uint32 val = 0;
+    uint32 regAddr = (addr & 0xFF) | ((addr & 0xF000000) >> 16);
+    // DRVPRINT("Info: ReadPCI addr 0x%x regAddr 0x%x\n", addr, regAddr);
+    if (regAddr <= 0xFF)
+    {
+        outl(addr, PCI_ADDR_PORT);
+        val = inl(PCI_DATA_PORT);
+    }
+    else
+    {
+        AccessPciExt(addr, &val, true);
+    }
+
+    return val;
+}
+
+// Write data to the specified PCI configuration address
+void WritePCI(uint32 addr, uint32 data)
+{
+    uint32 regAddr = (addr & 0xFF) | ((addr & 0xF000000) >> 16);
+
+    if (regAddr <= 0xFF)
+    {
+        outl(addr, PCI_ADDR_PORT);
+        outl(data, PCI_DATA_PORT);
+    }
+    else
+    {
+        //uint32 writeData = (uint32)data;
+        //AccessPciExt(addr, &writeData, true);
+    }
+}
+
+// Write data to PCI32  address space.
+void WritePCI32(uint32 address, uint32 data, uint32 mask)
+{
+    uint32 old_address;
+    uint32 current_data;
+    // Save previous address
+    old_address = inl(PCI_ADDR_PORT);
+    // Set new address
+    outl(PCI_ADDR_PORT, address);
+    // Read current data
+    current_data = inl(PCI_DATA_PORT);
+    // Clear bits we're going to change
+    current_data &= (mask);
+    // Add new data bits
+    current_data |= (data);
+    // Write data back
+    outl(PCI_DATA_PORT, current_data);
+    // Restore previous address
+    outl(PCI_ADDR_PORT, old_address);
+}
+
+uint32 GetOnlineCpus(void)
+{
+    return  num_online_cpus();
+}
+
+/* Note: For use in interrupt context only or when
+ * it is certain that preemption is disabled */
+int GetCoreId()
+{
+    return smp_processor_id();
+}
+
+/* Note: Maximum number of cpus supported ?? */
+int GetCoreCount()
+{
+    return nr_cpu_ids;
+}
+
+void PrepareAffinityMask(cpumask_t* pm_affinity, uint64 mask[])
+{
+    uint32 idx = 0;
+    unsigned long int coreMask = 0;
+    uint32 core = 0;
+
+    for (idx = 0; idx < PWR_CORE_MASK_SIZE; ++idx)
+    {
+        coreMask = mask[idx];
+
+        for_each_set_bit(core, &coreMask, PWR_CORE_MASK_BITS_COUNT)
+        {
+            cpumask_set_cpu((idx * PWR_CORE_MASK_BITS_COUNT) + core, pm_affinity);
+        }
+    }
+}
+
+static void DeferredCoreCb(void* pContext)
+{
+    if (NULL != pContext)
+    {
+        CoreContextInfo* pInfo = (CoreContextInfo*) pContext;
+        DRVPRINT("Thread %d actual %d", pInfo->m_core, GetCurrentCoreId());
+
+        if ((NULL != pInfo) && (NULL != pInfo->m_pCallback) && (NULL != pInfo->m_pContext))
+        {
+            ((void(*)(void*))pInfo->m_pCallback)((void*)pInfo->m_pContext);
+        }
+    }
+}
+
+// DeferedCoreExecution: Execute DPC. This funcion can be used if a particular access
+// needs to be done from a specific core context. In case of Linux it may not be a good idea
+// if we want to use this function to get all core context. Instead we can set the mask
+// and use smp_call_function_many.
+bool DeferedCoreExecution(uint32 core, void* pRoutine, void* pContext)
+{
+    cpumask_t* pMask = NULL;
+    uint32 cpu = 0;
+    uint64 mask[PWR_CORE_MASK_SIZE];
+    CoreContextInfo coreContext;
+    coreContext.m_pCallback = pRoutine;
+    coreContext.m_pContext = pContext;
+    coreContext.m_core = core;
+    pMask = kmalloc(sizeof(cpumask_t), GFP_KERNEL);
+
+    memset(mask, 0, sizeof(uint64) * PWR_CORE_MASK_SIZE);
+    mask[core / PWR_CORE_MASK_BITS_COUNT] = (1 << (core % PWR_CORE_MASK_BITS_COUNT));
+
+    // Prepare cpu m_affinity mask structure for the configured core mask
+    cpumask_clear(pMask);
+    PrepareAffinityMask(pMask, mask);
+
+    cpu = get_cpu();
+    put_cpu();
+
+    // Check if the requested core is the current core
+    if ((core == cpu) && cpumask_test_cpu(cpu, pMask))
+    {
+        DeferredCoreCb(&coreContext);
+    }
+    else
+    {
+        preempt_disable();
+        smp_call_function_many(pMask, (void*)DeferredCoreCb, (void*)&coreContext, true);
+        preempt_enable();
+    }
+
+    return true;
+}
+
+int ExecuteOnCore(int coreId, void* pFunc, void* arg)
+{
+    return smp_call_function_single(coreId, (smp_call_func_t)pFunc, arg, true);
+}
+
+void GetPerformanceCounter(uint64* perfCounter, uint64* freq)
+{
+    *perfCounter = ktime_to_ns(ktime_get());
+    *freq = 1;
+}
+
+// Get current time from thr kernel
+void GetTimeStamp(uint64* ts)
+{
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(4, 19, 29)
+    struct timespec now = current_kernel_time();
+#else
+    struct timespec64 now;
+    ktime_get_coarse_real_ts64(&now);
+#endif
+
+    // return value in mill-seconds
+    *ts = (now.tv_sec * 1000 + now.tv_nsec / 1000000);
+}
+
+// Currently this API is UNUSED and needed only for Power APP Analysis on Windows
+// AcquirePCMCountersLock: Check if PMC counters are available
+bool AcquirePCMCountersLock()
+{
+    return true;
+}
+
+// Currently this API is UNUSED and needed only for Power APP Analysis on Windows
+// ReleasePCMCountersLock: Release if PMC counters are acquired
+bool ReleasePCMCountersLock()
+{
+    return true;
+}
+
+/* Get timestamp in nanoseconds */
+uint64_t GetTimestamp()
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 17, 0)
+    return ktime_to_ns(ktime_get());
+#else
+    return ktime_get_ns();
+#endif
+}
diff --git a/drivers/powerprofiler/src/PwrProfDebugHelper.c b/drivers/powerprofiler/src/PwrProfDebugHelper.c
new file mode 100644
index 000000000000..df30db66bd18
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrProfDebugHelper.c
@@ -0,0 +1,67 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfDebugHelper.c
+///
+//==================================================================================
+#ifdef DEBUG
+#include <PwrProfInternal.h>
+#include <PwrDriverUtils.h>
+#include <PwrOsPrimitives.h>
+#include <PwrDriverTypedefs.h>
+
+// PrintPageBuffer
+//
+// Print PageBuffer Data structure
+void PrintPageBuffer(const PageBuffer* pPageBuffer)
+{
+    if (NULL != pPageBuffer)
+    {
+        DRVPRINT("Printing Page Buffer ....");
+        DRVPRINT("      Rec Count       : %llu ", pPageBuffer->m_recCnt);
+        DRVPRINT("      Current Offset  : %d ", ATOMIC_GET(&pPageBuffer->m_currentOffset, pPageBuffer->m_currentOffset));
+        DRVPRINT("      Consumed Offset : %d ", ATOMIC_GET(&pPageBuffer->m_consumedOffset, pPageBuffer->m_consumedOffset));
+    }
+}
+
+// PrintClientData
+//
+// Printing Client Data
+void PrintClientData(const ClientData* pClientData)
+{
+    if (NULL != pClientData)
+    {
+        DRVPRINT(" Client Id                : %d ", pClientData->m_clientId);
+        DRVPRINT(" Offline m_recCnt         : %d ", pClientData->m_isOffline);
+        DRVPRINT(" Configure count          : %d ", pClientData->m_configCount);
+        DRVPRINT(" Profile State            : %d ", pClientData->m_profileState);
+        PrintPageBuffer(&pClientData->m_header);
+        DRVPRINT(" OsClientCfg ");
+        DRVPRINT("          Affinity        : %d ",  1);
+        DRVPRINT("          Paused          : %d ", pClientData->m_osClientCfg.m_paused);
+        DRVPRINT("          Stopped         : %d ", pClientData->m_osClientCfg.m_stopped);
+        DRVPRINT("          Parent Id       : %d ", pClientData->m_osClientCfg.m_parentPid);
+    }
+}
+
+// PrintCoreData
+//
+// Printing Core Data
+void PrintCoreData(const CoreData* pCoreData)
+{
+    if (NULL != pCoreData)
+    {
+        DRVPRINT("Client ID : %d ", pCoreData->m_clientId);
+        DRVPRINT("Sample ID : %d ", pCoreData->m_sampleId);
+        DRVPRINT("Profile Type : %d ", pCoreData->m_profileType);
+        DRVPRINT("Sampling Interval : %d ", pCoreData->m_samplingInterval);
+        DRVPRINT("Record Length : %d ", pCoreData->m_recLen);
+        DRVPRINT(" Core ID : %d ", pCoreData->m_coreId);
+        DRVPRINT(" Process ID : %d ", pCoreData->m_contextData.m_processId);
+        DRVPRINT(" Thread ID : %d ", pCoreData->m_contextData.m_threadId);
+        DRVPRINT("TimeStamp : %llu ", pCoreData->m_contextData.m_timeStamp);
+        PrintSmuList(pCoreData->m_smuCfg);
+    }
+}
+#endif // DEBUG
diff --git a/drivers/powerprofiler/src/PwrProfEntry.c b/drivers/powerprofiler/src/PwrProfEntry.c
new file mode 100644
index 000000000000..68e4a31934da
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrProfEntry.c
@@ -0,0 +1,1216 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfEntry.c
+///
+//==================================================================================
+// PROJECT INCLUDES
+#include <linux/uaccess.h>
+#include <linux/slab.h>
+
+#include <PwrDriverTypedefs.h>
+#include <PwrDriverIoctls.h>
+
+// LOCAL INCLUDES
+#include <PwrOsPrimitives.h>
+#include <PwrDriverUtils.h>
+#include <PwrCommonDataTypes.h>
+#include <PwrVersion.h>
+#include <PwrProfSharedMemOps.h>
+#include <PwrProfTimer.h>
+#include <PmcInterface.h>
+#include <PmcProcessConfig.h>
+
+// LOCAL VARIABLES
+//
+
+// EXTERN FUNCTIONS
+long CheckHwSupport(void);
+extern int moduleState;
+
+//LOCAL FUNCTIONS
+void DeleteClient(void);
+void MarkClientForCleanup(unsigned long id);
+int RegisterClient(ClientType type, uint32_t* pClientId);
+int UnregisterClient(uint32_t clientId);
+int StartProfiler(uint32_t clientId);
+int ClearProfiler(uint32_t clientId);
+long PwrProfDrvIoctlImpl(struct file* file, unsigned int ioctl_num, unsigned long ioctl_param);
+void PwrProfDrvCleanup(void);
+long CheckPwrProfHwSupport(void);
+void GetVersions(unsigned int* major, unsigned int* minor, unsigned int* build);
+int StopProfiler(uint32_t clientId);
+bool CheckValidState(PwrProfState state);
+// STATIC VARIABLES
+// Minor build version for pcore
+static unsigned int pcore_build_number = 001;
+
+// Client id and state
+static unsigned long g_clientId = 0L;
+static bool g_isClientActiv = false;
+static bool g_isClientStateDirty  = false;
+
+// ToDo: Initialize to INVALID_CLIENT_ID for all clients
+static int32_t g_pmcClientId = INVALID_CLIENT_ID;
+
+ClientContext* g_pPmcClientContext = NULL;
+static GroupBuffer g_groupBuffer;
+
+static PwrProfState g_currState = PWR_UNCONFIGURED;
+static ClientType g_clientType = CLIENT_TYPE_INVALID;
+
+static unsigned int g_StateMap[PWR_STATE_MAX] =
+{
+    [PWR_UNCONFIGURED] = (1 << PWR_STOPPED) | (1 << PWR_REGISTERED),
+    [PWR_REGISTERED] = (1 << PWR_CONFIGURED) | (1 << PWR_STOPPED),
+    [PWR_CONFIGURED] = (1 << PWR_CONFIGURED) | (1 << PWR_RUNING) | (1 << PWR_STOPPED),
+    [PWR_RUNING] = (1 << PWR_PAUSED) | (1 << PWR_STOPPED),
+    [PWR_PAUSED] = (1 << PWR_RUNING) | (1 << PWR_STOPPED),
+    [PWR_STOPPED] = (1 << PWR_UNCONFIGURED)
+};
+
+static WhitelistedMsrInfo g_msrListPreZen4[] =
+{
+#include <MsrList.h>
+};
+
+static WhitelistedMsrInfo g_msrListZen4[] =
+{
+#include <MsrListZen4.h>
+};
+// LOCAL FUNCTIONS
+
+//check whether the state transition is valid or not.
+bool CheckValidState(PwrProfState state)
+{
+    int validStates = g_StateMap[g_currState];
+
+    return ((1 << state) & validStates);
+}
+
+// delete the client from the client list
+// ToDo: This function should take clientId as parameter or
+// delete all clients
+void DeleteClient(void)
+{
+    g_isClientActiv = false;
+    g_clientId = 0;
+    UnconfigureTimer(g_clientId);
+
+    // Release memory pool
+    ReleaseMemoryPool(&g_sessionPool);
+}
+
+// Mark the client for cleanup.
+// ToDo: Does this function clean up instead of marking for clean up?
+void MarkClientForCleanup(unsigned long id)
+{
+    if (id == g_clientId)
+    {
+        // Stop the timer
+        StopTimer(g_clientId);
+
+        g_isClientActiv         = false;
+        g_isClientStateDirty    = true;
+        moduleState             = 0;
+    }
+    else
+    {
+        DRVPRINTERROR("Error: Power Profiler: Incorrect Client id. \n");
+    }
+}
+
+int RegisterClient(ClientType type, uint32_t* pClientId)
+{
+    int retVal = 0;
+
+    DRVPRINT("type(%d) clientId(%p)", type, pClientId);
+
+    if (pClientId == NULL)
+    {
+        DRVPRINTERROR("pClientId == NULL");
+        retVal = ERROR_PMC_REGISTER_NULL_CLIENT;
+    }
+
+    if (!retVal)
+    {
+        if (type == CLIENT_TYPE_PMC)
+        {
+            if (g_pmcClientId != INVALID_CLIENT_ID)
+            {
+                DRVPRINTERROR("Error: Max one client permitted.g_pmcClientId (%d)", g_pmcClientId);
+                retVal = ERROR_PMC_REGISTER_INVALID_CLIENT;
+            }
+            else
+            {
+                /* Note: Since we support a single client
+                 * for Pmc, hardcoding the id for now */
+                g_pmcClientId = PMC_CLIENT_ID;
+                *pClientId = g_pmcClientId;
+
+                retVal = AllocateClientContext(*pClientId);
+            }
+        }
+        else if (type == CLIENT_TYPE_PWR_PROFILER)
+        {
+            if (g_isClientActiv)
+            {
+                DRVPRINTERROR("Power Profiler: Max one instance of Power Profiler client run permitted. ");
+                retVal = ERROR_PWR_REGISTER_INVALID_CLIENT;
+            }
+
+            g_isClientActiv = true;
+            *pClientId = g_clientId;
+        }
+        else
+        {
+            DRVPRINTERROR("Invalid client type(%d)", type);
+            retVal = ERROR_PWR_REGISTER_INVALID_TYPE;
+        }
+    }
+
+    if(!retVal)
+    {
+        InitStatus();
+    }
+
+    DRVPRINT("clientId(%lu) retVal(0x%x)", (unsigned long int)*pClientId, retVal);
+
+    return retVal;
+}
+
+int UnregisterClient(uint32_t clientId)
+{
+    int retVal = 0;
+    int clientState = 0;
+
+    DRVPRINT("Unregister start: clientId(%lu)", (unsigned long int)clientId);
+
+    if (clientId == PMC_CLIENT_ID)
+    {
+        if (NULL != g_pPmcClientContext)
+        {
+            clientState = g_pPmcClientContext->m_clientState;
+
+            if (clientState == PMC_CLIENT_STATE_RUNNING)
+            {
+               DRVPRINTERROR("Warning: Stop initiated again");
+               StopProfiler(clientId);
+            }
+
+            if (clientState == PMC_CLIENT_STATE_STOP_INITIATED)
+            {
+                DRVPRINTERROR("Error: Stop is in progress already");
+                retVal =  ERROR_PMC_INVALID_STATE;
+            }
+
+            if (!retVal && (clientState != PMC_CLIENT_STATE_STOPPED))
+            {
+                DRVPRINTERROR("Error: Not in stopped state. Current state (%d)", clientState);
+                retVal = ERROR_PMC_INVALID_STATE;
+            }
+
+            // Cleaning is required if state is in
+            // PMC_CLIENT_STATE_INIT - data structure is being allocated
+            // PMC_CLIENT_STATE_CONFIGURED - data structure is being allocated in previous init
+            // PMC_CLIENT_STATE_STOPPED - profile is stopped gracefully
+            if ((clientState == PMC_CLIENT_STATE_CONFIGURED)
+                || (clientState == PMC_CLIENT_STATE_INIT)
+                || (clientState == PMC_CLIENT_STATE_STOPPED))
+            {
+                if (g_pmcClientId != INVALID_CLIENT_ID)
+                {
+                    FreeClientContext(clientId);
+                    g_pmcClientId = INVALID_CLIENT_ID;
+                    clientState = PMC_CLIENT_STATE_UNKNOWN;
+                }
+                else
+                {
+                     DRVPRINTERROR("Error: Client(%d) already unregistered.", g_pmcClientId);
+                }
+            }
+        }
+        else
+        {
+            DRVPRINTERROR("Error: g_pPmcClientContext is NULL clientState(%d)", clientState);
+        }
+    }
+    else if (clientId == 0)
+    {
+        g_isClientActiv = false;
+        g_clientId = 0;
+
+        DeleteClient();
+    }
+    else
+    {
+        DRVPRINTERROR("Error: Invalid client id(%d) clientState(%d)", clientId, clientState);
+        retVal = ERROR_PMC_INVALID_CLIENTID;
+    }
+
+    DRVPRINTERROR("Unregister done: state (%d) clientId(%x) retVal(0x%x)", clientState, clientId, retVal);
+
+    return retVal;
+}
+
+int StartProfiler(uint32_t clientId)
+{
+    int retVal = 0;
+
+    if (clientId == PMC_CLIENT_ID)
+    {
+        PmcStartProfiler();
+    }
+    else if (clientId == 0)
+    {
+        retVal = StartTimer(clientId);
+    }
+    else
+    {
+        /* Invalid client Id */
+    }
+
+    return retVal;
+}
+
+int StopProfiler(uint32_t clientId)
+{
+    int retVal = 0;
+
+    if (clientId == PMC_CLIENT_ID)
+    {
+        PmcStopProfiler();
+    }
+    else if (clientId == 0)
+    {
+        retVal = StopTimer(clientId);
+    }
+    else
+    {
+        /* Invalid client Id */
+    }
+
+    return retVal;
+}
+
+int ClearProfiler(uint32_t clientId)
+{
+    int retVal = 0;
+
+    if (clientId == PMC_CLIENT_ID)
+    {
+        PmcClearProfiler();
+    }
+    else if (clientId == 0)
+    {
+        // Not used by power profiler
+    }
+    else
+    {
+        /* Invalid client Id */
+    }
+
+    return retVal;
+}
+
+// Register client for both power profiler and pmc profiler
+static int RegisterClientIoctl(ClientType* pClient)
+{
+    int retval  = 0;
+    uint32 clientId = 0;
+    ClientType clientType = CLIENT_TYPE_INVALID;
+    DRVPRINT("In register Client Ioctl");
+
+
+    if (NULL != pClient)
+    {
+        retval = copy_from_user(&clientType, pClient, sizeof(ClientType));
+        //setting the global for clientType while registering which will be needed in PowerStartIoctl.
+        g_clientType = clientType;
+    }
+    else
+    {
+        retval = ERROR_PMC_REGISTER_NULL_CLIENT;
+        DRVPRINTERROR("Error: pClient == NULL");
+    }
+
+    //DRVPRINT("clientType(%d) retval(%d)", clientType, retval);
+
+    if (retval)
+    {
+        DRVPRINTERROR("Error: Failed to get client type. 0x%x", retval);
+    }
+
+
+    if(!retval && (CLIENT_TYPE_PMC != clientType) && !CheckValidState(PWR_REGISTERED))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if (!retval)
+    {
+        retval = RegisterClient(clientType, &clientId);
+
+        if (retval < 0)
+        {
+            DRVPRINTERROR("Error: Failed to register client. 0x%x", retval);
+        }
+    }
+
+    if (!retval)
+    {
+        retval = copy_to_user((uint32_t*)pClient, &clientId, sizeof(uint32_t));
+
+        if (retval < 0)
+        {
+            // if in previous run we have not clean the configuration
+            //  delete the old client config
+            if ((clientId == 0) && (true == g_isClientStateDirty))
+            {
+                // TODO: Assuming only one client id can exist
+                // Clean the old configuration
+                DeleteClient();
+                g_isClientStateDirty = false;
+            }
+
+            DRVPRINTERROR("Error: Failed to set client Id. 0x%x", retval);
+        }
+    }
+
+    if ((CLIENT_TYPE_PMC != clientType) && 0 == retval)
+    {
+        g_currState = PWR_REGISTERED;
+    }
+
+    return retval;
+}
+
+// Unregister client for both power profiler and pmc profiler
+static int UnregisterClientIoctl(uint32_t* pClient)
+{
+    int retval = 0;
+    uint32_t temp = 0;
+    DRVPRINT("In un register Client Ioctl");
+
+    if (NULL != pClient)
+    {
+        retval = copy_from_user(&temp, (uint32_t*)pClient, sizeof(uint32_t));
+    }
+    else
+    {
+        retval = ERROR_PMC_REGISTER_NULL_CLIENT;
+        DRVPRINTERROR("Error: pClient == NULL");
+    }
+
+    if(!retval && (CLIENT_TYPE_PMC != temp) && !CheckValidState(PWR_STOPPED))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if (0 == retval)
+    {
+        DRVPRINT("UnRegistering client %u", temp);
+        retval = UnregisterClient(temp);
+
+        if(retval != 0)
+        {
+            DRVPRINTERROR("Error: Invalid parameter to Unregister Client");
+            retval = ERROR_PWR_UNREGISTER_INVALID_PARAMS;
+        }
+    }
+
+    if((CLIENT_TYPE_PMC != temp) && 0 == retval)
+    {
+        g_currState = PWR_UNCONFIGURED;
+    }
+
+    return retval;
+}
+
+// Pause client for both power profiler and pmc profiler
+static int PauseClientIoctl(uint32_t* pClient)
+{
+    int retval = 0;
+    uint32_t stopClientId = 0;
+    DRVPRINT("In Pause profiler ioctl");
+
+    if (NULL != pClient)
+    {
+        retval = copy_from_user(&stopClientId, (uint32_t*)pClient, sizeof(uint32_t));
+    }
+    else
+    {
+        retval = ERROR_PMC_REGISTER_NULL_CLIENT;
+        DRVPRINTERROR("Error: pClient == NULL");
+    }
+
+
+    if(!retval && (CLIENT_TYPE_PMC != g_clientType) &&!CheckValidState(PWR_PAUSED))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if(0 == retval)
+    {
+        DRVPRINT("Pausing Profile for client %d", stopClientId);
+        retval = PauseTimer(stopClientId);
+
+        if (retval != 0)
+        {
+            retval = ERROR_PWR_PAUSE_COPY;
+            DRVPRINTERROR("Error: Power Profiler: Invalid parameter to Pause Profiler");
+        }
+    }
+
+    if ((CLIENT_TYPE_PMC != g_clientType) && 0 == retval)
+    {
+        g_currState = PWR_PAUSED;
+    }
+
+    return retval;
+}
+
+// Stop client for both power profiler and pmc profiler
+static int StopIoctl(uint32_t* pClient)
+{
+    int retval = 0;
+    uint32_t tempClient = 0;
+    DRVPRINT("In stop profiler ioctl");
+
+    if(NULL != pClient)
+    {
+        retval = copy_from_user(&tempClient, (uint32_t*)pClient, sizeof(uint32_t));
+    }
+    else
+    {
+        retval = ERROR_PMC_REGISTER_NULL_CLIENT;
+        DRVPRINTERROR("Error: pClient == NULL");
+    }
+
+    if(!retval && (CLIENT_TYPE_PMC != tempClient) && !CheckValidState(PWR_STOPPED))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if (0 == retval)
+    {
+        DRVPRINT("Stopping Profile for client %d", tempClient);
+        retval = StopProfiler(tempClient);
+
+        if (retval != 0)
+        {
+            retval = ERROR_PWR_STOP_COPY;
+            DRVPRINTERROR("Error: Power Profiler: Invalid parameter to Stop Profiler");
+        }
+    }
+
+    if ((CLIENT_TYPE_PMC != tempClient) &&  0 == retval)
+    {
+        g_currState = PWR_UNCONFIGURED;
+    }
+
+    return retval;
+}
+
+// Used for power profiler and pmc profiler
+// Not use as of now
+static int PowerResumeIoctl(PROFILER_PROPERTIES* pProf)
+{
+    int retval = 0;
+    PROFILER_PROPERTIES profProps;
+    DRVPRINT("In Resume Profiler Ioctl");
+
+    if(NULL != pProf)
+    {
+        retval = (copy_from_user(&profProps, (PROFILER_PROPERTIES*)pProf, sizeof(PROFILER_PROPERTIES)) == 0);
+    }
+    else
+    {
+        retval = ERROR_PMC_REGISTER_NULL_CLIENT;
+        DRVPRINTERROR("Error: pProf == NULL");
+    }
+
+    if(!retval && (CLIENT_TYPE_PMC != g_clientType) && !CheckValidState(PWR_RUNING))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if (0 == retval)
+    {
+        DRVPRINT("Resuming Profile for client %u", profProps.m_clientId);
+        retval = ResumeTimer(profProps.m_clientId);
+
+        if (retval !=0)
+        {
+            retval = ERROR_PWR_RESUME_COPY;
+            DRVPRINTERROR("Error: Power Profiler: Invalid parameter to Resume Profiler");
+        }
+    }
+
+    if ((CLIENT_TYPE_PMC != g_clientType) && 0 == retval)
+    {
+        g_currState = PWR_RUNING;
+    }
+
+    return retval;
+}
+
+// Used for power profiler and pmc profiler
+static int PowerStartIoctl(PROFILER_PROPERTIES* pProf)
+{
+    int retval = 0;
+    PROFILER_PROPERTIES profProps;
+    DRVPRINT("In Start Profiler Ioctl");
+
+    if(NULL != pProf)
+    {
+        retval = copy_from_user(&profProps, (PROFILER_PROPERTIES*)pProf, sizeof(PROFILER_PROPERTIES));
+    }
+    else
+    {
+        retval = ERROR_PMC_REGISTER_NULL_CLIENT;
+        DRVPRINTERROR("Error: pProf == NULL");
+    }
+
+    if(!retval && (CLIENT_TYPE_PMC != g_clientType) && !CheckValidState(PWR_RUNING))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if (0 == retval)
+    {
+        DRVPRINT("Starting Profile for client %x", profProps.m_clientId);
+        retval = StartProfiler(profProps.m_clientId);
+
+        if ( retval != 0)
+        {
+            retval = ERROR_PWR_START_COPY;
+            DRVPRINTERROR("Error: Power Profiler: Invalid parameter to Start Profiler");
+        }
+    }
+
+    if ((CLIENT_TYPE_PMC != g_clientType) && 0 == retval)
+    {
+        g_currState = PWR_RUNING;
+    }
+
+    return retval;
+}
+
+// Used for power profiler and pmc profiler
+static int PowerClearIoctl(PROFILER_PROPERTIES* pProf)
+{
+    int retval = 0;
+    PROFILER_PROPERTIES profProps;
+    DRVPRINT("In Clear Profiler Ioctl");
+
+    if ((NULL != pProf) && (copy_from_user(&profProps, pProf, sizeof(PROFILER_PROPERTIES)) == 0))
+    {
+        DRVPRINT("Starting Profile for client %x", profProps.m_clientId);
+        retval = ClearProfiler(profProps.m_clientId);
+    }
+    else
+    {
+        DRVPRINTERROR("Error: Power Profiler: Invalid parameter to Start Profiler");
+        retval = ERROR_PMC_COUNTMODE_CLEAR_COPY;
+    }
+
+    return retval;
+}
+
+// This function will call multiple times based on the number of
+// group supplied from backend
+// used for pmc profiler only
+static int PmcGetGroupBufferIoctl(COUNT_MODE_CONFIG_EXTND* pIoctlParam)
+{
+    int retval = 0;
+
+    COUNT_MODE_CONFIG_EXTND extndBuffer;
+
+    DRVPRINT("In IOCTL_COUNT_MODE_CONFIG_EXTND Ioctl");
+
+    if ((NULL != pIoctlParam) && (copy_from_user(&extndBuffer, pIoctlParam, sizeof(COUNT_MODE_CONFIG_EXTND)) == 0))
+    {
+        DRVPRINT("info: copy_from_user passed");
+    }
+    else
+    {
+        DRVPRINTERROR("Error: Failed to copy user data");
+        retval = ERROR_PMC_COUNTMODE_EXT_COPY;
+    }
+
+    if (!retval)
+    {
+        // Memory allocation for group will be done when IOCTL will be called for first time
+        if ((g_groupBuffer.m_pBuffer == NULL)
+            && (extndBuffer.m_groupCnt > 0)
+            && (extndBuffer.m_groupCnt <= PWR_MAX_GROUP_COUNT)
+            && (extndBuffer.m_size > 0)
+            && (extndBuffer.m_size <= IOCTL_CONFIG_EXTND_SIZE))
+        {
+            g_groupBuffer.m_pBuffer = (CountModeGroupConfig*)kzalloc(extndBuffer.m_groupCnt * sizeof(CountModeGroupConfig), GFP_KERNEL);
+
+            if (g_groupBuffer.m_pBuffer == NULL)
+            {
+                retval = ERROR_PMC_COUNTMODE_EXT_ALLOC;
+                memset(&g_groupBuffer, 0, sizeof(GroupBuffer));
+                DRVPRINTERROR("Error: Memory allocation failed for g_groupBuffer.m_pBuffer");
+            }
+            else
+            {
+                 g_groupBuffer.m_totalGroups = extndBuffer.m_groupCnt;
+                 g_groupBuffer.m_idx = 0;
+            }
+        }
+
+        // m_size should also be less or equal to IOCTL_CONFIG_EXTND_SIZE
+        // total groups (m_groupCnt) should be lesser than or equal to the m_idx
+        if ((NULL == g_groupBuffer.m_pBuffer)
+            || (g_groupBuffer.m_totalGroups != extndBuffer.m_groupCnt)
+            || (extndBuffer.m_size > IOCTL_CONFIG_EXTND_SIZE)
+            || ((g_groupBuffer.m_idx + extndBuffer.m_size) > g_groupBuffer.m_totalGroups)
+            || (extndBuffer.m_size ==0))
+        {
+            retval = ERROR_PMC_COUNTMODE_EXT_COPY;
+            DRVPRINTERROR("Error:g_groupBuffer.m_pBuffer(%p)\n\
+                           g_groupBuffer.m_totalGroups(%d)\n\
+                           extndBuffer.m_groupCnt(%d)\n\
+                           g_groupBuffer.m_idx(%d)\n\
+                           extndBuffer.m_size(%d)",
+                           g_groupBuffer.m_pBuffer,
+                           g_groupBuffer.m_totalGroups,
+                           extndBuffer.m_groupCnt,
+                           g_groupBuffer.m_idx,
+                           extndBuffer.m_size);
+            memset(&g_groupBuffer, 0, sizeof(GroupBuffer));
+        }
+
+        if (!retval)
+        {
+            memcpy(&g_groupBuffer.m_pBuffer[g_groupBuffer.m_idx], extndBuffer.m_data, extndBuffer.m_size * sizeof(CountModeGroupConfig));
+            g_groupBuffer.m_idx += extndBuffer.m_size;
+        }
+    }
+
+    return retval;
+}
+
+// After getting all config blocks from backend through GetGroupBuffer
+// this function should be called
+// used for pmc profiler
+static int PmcProfileConfigIoctl(CountModeProfileConfig* pCfgParam)
+{
+    int retval = 0;
+    CountModeProfileConfig* pConfig = NULL;
+
+    /* Allocate memory for profile config */
+    pConfig = (CountModeProfileConfig*)kzalloc(sizeof(CountModeProfileConfig), GFP_KERNEL);
+
+    if ((pConfig == NULL) || (pCfgParam == NULL))
+    {
+        DRVPRINTERROR("Error: pConfig is NULL\n");
+        retval = ERROR_PMC_COUNTMODE_ALLOC;
+    }
+
+    /* Copy profile config */
+    if (!retval && copy_from_user(pConfig,
+                                  (CountModeProfileConfig*)pCfgParam,
+                                  sizeof(CountModeProfileConfig)))
+    {
+        DRVPRINTERROR("Error: CountModeProfileConfig copy failed\n");
+        retval = ERROR_PMC_COUNTMODE_COPY;
+    }
+
+    if (!retval)
+    {
+        if ((NULL == g_groupBuffer.m_pBuffer)
+            || (g_groupBuffer.m_idx != pConfig->m_groupCount))
+        {
+            DRVPRINTERROR("Error: g_groupBuffer.m_pBuffer is NULL\n");
+            retval = ERROR_PMC_COUNTMODE_NULL_GRPCFG;
+        }
+    }
+
+    if (!retval)
+    {
+        /* Save config groups */
+        pConfig->m_pConfigArray = (uint64_t)g_groupBuffer.m_pBuffer;
+        retval = ProcessCountModeProfileConfig(g_pPmcClientContext, pConfig);
+    }
+
+    if (!retval)
+    {
+        // Copy file descriptors to user
+        if (copy_to_user(((CountModeProfileConfig*)pCfgParam)->m_fdArray,
+                         pConfig->m_fdArray,
+                         sizeof(pConfig->m_fdArray)))
+        {
+            DRVPRINTERROR("Error: m_fdArray copy failed\n");
+            retval = ERROR_PMC_COUNTMODE_FD_COPY;
+        }
+    }
+
+    if (g_groupBuffer.m_pBuffer != NULL)
+    {
+        kfree(g_groupBuffer.m_pBuffer);
+        memset(&g_groupBuffer, 0, sizeof(GroupBuffer));
+    }
+
+    if (pConfig != NULL)
+    {
+        kfree(pConfig);
+    }
+
+    return retval;
+}
+
+// Used for power profiler only
+static int GetFileHeaderIoctl(FILE_HEADER* pHdr)
+{
+    int retval = 0;
+    FILE_HEADER file_header;
+
+    DRVPRINT("In get file header ioctl");
+
+    if ((NULL != pHdr) && (copy_from_user(&file_header, (FILE_HEADER*)pHdr, sizeof(FILE_HEADER)) == 0))
+    {
+        DRVPRINT("Get File header for client %u ", file_header.m_clientId);
+        retval = GetHeaderBuffer(&file_header);
+    }
+    else
+    {
+        retval = ERROR_PWR_FILE_HDR_COPY;
+        DRVPRINTERROR("Error: intput header buffer copy failed");
+    }
+
+    if (!retval)
+    {
+        if (copy_to_user((FILE_HEADER*)pHdr, &file_header, sizeof(FILE_HEADER)))
+        {
+            retval = ERROR_PWR_FILE_HDR_COPY;
+            DRVPRINTERROR("Error: output header buffer copy failed");
+        }
+    }
+
+    DRVPRINT("get header buffer ret %d", retval);
+
+    return retval;
+}
+
+// Used only for energy app analysis
+static int EnergyGetDataBufferIoctl(DATA_BUFFER* pDataBuffer)
+{
+    int retval = 0;
+    DATA_BUFFER dataBuffer;
+
+    DRVPRINT("In get data buffer ioctl");
+
+    if ((NULL != pDataBuffer) && (copy_from_user(&dataBuffer, (DATA_BUFFER*)pDataBuffer, sizeof(DATA_BUFFER)) == 0))
+    {
+        DRVPRINT("info: copy_from_user passed");
+        retval = GetDataBuffer(&dataBuffer);
+    }
+    else
+    {
+        retval = ERROR_PWR_DATA_BUFFER_COPY;
+        DRVPRINTERROR("Error: Input data buffer copy failed");        
+    }
+
+    DRVPRINT(" Avaliable Buffer Count %d", dataBuffer.ulavailableBuffCnt);
+
+    if (!retval)
+    {
+        if (copy_to_user((DATA_BUFFER*)pDataBuffer, &dataBuffer, sizeof(DATA_BUFFER)))
+        {
+            retval = ERROR_PWR_DATA_BUFFER_COPY;
+            DRVPRINTERROR("Error: Output data buffer copy failed");
+        }
+    }
+
+    return retval;
+}
+
+// Generic function. Registration not required for this ioctl
+static int TargetSystemInfoIoctl(PTARGET_SYSTEM_INFO pSysInfo)
+{
+    int retval = 0;
+    PTARGET_SYSTEM_INFO pInfo = NULL;
+
+    GetTargetSystemInfo(&pInfo, true);
+
+    if ((NULL != pSysInfo) && (NULL != pInfo))
+    {
+        if (copy_to_user(pSysInfo, pInfo, sizeof(TARGET_SYSTEM_INFO)))
+        {
+            retval = ERROR_PWR_SYSINFO_COPY;
+            DRVPRINTERROR("Error: Copy to User Failed for IOCTL_GET_TARGET_SYSTEM_INFO_BUFFER");
+        }
+    }
+    else
+    {
+        retval = ERROR_PWR_SYSINFO_GET;
+        DRVPRINTERROR("Error: Target System Info is NULL\n");
+    }
+
+    return retval;
+}
+
+// Used for power Profiler only
+static int PowerAddProfileConfigIoctl(PROF_CONFIGS* pCfg)
+{
+    int retval = 0;
+    uint32 clientId = 0;
+    PROF_CONFIGS profConfigs;
+    /* Extract the configuration information */
+    DRVPRINT("In Add Profile Configs Ioctl");
+
+    if(!CheckValidState(PWR_CONFIGURED))
+    {
+        retval = ERROR_PWR_INVALID_STATE;
+        DRVPRINT("Not a Valid State.\n");
+    }
+
+    if (0 == retval)
+    {
+        if ((NULL != pCfg) && copy_from_user(&profConfigs, (PROF_CONFIGS*)pCfg, sizeof(PROF_CONFIGS)) == 0)
+        {
+            DRVPRINT("Adding profile for client %u", profConfigs.m_clientId);
+
+            /* Get the profiler config */
+            clientId = profConfigs.m_clientId;
+            retval = ConfigureTimer(&profConfigs, clientId);
+
+            if(retval != 0)
+            {
+                DeleteClient();
+            }
+        }
+        else
+        {
+            retval = ERROR_PWR_ADDPROFCFG_COPY;
+            DRVPRINTERROR("Error: Invalid parameter to Add profile Config");
+        }
+    }
+
+    if (0 == retval)
+    {
+        g_currState = PWR_CONFIGURED;
+    }
+
+    return retval;
+}
+
+// Generic function to access Msr
+// Registration not required for this ioctl
+static int MsrAccessIoctl(ACCESS_MSR* pMsr)
+{
+    int retval = 0;
+    int idx = 0;
+    ACCESS_MSR msr;
+    bool foundEntry = false;
+    size_t nbrEntries = 0;
+    uint32_t msrAddr = 0;
+    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+    WhitelistedMsrInfo* pMsrList = NULL;
+    DRVPRINT("In Access MSR ioctl\n");
+        
+    if ((NULL != pMsr) && !copy_from_user(&msr, (ACCESS_MSR*)pMsr, sizeof(ACCESS_MSR)) == 0)
+    {
+        retval = ERROR_PWR_MSR_COPY;
+        DRVPRINTERROR("Error: Unknown Error in ACCESS_MSR");
+    }
+
+    msrAddr = msr.m_regId;
+
+    GetTargetSystemInfo(&pTargetInfo, false);
+
+
+    if ((!retval) && (NULL != pTargetInfo))
+    {
+        pMsrList = (pTargetInfo->m_zen.m_isZen4AndAbove) ? g_msrListZen4 : g_msrListPreZen4;
+        nbrEntries = (pTargetInfo->m_zen.m_isZen4AndAbove) ? sizeof(g_msrListZen4) : sizeof(g_msrListPreZen4);
+        nbrEntries = nbrEntries / sizeof(WhitelistedMsrInfo);
+    }
+
+    if ((!retval) && (NULL != pMsrList))
+    {
+        for (idx = 0; idx < nbrEntries; idx++)
+        {
+            if ((msrAddr >= pMsrList[idx].m_startMsrAddr) && (msrAddr <= pMsrList[idx].m_endMsrAddr))
+            {
+                foundEntry = true;
+                break;
+            }
+        }
+    }
+
+    if (!retval && foundEntry)
+    {
+        AccessMSRAddress(&msr);
+        DRVPRINT("read(%d) core(%d) reg(0x%x) data(%lld)\n", msr.m_isReadAccess, msr.m_core, msr.m_regId, msr.m_data);
+
+        if (copy_to_user((ACCESS_MSR*)pMsr, &msr, sizeof(ACCESS_MSR)) != 0)
+        {
+            retval = ERROR_PWR_MSR_OUT_COPY;
+            DRVPRINT("Error: Power Profiler: unknown error");
+        }
+    }
+    else
+    {
+        DRVPRINTERROR("Error: Power Profiler: Invalid Register Id");
+        retval = foundEntry;
+    }
+
+    return retval;
+}
+
+#if 0
+// Generic function to access Mmio
+// Registration not required for this ioctl
+static int MmioAccessIoctl(ACCESS_MMIO* pMmio)
+{
+    int retval = 0;
+    ACCESS_MMIO mmio;
+    DRVPRINT("In Access MMIO ioctl");
+
+    if ((NULL != pMmio) && !(copy_from_user(&mmio, (ACCESS_MMIO*)pMmio, sizeof(ACCESS_MMIO)) == 0))
+    {
+        retval = ERROR_PWR_MMIO_COPY;
+        DRVPRINTERROR("Error: Unknown Error in ACCESS_MMIO ");
+    }
+
+    if (!retval && (false == AccessMMIO(&mmio)))
+    {
+        retval = ERROR_PWR_MMIO_READ;
+        DRVPRINTERROR("Error: Error in ACCESS_MMIO ");
+    }
+
+    if (!retval && copy_to_user((ACCESS_MMIO*)pMmio, &mmio, sizeof(ACCESS_MMIO)) != 0)
+    {
+        retval = ERROR_PWR_MMIO_OUT_COPY;
+        DRVPRINTERROR("Error: Power Profiler: unknown error");
+    }
+
+    return retval;
+}
+#endif
+
+static int PwrHandleFileDescriptors(int* pParams)
+{
+    int retval = 0;
+    SharedFdInfo* pFd = kmalloc(sizeof(SharedFdInfo), GFP_KERNEL);
+
+    if (pFd != NULL)
+    {
+        uint32 cnt = 0;
+
+        memset(pFd, 0, sizeof(SharedFdInfo));
+
+        for (cnt = 0; cnt < GetTargetCoreCount(); cnt++)
+        {
+            pFd->m_fd[cnt] = CreateAnonInodeFd(cnt);
+        }
+
+        pFd->m_count = cnt;
+
+        DRVPRINT("In IOCTL_SET_AND_GET_FD ioctl");
+
+        if (copy_to_user((int*)pParams, pFd, sizeof(SharedFdInfo)))
+        //if (copy_to_user((int*)pParams, &pFd->m_fd[0], sizeof(int)))
+        {
+            retval = ERROR_PWR_FD_COPY;
+            DRVPRINTERROR("Error: Copy to User Failed for IOCTL_SET_AND_GET_FD ");
+        }
+
+        kfree (pFd);
+    }
+
+    return retval;
+}
+
+// Generic function to access Pcie
+// Registration not required for this ioctl
+static int PcieAccessIoctl(ACCESS_PCI* pPciIoctl)
+{
+    int retval = 0;
+    ACCESS_PCI* pPci = NULL;
+    DRVPRINT("In Access PCI ioctl");
+
+    pPci = (PACCESS_PCI)kzalloc(sizeof(ACCESS_PCI), GFP_KERNEL);
+
+    if ((NULL != pPciIoctl) && (NULL != pPci) && !copy_from_user(pPci, (ACCESS_PCI*)pPciIoctl, sizeof(ACCESS_PCI)) == 0)
+    {
+        retval = ERROR_PWR_PCI_COPY;
+        DRVPRINTERROR("Error: Power Profiler: Unknown Error in ACCESS_PCI");
+    }
+
+    if (!retval)
+    {
+        AccessPciAddress(pPci);
+    }
+
+    if (!retval && copy_to_user((ACCESS_PCI*)pPciIoctl, pPci, sizeof(ACCESS_PCI)) != 0)
+    {
+        retval = ERROR_PWR_PCI_OUT_COPY;
+        DRVPRINTERROR("Error: Power Profiler: unknown error");
+    }
+
+    if (pPci != NULL)
+    {
+        kfree(pPci);
+    }
+
+    return retval;
+}
+
+// Generic function to access Smn
+// Registration not required for this ioctl
+static int SmnAccessIoctl(ACCESS_SMN* pSmn)
+{
+    ACCESS_SMN smn;
+    int retval = 0;
+
+    DRVPRINT("In Access SMN ioctl\n");
+
+    if ((NULL != pSmn) && !copy_from_user(&smn, (ACCESS_SMN*)pSmn, sizeof(ACCESS_SMN)) == 0)
+    {
+        retval = ERROR_PWR_SMN_COPY;
+        DRVPRINTERROR("Error: Unknown Error in ACCESS_SMN");
+    }
+
+    if (!retval)
+    {
+        PTARGET_SYSTEM_INFO pInfo = NULL;
+
+        GetTargetSystemInfo(&pInfo, false);
+
+        if (NULL != pInfo)
+        {
+            AccessSMN(pInfo, &smn);
+            DRVPRINT("read(%d) address(0x%x) data(%d)\n", smn.m_isReadAccess, smn.m_address, smn.m_data);
+        }
+    }
+
+    if (!retval && copy_to_user((ACCESS_SMN*)pSmn, &smn, sizeof(ACCESS_SMN)) != 0)
+    {
+        retval = ERROR_PWR_SMN_OUT_COPY;
+        DRVPRINTERROR("Error: Power Profiler: unknown error");
+    }
+
+    return retval;
+}
+
+// IOCTL implementation for driver.
+// mapping File opertaions for the pcore driver module.
+long PwrProfDrvIoctlImpl(struct file* file, unsigned int ioctl_num, unsigned long ioctl_param)
+{
+    int retval                  = 0;
+    uint64_t version            = 0;
+
+    DRVPRINT("device_ioctl: ioctl_num(%x) ioctl_param(%p)", ioctl_num, (void*)ioctl_param);
+
+    switch (ioctl_num)
+    {
+        case IOCTL_GET_VERSION:
+            DRVPRINT(" In get version Ioctl");
+            version  = (unsigned long)LINUX_PWR_DRV_MAJOR << 32 | (unsigned int)LINUX_PWR_DRV_MINOR;
+            DRVPRINT(" Power Profiler version is %llx ", version);
+
+            retval = copy_to_user((unsigned long*) ioctl_param, &version, sizeof(unsigned long));
+            return retval;
+
+        case IOCTL_REGISTER_CLIENT:
+            return RegisterClientIoctl((ClientType*)ioctl_param);
+
+        case IOCTL_UNREGISTER_CLIENT:
+            return UnregisterClientIoctl((uint32_t*)ioctl_param);
+
+        case IOCTL_ADD_PROF_CONFIGS:
+            return PowerAddProfileConfigIoctl((PROF_CONFIGS*)ioctl_param);
+
+        case IOCTL_RESUME_PROFILER :
+            return PowerResumeIoctl((PROFILER_PROPERTIES*)ioctl_param);
+
+        case IOCTL_START_PROFILER:
+            return PowerStartIoctl((PROFILER_PROPERTIES*)ioctl_param);
+
+        case IOCTL_PAUSE_PROFILER:
+            return PauseClientIoctl((uint32_t*)ioctl_param);
+
+        case IOCTL_STOP_PROFILER:
+            return StopIoctl((uint32_t*)ioctl_param);
+
+        case IOCTL_GET_FILE_HEADER_BUFFER:
+            return GetFileHeaderIoctl((FILE_HEADER*)ioctl_param);
+
+        case IOCTL_GET_DATA_BUFFER:
+            return EnergyGetDataBufferIoctl((DATA_BUFFER*)ioctl_param);
+
+        case IOCTL_ACCESS_PCI_DEVICE:
+            return PcieAccessIoctl((ACCESS_PCI*)ioctl_param);
+
+        case IOCTL_ACCESS_MSR:
+            return MsrAccessIoctl((ACCESS_MSR*)ioctl_param);
+
+        case IOCTL_ACCESS_SMN:
+             return SmnAccessIoctl((ACCESS_SMN*)ioctl_param);
+
+        case IOCTL_ACCESS_MMIO:
+             retval = ERROR_PWR_IOCTL_NOT_SUPPORTED;
+             return retval;
+            //return MmioAccessIoctl((ACCESS_MMIO*)ioctl_param);
+
+        case IOCTL_SET_AND_GET_FD:
+            return PwrHandleFileDescriptors((int*)ioctl_param);
+
+        case IOCTL_GET_TARGET_SYSTEM_INFO_BUFFER:
+            return TargetSystemInfoIoctl((PTARGET_SYSTEM_INFO)ioctl_param);
+
+        case IOCTL_COUNT_MODE_PROFILE_CONFIG:
+            return PmcProfileConfigIoctl((CountModeProfileConfig*)ioctl_param);
+
+
+        case IOCTL_COUNT_MODE_CONFIG_EXTND:
+            return PmcGetGroupBufferIoctl((COUNT_MODE_CONFIG_EXTND*)ioctl_param);
+
+        case IOCTL_CLEAR_PROFILER:
+            return PowerClearIoctl((PROFILER_PROPERTIES*)ioctl_param);
+
+        default:
+            DRVPRINTERROR("Error: Power Profiler: Unknown IOCTL ");
+            retval = ERROR_PWR_IOCTL_INVALID;
+            return retval;
+    }
+}
+
+// Module specific cleanup
+void PwrProfDrvCleanup(void)
+{
+    g_isClientActiv = false;
+    g_clientId = 0;
+
+    UnconfigureTimer(g_clientId);
+    // Release memory pool
+    ReleaseMemoryPool(&g_sessionPool);
+}
+
+// check if hardware supported.
+long CheckPwrProfHwSupport(void)
+{
+    return CheckHwSupport();
+}
+
+// get the driver version.
+void GetVersions(unsigned int* major, unsigned int* minor, unsigned int* build)
+{
+    *major = LINUX_PWR_DRV_MAJOR;
+    *minor = LINUX_PWR_DRV_MINOR;
+    *build = pcore_build_number;
+}
diff --git a/drivers/powerprofiler/src/PwrProfModule.c b/drivers/powerprofiler/src/PwrProfModule.c
new file mode 100644
index 000000000000..8683f0de032d
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrProfModule.c
@@ -0,0 +1,311 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfModule.c
+///
+//==================================================================================
+// SYSTEM INCLUDES
+#include <linux/cdev.h>
+#include <linux/device.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/kdev_t.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/version.h>
+
+// PROJECT INCLUDES
+#include <PwrProfSharedMemOps.h>
+
+// MODULE DEFINES
+#define PROC_DIR_SIZE                   3
+#define PWR_PROF_DRV_FIRST_MINOR        0
+#define PWR_PROF_DRV_MINOR_CNT          1
+#define PWR_PROF_DRV_PROCFS_MAX_SIZE    1024
+#define PWR_PROF_DRV_DEVICE_NAME        "AMDPowerProfiler"
+
+// PCORE MODULE FUNCTIONS
+void GetVersions(unsigned int*, unsigned int*, unsigned int*);
+long PwrProfDrvIoctlImpl(struct file*, unsigned int, unsigned long);
+long CheckPwrProfHwSupport(void);
+void PwrProfDrvCleanup(void);
+
+// STATIC VARIABLE
+static dev_t dev;
+struct cdev* kernel_cdev;
+static struct proc_dir_entry* base;
+
+// GLOBAL VARIABLE
+// module state, tell if module is in use
+// 0: Not in use, 1: In use
+int moduleState = 0;
+
+#define _DGPU_ENABLED_
+
+// Invoke IOCTL implementation for AMDPowerProfiler driver.
+static long PwrProfDrvDeviceIoctl(struct file* file, unsigned int ioctl_num, unsigned long ioctl_param)
+{
+    return PwrProfDrvIoctlImpl(file, ioctl_num, ioctl_param);
+}
+
+// File operations for AMDPowerProfiler driver.
+struct file_operations Fops =
+{
+    .unlocked_ioctl = PwrProfDrvDeviceIoctl,
+};
+
+// File operations to show AMDPowerProfiler-device version.
+static int AMDPowerProfiler_proc_show_device(struct seq_file* m, void* v)
+{
+    seq_printf(m, "%d\n", MAJOR(dev));
+    return 0;
+}
+
+static int AMDPowerProfiler_proc_show_version(struct seq_file* m, void* v)
+{
+    unsigned int major_ver, minor_ver, build_num;
+    GetVersions(&major_ver, &minor_ver, &build_num);
+    seq_printf(m, "%u.%u-%u\n", major_ver, minor_ver, build_num);
+    return 0;
+}
+
+// File operation to open AMDPowerProfiler-device file.
+static int AMDPowerProfiler_proc_open_device(struct inode* inode, struct  file* file)
+{
+    return single_open(file, AMDPowerProfiler_proc_show_device, NULL);
+}
+
+static int AMDPowerProfiler_proc_open_version(struct inode* inode, struct  file* file)
+{
+    return single_open(file, AMDPowerProfiler_proc_show_version, NULL);
+}
+
+static int
+AMDPowerProfiler_proc_fops_mod_show(struct seq_file* m, void* v)
+{
+    seq_printf(m, "%d\n", moduleState);
+    return 0;
+}
+
+static int
+AMDPowerProfiler_proc_fops_mod_open(struct inode* inode, struct file* file)
+{
+    return single_open(file, AMDPowerProfiler_proc_fops_mod_show, NULL);
+}
+
+// File operation's for AMDPowerProfiler-device
+#if LINUX_VERSION_CODE > KERNEL_VERSION(5, 5, 19)
+static const struct proc_ops AMDPowerProfiler_proc_fops_device =
+{
+    .proc_open = AMDPowerProfiler_proc_open_device,
+    .proc_read = seq_read,
+    .proc_lseek = seq_lseek,
+    .proc_release = single_release,
+};
+
+static const struct proc_ops AMDPowerProfiler_proc_fops_version =
+{
+    .proc_open = AMDPowerProfiler_proc_open_version,
+    .proc_read = seq_read,
+    .proc_lseek = seq_lseek,
+    .proc_release = single_release,
+};
+
+static const struct
+    proc_ops AMDPowerProfiler_proc_fops_mod_state =
+{
+    .proc_open  = AMDPowerProfiler_proc_fops_mod_open,
+    .proc_read  = seq_read,
+    .proc_lseek = seq_lseek,
+    .proc_release = single_release,
+};
+
+#else
+static const struct file_operations AMDPowerProfiler_proc_fops_device =
+{
+    .open = AMDPowerProfiler_proc_open_device,
+    .read = seq_read,
+    .llseek = seq_lseek,
+    .release = single_release,
+};
+
+static const struct file_operations AMDPowerProfiler_proc_fops_version =
+{
+    .open = AMDPowerProfiler_proc_open_version,
+    .read = seq_read,
+    .llseek = seq_lseek,
+    .release = single_release,
+};
+
+static const struct
+    file_operations AMDPowerProfiler_proc_fops_mod_state =
+{
+    .owner      = THIS_MODULE,
+    .open       = AMDPowerProfiler_proc_fops_mod_open,
+    .read       = seq_read,
+    .llseek     = seq_lseek,
+    .release    = single_release,
+};
+#endif
+
+
+
+
+static struct
+{
+    const char* name;
+#if LINUX_VERSION_CODE > KERNEL_VERSION(5, 5, 19)
+    const struct proc_ops* proc_fops;
+#else
+    const struct file_operations* proc_fops;
+#endif
+} Entries[] =
+{
+    {"device", &AMDPowerProfiler_proc_fops_device},
+    {"version", &AMDPowerProfiler_proc_fops_version},
+    {"state", &AMDPowerProfiler_proc_fops_mod_state},
+};
+
+
+// Initialize the module - Register the character device
+static int __init PwrProfInitModule(void)
+{
+    int ret;
+    int i;
+    unsigned int major_ver, minor_ver, build_num;
+    struct proc_dir_entry* entry;
+    unsigned int entry_created = 0;
+
+    // Check for KERNEL VERSION SUPPORT.
+    // We dont support versions earlier to 2.6.32
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 32)
+    printk("AMDPowerProfiler: Error, Unsupported kernel version. AMDPowerProfiler only supports version >= 2.6.32 \n");
+    return -EPERM;
+#endif
+
+    // Check for x86_64 support
+#ifndef CONFIG_X86_64
+    printk("AMDPowerProfiler: Error, Unsupported kernel version. AMDPowerProfiler only supports 64 bit kernels \n");
+    return -EPERM;
+#endif
+#ifndef _DGPU_ENABLED_
+
+    // TODO: Add a function here to get supported uncore counters?
+    ret = CheckPwrProfHwSupport();
+
+    if ((ret < 0))
+    {
+        return ret;
+    }
+
+#endif
+    ret = alloc_chrdev_region(&dev, PWR_PROF_DRV_FIRST_MINOR, PWR_PROF_DRV_MINOR_CNT, PWR_PROF_DRV_DEVICE_NAME);
+
+    if (ret < 0)
+    {
+        printk(KERN_WARNING "AMDPowerProfiler: Char device allocation failed\n");
+        return ret;
+    }
+
+    kernel_cdev = cdev_alloc();
+
+    if (!kernel_cdev)
+    {
+        printk(KERN_WARNING "AMDPowerProfiler: Unable to allocate cdev\n");
+        unregister_chrdev_region(dev, PWR_PROF_DRV_MINOR_CNT);
+        return -EIO;
+    }
+
+    kernel_cdev->ops = &Fops;
+    kernel_cdev->owner = THIS_MODULE;
+
+    ret = cdev_add(kernel_cdev, dev, 1);
+
+    if (ret < 0)
+    {
+        printk(KERN_WARNING "AMDPowerProfiler: Unable to add cdev");
+        cdev_del(kernel_cdev);
+        unregister_chrdev_region(dev, PWR_PROF_DRV_MINOR_CNT);
+        return ret;
+    }
+
+    if (!(base = proc_mkdir(PWR_PROF_DRV_DEVICE_NAME, NULL)))
+    {
+        printk(KERN_WARNING "AMDPowerProfiler: Unable to create AMD Power Profiler  dir\n");
+        return -EIO;
+    }
+
+    // TODO: Do not create these proc entries by default, only when a client
+    // intends to configure power profiling
+    for (entry_created = 0; entry_created < PROC_DIR_SIZE ; ++entry_created)
+    {
+        entry = proc_create(Entries[entry_created].name, 0, base,
+                            Entries[entry_created].proc_fops);
+
+        if (NULL == entry)
+        {
+            ret = -ENOMEM;
+            break;
+        }
+    }
+
+    // TODO: Will need to create similar proc entries for count
+    // mode profiling
+
+    if (ret < 0)
+    {
+        printk(KERN_WARNING " AMDPowerProfiler: Internal error");
+
+        if (base)
+        {
+            for (i = 0; i < entry_created; ++i)
+            {
+                remove_proc_entry(Entries[i].name, base);
+            }
+
+            // delete directory
+            remove_proc_entry(PWR_PROF_DRV_DEVICE_NAME, NULL);
+        }
+
+        cdev_del(kernel_cdev);
+        unregister_chrdev_region(dev, PWR_PROF_DRV_MINOR_CNT);
+        return ret;
+    }
+
+    GetVersions(&major_ver, &minor_ver, &build_num);
+
+    printk(KERN_INFO "AMDPowerProfiler: Registration was successful.\n");
+    printk(KERN_INFO "AMDPowerProfiler: Version is %u.%u-%u\n", major_ver, minor_ver, build_num);
+    printk(KERN_INFO "AMDPowerProfiler: Device name: %s, Major device number: %d.\n", PWR_PROF_DRV_DEVICE_NAME, MAJOR(dev));
+
+    return 0;
+}
+
+// Cleanup - unregister the appropriate file from /proc
+static void __exit PwrProfDrvCleanupModule(void)
+{
+    int i;
+    // Module Specific Cleanup
+    PwrProfDrvCleanup();
+
+    if (base)
+    {
+        for (i = 0; i < PROC_DIR_SIZE ; ++i)
+        {
+            remove_proc_entry(Entries[i].name, base);
+        }
+
+        remove_proc_entry(PWR_PROF_DRV_DEVICE_NAME, NULL);
+    }
+
+    cdev_del(kernel_cdev);
+    unregister_chrdev_region(dev, PWR_PROF_DRV_MINOR_CNT);
+    printk(KERN_INFO "AMDPowerProfiler: Unregistreing AMDPowerProfiler ");
+}
+
+module_init(PwrProfInitModule);
+module_exit(PwrProfDrvCleanupModule);
+MODULE_LICENSE("Dual MIT/GPL");
diff --git a/drivers/powerprofiler/src/PwrProfSharedMemOps.c b/drivers/powerprofiler/src/PwrProfSharedMemOps.c
new file mode 100644
index 000000000000..3d358deb7db1
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrProfSharedMemOps.c
@@ -0,0 +1,263 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfSharedMemOps.c
+///
+//==================================================================================
+// SYSTEM INCLUDES
+#include <linux/fs.h>
+#include <linux/anon_inodes.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/poll.h>
+#include <linux/version.h>
+
+// LOCAL INCLUDES
+#include <PwrOsPrimitives.h>
+#include <PwrSharedBufferConfig.h>
+#include <PwrProfSharedMemOps.h>
+#include <PwrDriverUtils.h>
+
+#ifndef VM_RESERVED
+    #define VM_RESERVED   (VM_DONTEXPAND | VM_DONTDUMP)
+#endif
+
+
+DECLARE_WAIT_QUEUE_HEAD(work_queue);
+
+// GLOBAL VARIABLE
+uint8_t* g_pPwrSharedBuffer[MAX_CORE_CNT];
+struct file_operations;
+
+extern atomic_t g_signal;
+// Helper functions to [de]allocate private data
+static struct PwrMmapCtx* PwrAllocateDataCtx(unsigned int cpuId)
+{
+    PwrMmapCtx* ctx = NULL;
+    unsigned int order = 0;
+    unsigned int sharedBufferSize = PwrGetSharedBufferSize(GetTargetCoreCount());
+    ctx = kmalloc(sizeof(PwrMmapCtx), GFP_KERNEL);
+
+    if (NULL != ctx)
+    {
+        atomic_set(&ctx->m_mmapCount, 0);
+        ctx->m_flags = 0;
+        ctx->m_mmapAddress = 0;
+        ctx->m_mmapSize = sharedBufferSize;
+        ctx->m_cpuId = cpuId;
+        //ctx->mmap_mutex = ?? // FIXME
+
+        // Find the order
+        for (order = 0; order < PWRPROF_MAX_MEM_ORDER; order++)
+        {
+            if (sharedBufferSize <= ((1 << order) * DEFAULT_PAGE_SIZE))
+            {
+                ctx->m_order = order;
+                break;
+            }
+        }
+    }
+
+    return ctx;
+}
+
+static void PwrMmap_close(struct vm_area_struct* vma)
+{
+    PwrMmapCtx* ctx   = NULL;
+
+    if (NULL != vma)
+    {
+        ctx = (PwrMmapCtx*)vma->vm_private_data;
+
+        if (NULL != ctx)
+        {
+            // decrement the mmap count
+            atomic_dec(&ctx->m_mmapCount);
+
+            if (0 == atomic_read(&ctx->m_mmapCount))
+            {
+                if (!ctx->m_mmapAddress)
+                {
+                    free_pages((unsigned long)ctx->m_mmapAddress, ctx->m_order);
+                }
+
+                // reset
+                ctx->m_order = 0;
+                ctx->m_mmapAddress = 0;
+                ctx->m_mmapSize = 0;
+                g_pPwrSharedBuffer[ctx->m_cpuId] = NULL;
+                kfree(ctx);
+            }
+        }
+    }
+
+    return;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
+    static vm_fault_t PwrMmap_fault(struct vm_fault* vmf)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
+    static int PwrMmap_fault(struct vm_fault* vmf)
+#else
+    static int PwrMmap_fault(struct vm_area_struct* vma, struct vm_fault* vmf)
+#endif
+{
+    int retVal = VM_FAULT_SIGBUS;
+    DRVPRINT("Error: Unexpected call(%d)", retVal);
+
+    return retVal;
+}
+
+// MMAP OPs APIs
+static void PwrMmap_open(struct vm_area_struct* vma)
+{
+    PwrMmapCtx* ctx  = NULL;
+    ctx = (PwrMmapCtx*)vma->vm_private_data;
+
+    if (NULL != ctx)
+    {
+        atomic_inc(&ctx->m_mmapCount);
+    }
+}
+
+struct vm_operations_struct PwrVmOps =
+{
+    .open  = PwrMmap_open,
+    .close = PwrMmap_close,
+    .fault = PwrMmap_fault,
+};
+
+static int PwrMmap(struct file* file, struct vm_area_struct* vma)
+{
+    int ret = 0;
+    PwrMmapCtx* ctx  = NULL;
+    uint8* pSharedBuffer = NULL;
+    unsigned long vmSize = 0;
+    uint32_t node = 0;
+    unsigned long numOfPages = 0;
+    void *pDataBuffer = NULL;
+
+    if (NULL != file && NULL != vma)
+    {
+        vma->vm_ops          = &PwrVmOps;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+        vm_flags_set(vma, VM_RESERVED);
+#else
+        vma->vm_flags |= VM_RESERVED;
+#endif
+
+        vma->vm_private_data = file->private_data;
+
+        ctx = (PwrMmapCtx*)vma->vm_private_data;
+        
+        if (NULL == ctx)
+        {
+            ret = -1;
+        }
+
+        if (ret == 0)
+        {
+            vmSize = (vma->vm_end - vma->vm_start);
+            node = cpu_to_node(ctx->m_cpuId);
+            numOfPages = (ctx->m_mmapSize) >> PAGE_SHIFT;
+            DRVPRINT("CPUID %d vmSize(%ld) mapSize(%ld) node(%d) pages(%ld)\n", ctx->m_cpuId, vmSize, ctx->m_mmapSize, node, numOfPages);
+
+            if (vmSize > ctx->m_mmapSize)
+            {
+                DRVPRINT("Error: Size not matching vmSize(%d) bufferSize(%d)", (int)vmSize, (int)ctx->m_mmapSize);
+                ret = -1;
+            }
+        }
+        
+        if (ret == 0)
+        {
+            
+            pDataBuffer = kmalloc_node(PAGE_SIZE * numOfPages, GFP_KERNEL, node);
+
+            if (pDataBuffer == NULL)
+            {
+                DRVPRINT("Error: Allocation failed(%p) pageSize(%lu) pages (%lu)", pDataBuffer, PAGE_SIZE, numOfPages);
+                ret = -1;
+            }
+        }
+                
+        if (ret == 0)
+        {
+            uint32_t idx = 0;
+            unsigned long pfn = 0;
+
+            for (idx = 0; idx < numOfPages * PAGE_SIZE; idx += PAGE_SIZE)
+            {
+                SetPageReserved(virt_to_page(((unsigned long)pDataBuffer) + idx));
+            }
+            
+            pfn = virt_to_phys((void *)pDataBuffer) >> PAGE_SHIFT;
+            ret = remap_pfn_range(vma, vma->vm_start, pfn, vmSize, vma->vm_page_prot);
+            
+            if (ret < 0)
+            {
+                DRVPRINT("Error: could not map the address area\n");
+                ret = -1;
+            }
+        }
+        
+        if (ret == 0)
+        {
+            g_pPwrSharedBuffer[ctx->m_cpuId] = pDataBuffer;
+            ctx->m_mmapAddress = (uint64_t)pSharedBuffer;
+            atomic_inc(&ctx->m_mmapCount);
+        }
+    }
+
+    return ret;
+}
+
+static unsigned int PwrPoll(struct file* filp, poll_table* wait)
+{
+    unsigned int mask = 0;
+    unsigned int signal = 0;
+
+    poll_wait(filp, &work_queue, wait);
+
+    ATOMIC_GET(&signal, g_signal);
+
+    if (signal)
+    {
+        mask = POLLIN;
+        ATOMIC_SET(&g_signal, 0);
+    }
+
+    return mask;
+}
+
+static const struct file_operations PwrOps =
+{
+    .mmap       = PwrMmap,
+    .poll       = PwrPoll,
+};
+
+int CreateAnonInodeFd(unsigned int cpuId)
+{
+    int fd                          = -1;
+    int flags                       = O_RDWR | O_CLOEXEC;
+    PwrMmapCtx* ctx   = NULL;
+
+    ctx = PwrAllocateDataCtx(cpuId);
+
+    if (NULL == ctx)
+    {
+        DRVPRINT("Failed to allocate private data for anon_inode.");
+        return -ENOMEM;
+    }
+
+    fd = anon_inode_getfd("[AMDPowerProfiler]", &PwrOps, ctx, flags);
+
+    if (fd < 0)
+    {
+        DRVPRINT("Failed to create anonymous inode.");
+    }
+
+    return fd;
+}
diff --git a/drivers/powerprofiler/src/PwrProfTimer.c b/drivers/powerprofiler/src/PwrProfTimer.c
new file mode 100644
index 000000000000..74b1ff946b9e
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrProfTimer.c
@@ -0,0 +1,801 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfTimer.c
+///
+//==================================================================================
+// System headers
+
+#include <linux/hrtimer.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/ktime.h>
+#include <linux/rcupdate.h>
+#include <linux/sched.h>
+#include <linux/smp.h>
+#include <linux/atomic.h>
+#include <linux/cpu.h>
+#include <linux/poll.h>
+
+// Project headers
+#include <PwrOsPrimitives.h>
+#include <PwrCommonConfig.h>
+#include <PwrDriverTypedefs.h>
+#include <PwrDriverUtils.h>
+#include <PwrCommonDataTypes.h>
+#include <PwrProfInternal.h>
+#include <PwrProfTimer.h>
+#include <PwrProfTimerHelper.h>
+
+#include <asm/irq_regs.h>
+#include <linux/slab.h>
+#include <linux/pid_namespace.h>
+#include <linux/pid.h>
+
+
+// Global core config list
+CoreData* g_pCoreCfg = NULL;
+#define PWR_ESCAPE_CODE  ~0UL
+
+// Define per-cpu client-data
+DEFINE_PER_CPU(CoreData, g_coreClientData);
+
+// Extern definations
+extern struct task_struct init_task;
+extern int moduleState;
+
+// Extern functions
+extern void MarkClientForCleanup(unsigned long);
+extern void InitializeGenericCounterAccess(uint32 core);
+extern void CloseGenericCounterAccess(void);
+extern wait_queue_head_t work_queue;
+
+// Global signal handler
+atomic_t g_signal;
+uint8* pSharedBuffer = NULL;
+
+// Local structure
+typedef struct ClientList
+{
+    struct list_head    list;
+    ClientData*         m_pClientData;
+} ClientList;
+
+static ClientList tlist =
+{
+    .list = LIST_HEAD_INIT(tlist.list),
+};
+
+// CheckParentPid
+//
+// Check if the the process started timer is still.
+//
+bool CheckParentPid(pid_t parentPid)
+{
+    struct pid_namespace *ns = task_active_pid_ns(current);
+    struct pid* pid_struct  = NULL;
+    struct task_struct* task = NULL;
+    bool ret = true;
+
+    if (ns)
+    {
+        pid_struct = find_pid_ns(parentPid, ns);
+
+        if (NULL != pid_struct)
+        {
+            rcu_read_lock();
+            task = pid_task(pid_struct, PIDTYPE_PID);
+
+            if (NULL == task)
+            {
+                ret = false;
+            }
+            rcu_read_unlock();
+        }
+        else
+        {
+            ret = false;
+        }
+    }
+
+    return ret;
+}
+
+void SetInstructionPointer(uint32* isKernel, uint64* ip)
+{
+    struct pt_regs* regs = get_irq_regs();
+
+    if (likely(regs))
+    {
+        *isKernel = !user_mode(regs);
+        *ip = instruction_pointer(regs);
+    }
+    else
+    {
+        *isKernel = 0;
+        *ip = PWR_ESCAPE_CODE;
+    }
+}
+
+// SampleDataCallback
+//
+// Timer Callback function invoked when the HR timer expires
+//
+int SampleDataCallback(ClientData* pClientData)
+{
+    int cpu = 0;
+    CoreData* pCoreClientData = NULL;
+    cpu = get_cpu();
+    put_cpu();
+
+    if (NULL != pClientData)
+    {
+       if (CheckParentPid(pClientData->m_osClientCfg.m_parentPid))
+       // CheckParentPid has an issue with stress-ng. Function is corrected now.
+       // However, commented here as application profiling is innactive now
+       {
+            struct task_struct* currentTask = NULL;
+            currentTask = get_current();
+            pCoreClientData = &per_cpu(g_coreClientData, cpu);
+
+            // set context info for each core
+            pCoreClientData->m_contextData.m_processId  = currentTask->tgid;
+            pCoreClientData->m_contextData.m_threadId   = currentTask->pid;
+            pCoreClientData->m_contextData.m_timeStamp  = ktime_to_ns(ktime_get());
+            pCoreClientData->m_coreId                   = cpu;
+            WriteSampleData(pCoreClientData);
+
+            if (1 == pCoreClientData->m_sampleId)
+            {
+                ATOMIC_SET(&g_signal, 1);
+                wake_up_interruptible(&work_queue);
+            }
+       }
+       else
+       {
+            printk("Warning: CheckParentPid failed\n");
+            MarkClientForCleanup(pClientData->m_clientId);
+       }
+    }
+   return 0;
+}
+
+// StartHrTimer
+//
+// Start/Re-start HR timer
+//
+void StartHrTimer(void)
+{
+    int cpu = 0;
+    CoreData* pCoreClientData = NULL;
+
+    // get current core id
+    cpu = get_cpu();
+    put_cpu();
+
+    // get the CoreData Object
+    pCoreClientData = &per_cpu(g_coreClientData, cpu);
+
+    if (NULL != pCoreClientData)
+    {
+        // start hr timer
+        hrtimer_start(&pCoreClientData->m_hrTimer,
+                      pCoreClientData->m_interval,
+                      HRTIMER_MODE_REL_PINNED);
+
+    }
+}
+
+// StartTimer
+//
+// Invoked when profiling starts, add a timer for
+// sampling time.
+//
+int StartTimer(uint32 clientId)
+{
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    int ret = 0;
+    int cpu = 0;
+
+    DRVPRINT("Start Timer for client id : %d ", clientId);
+
+    list_for_each(pCurrent, &tlist.list)
+    {
+        pClients = list_entry(pCurrent, ClientList, list);
+
+        if ((pClients->m_pClientData->m_clientId == clientId))
+        {
+            pClients->m_pClientData->m_osClientCfg.m_paused    = false;
+            pClients->m_pClientData->m_osClientCfg.m_stopped   = false;
+
+            cpu = get_cpu();
+            put_cpu();
+
+            if (cpumask_test_cpu(cpu, &pClients->m_pClientData->m_osClientCfg.m_affinity))
+            {
+                StartHrTimer();
+            }
+
+            preempt_disable();
+
+            smp_call_function_many(&pClients->m_pClientData->m_osClientCfg.m_affinity,
+                                   (void*)StartHrTimer,
+                                   (void*)NULL,
+                                   true); // blocking call
+
+            preempt_enable();
+
+            ret = UpdateBufferHeader(pClients->m_pClientData, 0);
+        }
+    }
+
+    // module is in use, set state to 1
+    moduleState = 1;
+
+    return ret;
+}
+
+// ResumeTimer
+//
+// Resume the timer to collect data
+//
+int ResumeTimer(uint32 clientId)
+{
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    int ret = 0;
+    int cpu = 0;
+
+    DRVPRINT("Resuming the timers for client %d ", clientId);
+    list_for_each(pCurrent, &tlist.list)
+    {
+        pClients = list_entry(pCurrent, ClientList, list);
+
+        if (NULL != pClients->m_pClientData)
+        {
+            DRVPRINT("Check client %d ", pClients->m_pClientData->m_clientId);
+
+            if ((pClients->m_pClientData->m_clientId == clientId))
+            {
+                // Fire the timer to start from
+                DRVPRINT("Starting the timer to start in msec ");
+                pClients->m_pClientData->m_osClientCfg.m_paused = false;
+
+                cpu = get_cpu();
+                put_cpu();
+
+                if (cpumask_test_cpu(cpu, &pClients->m_pClientData->m_osClientCfg.m_affinity))
+                {
+                    StartHrTimer();
+                }
+
+                preempt_disable();
+
+                smp_call_function_many(&pClients->m_pClientData->m_osClientCfg.m_affinity,
+                                       (void*)StartHrTimer,
+                                       (void*)NULL,
+                                       true); // blocking call
+
+                preempt_enable();
+            }
+        }
+        else
+        {
+            ret = -1;
+        }
+    }
+
+    return ret;
+}
+
+// GetHeaderBuffer
+//
+// Get header buffer for the kernel space
+// convert it into user space
+//
+int GetHeaderBuffer(PFILE_HEADER pFileHeader)
+{
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    int ret = 0;
+
+    DRVPRINT(" Get File Header for client %u ", pFileHeader->m_clientId);
+
+    list_for_each(pCurrent, &tlist.list)
+    {
+        pClients = list_entry(pCurrent, ClientList, list);
+
+        DRVPRINT("Client id %d", pClients->m_pClientData->m_clientId);
+
+        if (pClients->m_pClientData->m_clientId == pFileHeader->m_clientId)
+        {
+            if (NULL == pClients->m_pClientData->m_header.m_pBuffer)
+            {
+                DRVPRINT(KERN_ERR "Power Profiler Timer:get header buffer , timer buffer NULL ");
+                return EFAULT;
+            }
+
+            // Only one config
+            pFileHeader->m_bufferCnt = 1;
+            memcpy((unsigned char*)pFileHeader->m_buffer, pClients->m_pClientData->m_header.m_pBuffer, HEADER_BUFFER_SIZE);
+        }
+    }
+    return ret;
+}
+
+// GetDataBuffer
+//
+// Get data buffer for the counter
+//
+int GetDataBuffer(PDATA_BUFFER data_buffer)
+{
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    RawBufferInfo* pBufferList = NULL;
+    RawBufferInfo* pBuff = NULL;
+    uint8* pBuffer = NULL;
+    ClientData* pClientData = NULL;
+    CoreData* pCoreClientData = NULL;
+    int ret = 0;
+    int currentOffset = 0;
+    int consumedOffset = 0;
+    uint32_t cnt = 0;
+    uint32 coreId = 0;
+
+    DRVPRINT(" Get data buffer for client %u ", data_buffer->ulClientId);
+
+    list_for_each(pCurrent, &tlist.list)
+    {
+        pClients = list_entry(pCurrent, ClientList, list);
+
+        pClientData = pClients->m_pClientData;
+
+        if (NULL != pClientData && pClientData->m_clientId == data_buffer->ulClientId)
+        {
+            pBufferList = (RawBufferInfo*)(data_buffer->uliBuffer);
+
+            for_each_cpu(coreId, &pClientData->m_osClientCfg.m_affinity)
+            {
+                pCoreClientData = &per_cpu(g_coreClientData, coreId);
+                pBuff = (RawBufferInfo*)(pBufferList + cnt);
+
+                if (NULL == pBuff)
+                {
+                    DRVPRINT(KERN_ERR "Power Profiler Timer:Null buff ");
+                    return -EFAULT;
+                }
+
+                currentOffset = atomic_read(&pCoreClientData->m_pCoreBuffer->m_currentOffset);
+                consumedOffset = atomic_read(&pCoreClientData->m_pCoreBuffer->m_consumedOffset);
+
+                pBuff->ulvalidLength = (unsigned long)(currentOffset - consumedOffset);
+                pBuff->ulvalidLength = pBuff->ulvalidLength > DATA_PAGE_BUFFER_SIZE ?
+                                       DATA_PAGE_BUFFER_SIZE : pBuff->ulvalidLength;
+
+                pBuffer = (uint8*)pBuff->uliBuffer.QuadPart;
+                DRVPRINT(" copy data buffer from %u to %u ", consumedOffset, consumedOffset + pBuff->ulvalidLength);
+
+                memcpy(pBuffer, &pCoreClientData->m_pCoreBuffer->m_pBuffer[consumedOffset], pBuff->ulvalidLength);
+                atomic_set(&pCoreClientData->m_pCoreBuffer->m_consumedOffset, currentOffset);
+
+                cnt++;
+            }
+
+            data_buffer->ulavailableBuffCnt = pClientData->m_configCount;
+            DRVPRINT(" Avaliable Buffer Count %u ", data_buffer->ulavailableBuffCnt);
+            data_buffer->ulStatus = PROF_SUCCESS;
+        }
+    }
+
+    DRVPRINT("Returning value from get buffer %d", ret);
+    return ret;
+}
+
+// StopTimer
+//
+// Stop timer for the specified client id
+// release the memory allocated for timer
+//
+int StopTimer(uint32 clientId)
+{
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    bool stopped = false;
+
+    DRVPRINT(" Stopping the timers for client %d ", clientId);
+
+    if (!list_empty(&tlist.list))
+    {
+        list_for_each(pCurrent, &tlist.list)
+        {
+            pClients = list_entry(pCurrent, ClientList, list);
+
+            DRVPRINT("pClients->m_pClientData->client_id %d, clientId %d ", pClients->m_pClientData->m_clientId, clientId);
+
+            if (NULL != pClients)
+            {
+                if (pClients->m_pClientData->m_clientId == clientId)
+                {
+                    pClients->m_pClientData->m_osClientCfg.m_stopped = true;
+                    stopped = true;
+                }
+            }
+        }
+
+    }
+    else
+    {
+        printk(KERN_ERR "Power Profiler Timer: empty timerlist for client %d \n", clientId);
+    }
+
+    if (false == stopped)
+    {
+        printk(KERN_ERR "Power Profiler Timer:Could not stop profiler for client %d \n", clientId);
+    }
+
+    // m_stopped profiling, set state to 0
+    moduleState = 0;
+
+    return stopped ? 0 : -1;
+}
+
+// PauseTimer
+//
+// Set the pause flag to true to probhit collecting data.
+//
+int PauseTimer(uint32 clientId)
+{
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    bool m_paused = false;
+
+    DRVPRINT(" Pausing the timers for client %d ", clientId);
+
+    if (!list_empty(&tlist.list))
+    {
+        list_for_each(pCurrent, &tlist.list)
+        {
+            pClients = list_entry(pCurrent, ClientList, list);
+
+            if (NULL != pClients->m_pClientData)
+            {
+                DRVPRINT("pClients->m_pClientData->m_clientId %d, clientId %d ", pClients->m_pClientData->m_clientId, clientId);
+
+                if (pClients->m_pClientData->m_clientId == clientId)
+                {
+                    pClients->m_pClientData->m_osClientCfg.m_paused = true;
+                    m_paused = true;
+                }
+            }
+        }
+    }
+    else
+    {
+        DRVPRINT(KERN_ERR "Power Profiler Timer: empty timerlist for client %d ", clientId);
+    }
+
+    if (false == m_paused)
+    {
+        DRVPRINT(KERN_ERR "Power Profiler Timer:Could not pause profiler for client %d ", clientId);
+    }
+
+    return m_paused ? 0 : -1;
+}
+
+// HrTimerCallback
+//
+// Timer functon call back, triggered each time
+// when HR timer expires
+//
+enum hrtimer_restart HrTimerCallback(struct hrtimer* timer_for_restart)
+{
+    CoreData* pCoreClientData = NULL;
+    struct list_head* pCurrent = NULL;
+    ClientList* pClients = NULL;
+    int errorCode = 0;
+    ktime_t currtime;
+    enum hrtimer_restart ret = HRTIMER_NORESTART;
+    const unsigned long ms = 1000000;                   // for process profiling setting sampling time to 1 ms
+    ktime_t processProfDur = ktime_set(0, ms);
+    int cpu = 0;
+
+    // get core id
+    cpu = get_cpu();
+    put_cpu();
+
+    DRVPRINT("Callback (%d)", cpu);
+
+    // get the CORE_CLIENT_OBJECT
+    pCoreClientData = &per_cpu(g_coreClientData, cpu);
+
+    if (!list_empty(&tlist.list))
+    {
+        list_for_each(pCurrent, &tlist.list)
+        {
+            pClients = list_entry(pCurrent, ClientList, list);
+
+            if (NULL != pClients->m_pClientData
+                && pCoreClientData->m_clientId == pClients->m_pClientData->m_clientId
+                && false == pClients->m_pClientData->m_osClientCfg.m_paused
+                && false == pClients->m_pClientData->m_osClientCfg.m_stopped)
+            {
+                currtime = ktime_get();
+                errorCode = SampleDataCallback(pClients->m_pClientData);
+
+                if (!errorCode)
+                {
+                    if (PROFILE_TYPE_TIMELINE == (ProfileType)pCoreClientData->m_profileType)
+                    {
+                        hrtimer_forward_now(timer_for_restart, pCoreClientData->m_interval);
+                    }
+                    else
+                    {
+                        // for Process profiling sampling interval will be 1ms
+                        hrtimer_forward_now(timer_for_restart, processProfDur);
+                    }
+
+                    ret = HRTIMER_RESTART;
+                }
+            }
+        }
+    }
+
+    return ret;
+}
+
+// InitHrTimer
+//
+// Initiailize HR timer
+//
+void InitHrTimer(uint32 cpu)
+{
+    CoreData* pCoreClientData = NULL;
+
+    // get the CORE_CLIENT_OBJECT
+    pCoreClientData = &per_cpu(g_coreClientData, cpu);
+
+    // initialize HR timer
+    hrtimer_init(&pCoreClientData->m_hrTimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
+    pCoreClientData->m_hrTimer.function = &HrTimerCallback;
+
+    return;
+} // InitHrTimer
+
+
+// Initialize : Init HrTimer and counter data
+void Initialize(void)
+{
+    uint32 cpu = get_cpu();
+    put_cpu();
+
+    InitHrTimer(cpu);
+    InitializeGenericCounterAccess(cpu);
+}
+
+// ConfigureTimer
+//
+// Configure the timer with given sampling interval.
+//
+int ConfigureTimer(PROF_CONFIGS* pCfg, uint32 clientId)
+{
+    ClientData* pClientData     = NULL;
+    ClientList* pTempNode       = NULL;
+    CoreData* pCoreData         = NULL;
+    CoreData* pCoreClientData   = NULL;
+    int errRet                  = 0;
+    int cpu                     = 0;
+    uint32 configuredCoreCount  = 0;
+    uint32 coreId               = 0;
+    int cpuCnt                  = 0;
+    bool isFirstConfig          = true;
+    int configIdx               = 0;
+    int ret                     = -1;
+    cpumask_t* pMask            = NULL;
+
+    PwrInternalAddr internalCounter;
+    memset(&internalCounter, 0, sizeof(internalCounter));
+
+    DRVPRINT("Configuring Timer for client %d\n", clientId);
+
+    pMask = kmalloc(sizeof(cpumask_t), GFP_KERNEL);
+
+    if (!pMask)
+    {
+        printk(KERN_WARNING "Power Profiler: Cpu mask creatiom failed\n");
+        return -ENOMEM;
+    }
+
+    // Prepare cpu m_affinity mask structure for the configured core mask
+    cpumask_clear(pMask);
+    PrepareAffinityMask(pMask, pCfg->m_config.m_mask);
+
+    // Create memory pool for this session
+    if (false == CreateMemoryPool(&g_sessionPool, SESSION_POOL_SIZE))
+    {
+        printk(KERN_WARNING "Power Profiler: CreateMemoryPool failed\n");
+        return -ENOMEM;
+    }
+
+    if (AllocateAndInitClientData(&pClientData, clientId, *pMask, pCfg->m_pid, pCfg) != 0)
+    {
+        return -ENOMEM;
+    }
+
+    configuredCoreCount = pCfg->m_config.m_maskCnt;
+    cpuCnt = num_online_cpus();
+
+    DRVPRINT("Configured cpu Count %d and total Number of CPUs : %d ",
+             configuredCoreCount, cpuCnt);
+
+    if (NULL != g_pCoreCfg)
+    {
+        kfree(g_pCoreCfg);
+        g_pCoreCfg = NULL;
+    }
+
+    g_pCoreCfg = kmalloc(cpuCnt * sizeof(CoreData), GFP_KERNEL);
+
+    if (NULL == g_pCoreCfg)
+    {
+        printk(KERN_WARNING "Power Profiler: Memory Allocation for Global configuration failed \n");
+        kfree(pMask);
+        return -ENOMEM;
+    }
+
+    // setting pointer to global config, to be used by RawFileHeader.c
+    pCoreData = g_pCoreCfg;
+
+    for_each_cpu(coreId, &pClientData->m_osClientCfg.m_affinity)
+    {
+        DRVPRINT("Configuring for cpu: %d ", coreId);
+
+        // Get the core specific CORE_CLIENT_DATA for this configured coreId
+        pCoreClientData = &per_cpu(g_coreClientData, coreId);
+
+        ret = IntializeCoreData(pCoreClientData, configIdx, &isFirstConfig,
+                                clientId, coreId, pCfg);
+
+        if (0 != ret)
+        {
+            // free client data
+            printk("Power Profiler: Failed to Intiailise Core data for Core : %d \n", coreId);
+            FreeClientData(pClientData);
+            kfree(pMask);
+            return -ENOMEM;
+        }
+
+        GetRequiredBufferLength(pCoreClientData, &pCoreClientData->m_recLen);
+        pCoreData = pCoreClientData;
+        ++pCoreData;
+
+        configIdx++;
+    }
+
+    cpu = get_cpu();
+    put_cpu();
+
+    if (cpumask_test_cpu(cpu, &pClientData->m_osClientCfg.m_affinity))
+    {
+        Initialize();
+    }
+
+    preempt_disable();
+    smp_call_function_many(&pClientData->m_osClientCfg.m_affinity,
+                           (void*)Initialize,
+                           (void*)NULL,
+                           false); // non blocking call
+    preempt_enable();
+
+    // add to global list of timers data
+    pTempNode = kmalloc(sizeof(ClientList), GFP_KERNEL);
+
+    if (NULL != pTempNode)
+    {
+        pTempNode->m_pClientData = pClientData;
+        list_add(&pTempNode->list, &tlist.list);
+    }
+    else
+    {
+        printk("Error: Failed to add to the list");
+    }
+
+    // Write header data buffer for the file
+    errRet = WriteHeader(pClientData, pCfg);
+
+    DRVPRINT("Exiting Configure Timer with success ");
+    kfree(pMask);
+    return 0;
+} // ConfigureTimer
+
+// UnconfigureTimer
+//
+// Unconfigure timer, delete it from timer list
+//
+int UnconfigureTimer(uint32 clientId)
+{
+    struct list_head* pCurrent = NULL;
+    struct list_head* pTemp = NULL;
+    ClientList* pClients       = NULL;
+    ClientData* pClientData     = NULL;
+    CoreData* pCoreClientData   = NULL;
+    int cpu;
+
+    list_for_each_safe(pCurrent, pTemp, &tlist.list)
+    {
+        if (NULL != pCurrent)
+        {
+            pClients = list_entry(pCurrent, ClientList, list);
+
+            if (NULL != pClients)
+            {
+                pClientData = (ClientData*)pClients->m_pClientData;
+
+                if (NULL != pClientData)
+                {
+                    if (pClientData->m_clientId == clientId)
+                    {
+                        DRVPRINT(" Deleting timer for client id %d ", clientId);
+
+                        for_each_cpu(cpu, &pClientData->m_osClientCfg.m_affinity)
+                        {
+                            pCoreClientData = &per_cpu(g_coreClientData, cpu);
+
+                            if (NULL != pCoreClientData)
+                            {
+                                hrtimer_cancel(&pCoreClientData->m_hrTimer);
+
+                                // Release smu configuration
+                                //ConfigureSmu(pCoreClientData->m_smuCfg, false);
+                                FreeCoreData(pCoreClientData);
+
+                                pCoreClientData = NULL;
+                            }
+                            else
+                            {
+                                DRVPRINT("Error: pCoreClientData == NULL");
+                            }
+                        }
+
+                        pClientData->m_osClientCfg.m_stopped = true;
+                        pClientData->m_osClientCfg.m_paused = true;
+
+
+                        CloseGenericCounterAccess();
+
+                        FreeClientData(pClientData);
+
+                        list_del(pCurrent);
+                        kfree(pClients);
+
+                        if (NULL != g_pCoreCfg)
+                        {
+                            kfree(g_pCoreCfg);
+                            g_pCoreCfg = NULL;
+                        }
+                        else
+                        {
+                            DRVPRINT("Error: g_pCoreCfg == NULL");
+                        }
+                    }
+                }
+                else
+                {
+                    DRVPRINT("Error: pClientData == NULL");
+                }
+            }
+            else
+            {
+                DRVPRINT("Error: pClients == NULL");
+            }
+        }
+        else
+        {
+            DRVPRINT("Error: pCounter == NULL");
+        }
+    }
+
+    return 0;
+}
+
diff --git a/drivers/powerprofiler/src/PwrProfTimerHelper.c b/drivers/powerprofiler/src/PwrProfTimerHelper.c
new file mode 100644
index 000000000000..4f6346ad0838
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrProfTimerHelper.c
@@ -0,0 +1,226 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrProfTimerHelper.c
+///
+//==================================================================================
+#include <linux/slab.h>
+#include <PwrOsPrimitives.h>
+#include <PwrProfTimerHelper.h>
+#include <PwrDriverUtils.h>
+#include <PwrCommonConfig.h>
+#include <PwrSharedBufferConfig.h>
+
+extern uint8_t* g_pPwrSharedBuffer[MAX_CORE_CNT];
+
+// AllocateAndInitClientData
+//
+// Allocate and Initialise Client Data
+int AllocateAndInitClientData(ClientData** ppClientData,
+                              uint32 clientId,
+                              cpumask_t affinity,
+                              pid_t parentPID,
+                              const PROF_CONFIGS* pCfg)
+{
+    ClientData* pClientData = NULL;
+
+    // Allocate and construct ClientData
+    pClientData = kmalloc(sizeof(ClientData), GFP_KERNEL);
+
+    if (NULL == pClientData)
+    {
+        printk(KERN_WARNING "Power Profiler: Memory Allocation failure for timer \n");
+        return -ENOMEM;
+    }
+
+    // initialise ClientData
+    memset(pClientData, 0, sizeof(ClientData));
+
+    pClientData->m_clientId                       = clientId;
+    pClientData->m_osClientCfg.m_affinity         = affinity;
+    pClientData->m_osClientCfg.m_paused           = false;
+    pClientData->m_osClientCfg.m_stopped          = false;
+    pClientData->m_osClientCfg.m_parentPid        = parentPID;
+    pClientData->m_configCount                    = pCfg->m_config.m_maskCnt;
+
+    pClientData->m_header.m_pBuffer = kmalloc(HEADER_BUFFER_SIZE, false);
+
+    if (NULL == pClientData->m_header.m_pBuffer)
+    {
+        printk(KERN_WARNING "Power Profiler: Memory Allocation failure for Core Buffer\n");
+        return -ENOMEM;
+    }
+
+    pClientData->m_header.m_recCnt = 0;
+    atomic_set(&pClientData->m_header.m_currentOffset, 0);
+    atomic_set(&pClientData->m_header.m_consumedOffset, 0);
+
+    *ppClientData = pClientData;
+    return 0;
+}
+
+// IntializeCoreData
+//
+// Initialise and  per core data
+int IntializeCoreData(CoreData* pCoreClientData,
+                      int index,
+                      bool* isFirstConfig,
+                      uint32 clientId,
+                      uint32 coreId,
+                      PROF_CONFIGS* pCfg)
+{
+    uint64 phyCoreMask = 0;
+    uint64 pkgCounterMask = 0;
+    uint64 coreSpecficMask = 0;
+    PTARGET_SYSTEM_INFO pTargetInfo = NULL;
+
+    if (NULL == g_pPwrSharedBuffer[index])
+    {
+        printk("Power Profiler: shared memory is not yet allocated.\n");
+        return -ENOMEM;
+    }
+
+    GetTargetSystemInfo(&pTargetInfo, false);
+
+    if (NULL == pTargetInfo)
+    {
+        // Todo: currently it is null for intel/unsupported platform. We need to fix this
+        DRVPRINT("pTargetInfo is NULL");
+        return -ENOMEM;
+    }
+
+    // currently blindly clearing the g_coreClientData
+    memset(pCoreClientData, 0, sizeof(CoreData));
+
+    pCoreClientData->m_clientId             = clientId;
+    pCoreClientData->m_sampleId             = index + 1;
+    pCoreClientData->m_samplingInterval     = pCfg->m_config.m_samplingPeriod;
+    pCoreClientData->m_recLen               = 0;
+    pCoreClientData->m_coreId               = coreId;
+    pCoreClientData->m_bufferSize = PWRPROF_CORE_BUFFER_SIZE - sizeof(PageBuffer);
+
+    pCoreClientData->m_pCoreBuffer = NULL;
+
+    pCoreClientData->m_pCoreBuffer = (PageBuffer*)g_pPwrSharedBuffer[index];
+
+
+    if (NULL == pCoreClientData->m_pCoreBuffer)
+    {
+        printk("Memory allocation failed for pCoreBuffer offset %d index\n", index);
+        return -ENOMEM;
+    }
+
+    // initialize the meta data shared between driver and backend
+    pCoreClientData->m_pCoreBuffer->m_recCnt = 0;
+    atomic_set(&pCoreClientData->m_pCoreBuffer->m_currentOffset, 0);
+    atomic_set(&pCoreClientData->m_pCoreBuffer->m_consumedOffset, 0);
+    atomic_set(&pCoreClientData->m_pCoreBuffer->m_maxValidOffset, 0);
+    pCoreClientData->m_pCoreBuffer->m_fill = 0xdeadbeef;
+
+    // m_pCoreBuffer::m_pBuffer should point to the start of the data buffer
+    pCoreClientData->m_pCoreBuffer->m_pBuffer = g_pPwrSharedBuffer[index] + sizeof(PageBuffer);
+
+    // TODO: Is it OK to do memset for many pages?
+    memset(pCoreClientData->m_pCoreBuffer->m_pBuffer, 0, pCoreClientData->m_bufferSize);
+
+    // Callback timer
+    pCoreClientData->m_interval = ktime_set(0, pCfg->m_config.m_samplingPeriod * 1000000);
+    pCoreClientData->m_samplingInterval = pCfg->m_config.m_samplingPeriod;
+    pCoreClientData->m_profileType = pCfg->m_config.m_profileType;
+
+    if (NULL != pTargetInfo)
+    {
+        // Check for core energy counters which are physical core specific
+        if (pCfg->m_config.m_counterMask & (1ULL << COUNTERID_CORE_POWER))
+        {
+            if(!cpu_online(pTargetInfo->m_zen.m_apic[coreId].m_physicalId))
+            {
+                uint32_t thread_id = 0;
+
+                for (thread_id = 0; thread_id < pTargetInfo->m_zen.m_totalThreads; thread_id++)
+                {
+                    if (coreId == (pTargetInfo->m_zen.m_apic[thread_id].m_extdApic >> 1))
+                    {
+                        if (cpu_online(thread_id))
+                        {
+                            pTargetInfo->m_zen.m_apic[coreId].m_physicalId = (pTargetInfo->m_zen.m_apic[thread_id].m_extdApic >> 1);
+                            break;
+                        }
+                    }
+                }
+            }
+
+            if (coreId == pTargetInfo->m_zen.m_apic[coreId].m_physicalId)
+            {
+                phyCoreMask = (1ULL << COUNTERID_CORE_POWER);
+            }
+        }
+
+        if ((pTargetInfo->m_socketCount > 1)
+            && (pTargetInfo->m_isZen))
+        {
+            uint32 socketId = 0;
+
+            for (socketId = 0; socketId < PWR_MAX_SOCKET_COUNT; socketId++)
+            {
+                if(pTargetInfo->m_zen.m_firstCore[socketId] == coreId)
+                {
+                    pkgCounterMask = (pCfg->m_config.m_counterMask & (1ULL << COUNTERID_PKG_POWER)) ? (1ULL << COUNTERID_PKG_POWER) : 0;
+                    pkgCounterMask |= (pCfg->m_config.m_counterMask & (1ULL << COUNTERID_PKG_TEMPERATURE)) ? (1ULL << COUNTERID_PKG_TEMPERATURE) : 0;
+                    break;
+                }
+            }
+        }
+    }
+
+    if (true == *isFirstConfig)
+    {
+        // Configuration for master core
+        pCoreClientData->m_counterMask = pCfg->m_config.m_counterMask;
+        *isFirstConfig = false;
+    }
+    else
+    {
+        coreSpecficMask = pCfg->m_config.m_counterMask & PWR_PERCORE_COUNTER_MASK;
+        pCoreClientData->m_counterMask = coreSpecficMask | phyCoreMask | pkgCounterMask;
+    }
+
+    return 0;
+}
+
+// FreeClientData
+//
+// Free Memmory set by client data
+void FreeClientData(ClientData* pClientData)
+{
+    if (NULL != pClientData)
+    {
+        if (NULL != pClientData->m_header.m_pBuffer)
+        {
+            kfree(pClientData->m_header.m_pBuffer);
+            pClientData->m_header.m_pBuffer = NULL;
+        }
+
+        kfree(pClientData);
+    }
+
+    return;
+}
+
+// FreeCoreData
+//
+// Free memory allocated to CoreData
+//
+void FreeCoreData(CoreData* pCoreClientData)
+{
+    if (NULL != pCoreClientData)
+    {
+        if (NULL != pCoreClientData->m_pCoreBuffer)
+        {
+            pCoreClientData->m_pCoreBuffer = NULL;
+        }
+    }
+
+    return;
+}
diff --git a/drivers/powerprofiler/src/PwrSampleCollect.c b/drivers/powerprofiler/src/PwrSampleCollect.c
new file mode 100644
index 000000000000..6a7168627f7c
--- /dev/null
+++ b/drivers/powerprofiler/src/PwrSampleCollect.c
@@ -0,0 +1,613 @@
+//==================================================================================
+// Copyright (c) 2017 , Advanced Micro Devices, Inc.  All rights reserved.
+//
+/// \author AMD Developer Tools Team
+/// \file PwrSampleCollect.c
+///
+//==================================================================================
+#include <PwrCounterAccessInterface.h>
+#include <PwrOsPrimitives.h>
+#include <PwrDriverUtils.h>
+#include <PwrCommonDataTypes.h>
+#include <PwrProfInternal.h>
+#include <PwrSharedBufferConfig.h>
+#include <PwrCommonConfig.h>
+
+#define ONLINE_SECTION_HEADER_CNT (2)
+#define MAX_SMU_VALUE_CNT 64
+#define MAX_REPEAT_CNT 10
+#define PWR_BASIC_AND_HEADER_RECORD_LEN 26
+
+#if defined(_WIN32)
+    extern PPWRPROF_DEV_EXTENSION gpPwrDevExt;
+#endif
+
+extern CoreData* g_pCoreCfg;
+extern uint8* pSharedBuffer;
+
+//WriteRawBufferHeader: Prepare and write header to the header buffer
+int32 WriteRawBufferHeader(RawFileHeader* pHeader, uint16 sectionCnt)
+{
+    int32 ret = STATUS_SUCCESS;
+
+    if (pHeader == NULL)
+    {
+        DRVPRINTERROR("Error: pHeader == NULL");
+        ret = STATUS_INVALID_PARAMETER;
+    }
+    else
+    {
+        pHeader->m_magicNum = RAWFILE_MAGIC;
+        pHeader->m_rawFileVersion = RAW_FILE_VERSION;
+        pHeader->m_sectionTabCnt = SECTION_HDR_CNT;
+        pHeader->m_versionNum = PROFILE_VERSION;
+
+        // High resolution relative timestamp
+        pHeader->m_startPerfCounter = 0;
+        pHeader->m_perfFreq = 0;
+
+        //Start session should be updated when start profiling is called
+        pHeader->m_sessionStart = 0;
+
+        //End session should be updated when stop profiling is called
+        pHeader->m_sessionEnd = 0;
+
+        //Get the family and model of the CPU
+        GetCpuModelFamily((uint32*)&pHeader->m_family, (uint32*)&pHeader->m_model);
+
+        //Record count can not be provided in  case of online profiling
+        pHeader->m_rawRecordCount = 0;
+
+        //Only one section header table is used at this moment.
+        pHeader->m_tabInfo[0].m_sectionTabOff = sizeof(RawFileHeader);
+        pHeader->m_tabInfo[0].m_sectionTabSize = sectionCnt * sizeof(SectionHdrInfo);
+    }
+
+    return ret;
+}
+
+//WriteSectionHeaders: Prepare and write section headers based on the section header mask
+int32 WriteSectionHeaders(SectionHdrInfo* secHeader, uint64 secHeaderMask)
+{
+    int32 ret = STATUS_SUCCESS;
+    uint32 cnt = 1;
+
+    if (secHeader == NULL)
+    {
+        DRVPRINTERROR("Error: secHeader == NULL");
+        ret = STATUS_INVALID_PARAMETER;
+    }
+    else
+    {
+        while (cnt < RAW_FILE_SECTION_MAX - 1)
+        {
+            if (secHeaderMask & cnt)
+            {
+                secHeader->m_sectionType = cnt;
+                secHeader->m_sectionOffset = 0;
+                secHeader->m_sectionSize = 0;
+
+                secHeader++;
+            }
+
+            cnt = cnt << 1;
+        }
+    }
+
+    return ret;
+}
+
+//UpdateBufferHeader: Update header buffer for session start/end timestamp, record count
+//field = 0 for start time update
+//field = 1 for end time update
+//filed =2 for record count
+int32 UpdateBufferHeader(ClientData* pClient, uint16 field)
+{
+    int32 ret = STATUS_SUCCESS;
+    PageBuffer* pBuffer;
+    RawFileHeader* pHeader = NULL;
+
+    if (NULL == pClient->m_header.m_pBuffer)
+    {
+        ret = STATUS_INVALID_PARAMETER;
+        DRVPRINTERROR("Error: pClient->m_header.m_pBuffer is NULL");
+    }
+    else
+    {
+        pBuffer = &pClient->m_header;
+
+        if (NULL != pBuffer)
+        {
+            pHeader = (RawFileHeader*)pBuffer->m_pBuffer;
+
+            if (NULL == pHeader)
+            {
+                DRVPRINTERROR("Error: pBuffer is NULL");
+                ret = STATUS_INVALID_PARAMETER;
+            }
+        }
+        else
+        {
+            DRVPRINTERROR("Error: pHeader is NULL");
+            ret = STATUS_INVALID_PARAMETER;
+        }
+    }
+
+    if (STATUS_SUCCESS == ret)
+    {
+        switch (field)
+        {
+            case 0:
+            {
+                //update start session timestamp
+                //Retrive the current time stamp when session was started
+                GetTimeStamp(&pHeader->m_sessionStart);
+
+                // Also get the high resolution performance counter and frequency
+                // values for relative timestamp
+                GetPerformanceCounter(&pHeader->m_startPerfCounter, &pHeader->m_perfFreq);
+                break;
+            }
+
+            case 1:
+            {
+                //update end session timestamp
+                //Retrive the current time stamp when session was stopped
+                GetTimeStamp(&pHeader->m_sessionEnd);
+                break;
+            }
+
+            case 2:
+            {
+                //update total record count
+                PageBuffer* pCoreBuffer = g_pCoreCfg->m_pCoreBuffer;
+
+                if (NULL != pCoreBuffer)
+                {
+                    pHeader->m_rawRecordCount = pCoreBuffer->m_recCnt;
+                }
+                else
+                {
+                    DRVPRINTERROR("Error: pCoreBuffer in valid");
+                    ret = STATUS_INVALID_PARAMETER;
+                }
+
+                break;
+            }
+
+            default:
+            {
+                DRVPRINTERROR("Error: invalid operation");
+                ret = STATUS_INVALID_PARAMETER;
+            }
+        }
+    }
+
+    return ret;
+
+}
+
+//WriteSampleCfgInfo: Prepare and write the Sample configuration to the buffer
+int32 WriteSampleCfgInfo(ClientData* pClient, PROF_CONFIGS* pSrcCfg)
+{
+    int32 ret = STATUS_SUCCESS;
+    SectionHdrInfo* hdrInfo = NULL;
+    PROF_CONFIGS* profConfig = NULL;
+    PageBuffer* pBuffer = &pClient->m_header;
+    uint32 offset = 0;
+    uint32 currentOffset = 0;
+    uint32 cnt = ONLINE_SECTION_HEADER_CNT;
+
+    if (NULL == pBuffer->m_pBuffer)
+    {
+        DRVPRINTERROR("Error: pBuffer->m_pBuffer is NULL");
+        ret = STATUS_INVALID_PARAMETER;
+    }
+    else
+    {
+        ATOMIC_GET(&offset, pBuffer->m_currentOffset);
+        hdrInfo = (SectionHdrInfo*) & (pBuffer->m_pBuffer[sizeof(RawFileHeader)]);
+        profConfig = (PROF_CONFIGS*) & (pBuffer->m_pBuffer[offset]);
+        memcpy(profConfig, pSrcCfg, sizeof(PROF_CONFIGS));
+        ATOMIC_SET(&pBuffer->m_currentOffset, offset + sizeof(PROF_CONFIGS));
+
+        //Update section header
+        while (cnt--)
+        {
+            if (hdrInfo->m_sectionType == RAW_FILE_SECTION_SAMPLE_CONFIG)
+            {
+                hdrInfo->m_sectionOffset = offset;
+                hdrInfo->m_sectionSize = currentOffset - offset;
+                break;
+            }
+
+            hdrInfo++;
+        }
+    }
+
+    return ret;
+}
+
+//WriteSampleInfo: This section tells the information regarding the
+//first chunk offset and other details. Using the next chunk offset information
+//it is easy to walk through similar type chunk records.
+int32 WriteSampleInfo(ClientData* pClient)
+{
+    int32 ret = STATUS_SUCCESS;
+    SectionHdrInfo* hdrInfo = NULL;
+    SectionSampleInfo* sampleInfo = NULL;
+    uint32 cnt = ONLINE_SECTION_HEADER_CNT;
+    PageBuffer* pBuffer = &pClient->m_header;
+    uint32 offset = 0;
+
+    if (NULL == pBuffer)
+    {
+        DRVPRINTERROR("Error: pBuffer is NULL");
+        ret = STATUS_INVALID_PARAMETER;
+    }
+    else
+    {
+        ATOMIC_GET(&offset, pBuffer->m_currentOffset);
+
+        hdrInfo = (SectionHdrInfo*) & (pBuffer->m_pBuffer[sizeof(RawFileHeader)]);
+        sampleInfo = (SectionSampleInfo*) & (pBuffer->m_pBuffer[offset]);
+
+        sampleInfo->m_firstChunkOffset = 0;
+        sampleInfo->m_recordCount = 0;
+        sampleInfo->m_size = 0;
+        ATOMIC_SET(&pBuffer->m_currentOffset, offset + sizeof(SectionSampleInfo));
+
+        //Update section header
+        while (cnt--)
+        {
+            if (hdrInfo->m_sectionType == RAW_FILE_SECTION_SAMPLE_REC_INFO)
+            {
+                hdrInfo->m_sectionOffset = offset;
+                hdrInfo->m_sectionSize = sizeof(SectionSampleInfo);
+                break;
+            }
+
+            hdrInfo++;
+        }
+    }
+
+    return ret;
+}
+
+//WriteSections: Write various sections in the header buffer.
+//Only two sections are added in case of online profiling at this moment
+int32 WriteSections(ClientData* pClient, PROF_CONFIGS* pSrcCfg, uint64 secHeaderMask)
+{
+    int32 ret = STATUS_SUCCESS;
+
+    uint64 cnt = 1;
+
+    while (cnt < RAW_FILE_SECTION_MAX)
+    {
+        switch (secHeaderMask & cnt)
+        {
+            case RAW_FILE_SECTION_RUN_INFO:
+                break;
+
+            case RAW_FILE_SECTION_CPU_INFO:
+                break;
+
+            case RAW_FILE_SECTION_CPU_TOPOLOGY:
+                break;
+
+            case RAW_FILE_SECTION_SAMPLE_CONFIG:
+                ret = WriteSampleCfgInfo(pClient, pSrcCfg);
+                break;
+
+            case RAW_FILE_SECTION_SAMPLE_REC_INFO:
+                ret = WriteSampleInfo(pClient);
+                break;
+
+            case RAW_FILE_SECTION_TI_REC_INFO:
+                break;
+
+            default:
+                //Do nothing and check for next optional section
+                break;
+        }
+
+        cnt = cnt << 1;
+    }
+
+    return ret;
+}
+
+//WriteHeader: Prepare and write data header
+int32 WriteHeader(ClientData* pClient, PROF_CONFIGS* pSrcCfg)
+{
+    int32 ret = STATUS_SUCCESS;
+    PageBuffer* pBuffer = &pClient->m_header;
+    RawFileHeader* pHeader = NULL;
+    uint32 offset = 0;
+
+    //Only two sections are written to the header for online profiling
+    uint16 sectionCnt = ONLINE_SECTION_HEADER_CNT;
+    uint64 secMask = RAW_FILE_SECTION_SAMPLE_CONFIG |
+                     RAW_FILE_SECTION_SAMPLE_REC_INFO;
+
+    if (NULL == pBuffer || NULL == pSrcCfg)
+    {
+        DRVPRINTERROR("Error: NULL pBuffer(%p) pSrcCfg(%p)", pBuffer, pSrcCfg);
+        ret = STATUS_INVALID_PARAMETER;
+    }
+
+    if (STATUS_SUCCESS == ret)
+    {
+        // Write raw file header
+        ret = WriteRawBufferHeader((RawFileHeader*)pBuffer->m_pBuffer, sectionCnt);
+    }
+
+    if (STATUS_SUCCESS == ret)
+    {
+        ATOMIC_SET(&pBuffer->m_currentOffset, offset + sizeof(RawFileHeader));
+        ATOMIC_GET(&offset, pBuffer->m_currentOffset);
+        // Write section headers
+        ret = WriteSectionHeaders((SectionHdrInfo*) & (pBuffer->m_pBuffer[offset]), secMask);
+    }
+
+    if (STATUS_SUCCESS == ret)
+    {
+        ATOMIC_GET(&offset, pBuffer->m_currentOffset);
+        ATOMIC_SET(&pBuffer->m_currentOffset, offset + (sectionCnt * sizeof(SectionHdrInfo)));
+
+        pHeader = (RawFileHeader*)pBuffer->m_pBuffer;
+        pHeader->m_tabInfo[0].m_sectionTabSize = ONLINE_SECTION_HEADER_CNT * sizeof(SectionHdrInfo);
+
+        // Write sections
+        ret = WriteSections(pClient, pSrcCfg, secMask);
+    }
+
+    return ret;
+}
+
+bool GetRequiredBufferLength(CoreData* pCfg, uint32* pLength)
+{
+    uint32 attrCnt = 0;
+    uint32 bufferLen = 0;
+    uint64 mask = 0;
+
+    if ((NULL != pLength) && (NULL != pCfg))
+    {
+        mask = pCfg->m_counterMask;
+
+        // Default length calculation for each counter
+        bufferLen = PWR_BASIC_AND_HEADER_RECORD_LEN;
+
+        for (attrCnt = 0; attrCnt < COUNTERID_NODE_MAX_CNT; attrCnt++)
+        {
+            if ((mask >> attrCnt) & 0x01)
+            {
+                bufferLen += GetNodeCounterSize(attrCnt);
+            }
+        }
+
+        DRVPRINT("Counter len %d", bufferLen);
+        *pLength = bufferLen;
+    }
+
+    return true;
+}
+
+// GetMarkerKey: Generate marker id from the given marker name
+uint32 GetMarkerKey(uint8* str)
+{
+    uint32 hash = 5381;
+    uint32 c;
+    uint32 len = 0;
+
+    while (((c = *str++) != 0) && (len++ < PWR_MARKER_BUFFER_SIZE))
+    {
+        hash = ((hash << 5) + hash) + c;
+    }
+
+    return hash;
+}
+
+// GetMarkerRecords: Read available markers from shared buffer
+void GetMarkerRecords(MarkerTag* pTags, uint32* pCount)
+{
+    uint32* pMarkerCnt = 0;
+    MarkerTag* pBuffer = NULL;
+    uint32 prev = 0;
+    *pCount = 0;
+
+    if ((NULL != pSharedBuffer)
+        && (*(uint32*)&pSharedBuffer[ sizeof(uint32)] > 0)
+        && (NULL != pTags))
+    {
+
+        // Check if buffer is busy. If not, set the busy flag and read data
+        prev = ATOMIC_CMPEXCHANGE(pSharedBuffer, 1, 0);
+
+        // Buffer is not busy, read the content
+        if (prev == 0)
+        {
+            pMarkerCnt = (uint32*)&pSharedBuffer[ sizeof(uint32)];
+
+            if (*pMarkerCnt > 0)
+            {
+                pBuffer = (MarkerTag*)&pSharedBuffer[2 * sizeof(uint32)];
+                memset(pTags, 0, PWR_MAX_MARKER_CNT * sizeof(MarkerTag));
+                memcpy(pTags, pBuffer, *pMarkerCnt * sizeof(MarkerTag));
+                *pCount = *pMarkerCnt;
+                ATOMIC_SET((atomic*)pSharedBuffer, 0);
+                ATOMIC_SET((atomic*)pMarkerCnt, 0);
+            }
+        }
+    }
+}
+
+#define PWR_EMPTY_RECORD_LEN 26 //(HDR+BASIC COUNTERS)
+//WriteSampleData: Prepare the records from the atrribute values and write into
+//the buffer.
+int32 WriteSampleData(CoreData* pCoreCfg)
+{
+    int32 ret = STATUS_SUCCESS;
+    uint8* pBuffer = NULL;
+    RawRecordHdr* pRecHdr = NULL;
+    uint64 attrMask = 0;
+    uint32 offset = 0;
+    PageBuffer* pCoreBuffer = NULL;
+    bool collectSample = true;
+    bool isMarkerTag = false;
+    uint32 len = 0;
+    uint32 prevOffset = 0;
+    uint32 markerCnt = 0;
+    uint32 idx = 0;
+    bool updateMax = false;
+    MarkerTag markerInfo[PWR_MAX_MARKER_CNT];
+
+    // Check valid pointers & buffers
+    if ((NULL == pCoreCfg)
+        || (NULL == pCoreCfg->m_pCoreBuffer)
+        || (NULL == pCoreCfg->m_pCoreBuffer->m_pBuffer))
+    {
+        DRVPRINT("NULL pointer pCoreCfg %s m_pBuffer %s",
+                 (NULL == pCoreCfg) ? "NULL" : "OK",
+                 (NULL == pCoreCfg->m_pCoreBuffer->m_pBuffer) ? "NULL" : "OK");
+        ret = STATUS_NO_MEMORY;
+    }
+
+    // Calculate buffer required
+    if (STATUS_SUCCESS == ret)
+    {
+        pCoreCfg->m_pCoreBuffer->m_recCnt++;
+
+        // Calculate buffer required for context record
+        if (PROFILE_TYPE_APP_ANALYSIS == pCoreCfg->m_profileType)
+        {
+            collectSample =  false;
+            len = CONTEXT_RECORD_LEN;
+
+            if (!(pCoreCfg->m_pCoreBuffer->m_recCnt % pCoreCfg->m_samplingInterval)
+                && (0 != pCoreCfg->m_pCoreBuffer->m_recCnt))
+            {
+                len += pCoreCfg->m_recLen;
+
+                // Todo: Need to check if we can avoid writing a blank sample record for NON RAPL core
+                // This will free up some shared memory space. We have seen some missing record if we avaoid
+                // writing a dummy sample
+                collectSample = true;
+
+                GetMarkerRecords(markerInfo, &markerCnt);
+
+                if (markerCnt > 0)
+                {
+                    len += (markerCnt * MARKER_RECORD_LEN);
+                    isMarkerTag = true;
+                }
+            }
+        }
+        else
+        {
+            len = pCoreCfg->m_recLen;
+        }
+    }
+
+    if (STATUS_SUCCESS == ret)
+    {
+        pCoreBuffer = pCoreCfg->m_pCoreBuffer;
+        ATOMIC_GET(&offset, pCoreBuffer->m_currentOffset);
+
+        // Check if remaining buffer area is not sufficient to accommodated one more record.
+        // If so, start writing from begining
+        if (pCoreCfg->m_bufferSize < (offset + len))
+        {
+            ATOMIC_SET(&pCoreBuffer->m_currentOffset, 0);
+            prevOffset = offset;
+            updateMax = true;
+            offset = 0;
+        }
+
+        pBuffer = pCoreBuffer->m_pBuffer;
+    }
+
+    if ((STATUS_SUCCESS == ret)
+        && isMarkerTag)
+    {
+        for (idx = 0; idx < markerCnt; idx++)
+        {
+            pRecHdr = (RawRecordHdr*) &pBuffer[offset];
+            pRecHdr->m_recordType = REC_TYPE_MARKER_DATA;
+            pRecHdr->m_recordLen = (uint16)MARKER_RECORD_LEN;
+            pRecHdr->m_coreId = pCoreCfg->m_coreId;
+            offset += sizeof(RawRecordHdr);
+            markerInfo[idx].m_ts = pCoreCfg->m_contextData.m_timeStamp;
+            markerInfo[idx].m_markerId = GetMarkerKey(markerInfo[idx].m_name);
+            memcpy((MarkerTag*)&pBuffer[offset], &markerInfo[idx], sizeof(MarkerTag));
+            offset += sizeof(MarkerTag);
+            DRVPRINT("marker name %s id %d", markerInfo[idx].m_name, markerInfo[idx].m_markerId);
+        }
+
+        markerCnt = 0;
+        isMarkerTag = false;
+    }
+
+    if ((STATUS_SUCCESS == ret)
+        && (PROFILE_TYPE_APP_ANALYSIS == pCoreCfg->m_profileType))
+    {
+        // Collect context data @ 1ms
+        uint64* pRecId = NULL;
+        ContextData* pContextData = NULL;
+
+        pRecHdr = (RawRecordHdr*) &pBuffer[offset];
+
+        pRecHdr->m_recordType = REC_TYPE_CONTEXT_DATA;
+        pRecHdr->m_recordLen = (uint16)CONTEXT_RECORD_LEN;
+        pRecHdr->m_coreId = pCoreCfg->m_coreId;
+        offset += sizeof(RawRecordHdr);
+
+        pRecId = (uint64*)&pBuffer[offset];
+        *pRecId = pCoreCfg->m_pCoreBuffer->m_recCnt;
+        offset += sizeof(uint64);
+
+        // Fill the context data
+        pContextData = (ContextData*)&pBuffer[offset];
+        PwrGetIpcData(pCoreCfg->m_pmc, pContextData->m_pmcData);
+
+        pContextData->m_processId = pCoreCfg->m_contextData.m_processId;
+        pContextData->m_threadId = pCoreCfg->m_contextData.m_threadId;
+        pContextData->m_timeStamp = pCoreCfg->m_contextData.m_timeStamp;
+        pContextData->m_ip = pCoreCfg->m_contextData.m_ip;
+
+        offset += sizeof(ContextData);
+    }
+
+    if ((true == collectSample) && (STATUS_SUCCESS == ret))
+    {
+        pRecHdr = (RawRecordHdr*) &pBuffer[offset];
+        pRecHdr->m_recordType = REC_TYPE_SAMPLE_DATA;
+        pRecHdr->m_recordLen = (uint16)pCoreCfg->m_recLen;
+        pRecHdr->m_coreId = pCoreCfg->m_coreId;
+        offset += sizeof(RawRecordHdr);
+
+        // These attributes are common to all cores
+        CollectBasicCounters(pCoreCfg, &offset);
+
+        attrMask = pCoreCfg->m_counterMask;
+
+        // Collect node counters
+        if (attrMask)
+        {
+            CollectNodeCounters(pCoreCfg, &offset);
+        }
+    }
+
+    if (STATUS_SUCCESS == ret)
+    {
+        //Update the currentOffset now
+        ATOMIC_SET(&pCoreBuffer->m_currentOffset, offset);
+
+        if (true == updateMax)
+        {
+            ATOMIC_SET(&pCoreBuffer->m_maxValidOffset, prevOffset);
+        }
+    }
+
+    return ret;
+}
-- 
2.34.1

